{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cDtxLIBHgQ",
        "outputId": "e42cb242-d29f-42ef-9b1c-e1b7c0e61cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun 28 16:53:14 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpPg4mGKc1v",
        "outputId": "9fed49b5-3ce8-4c81-9c40-03b015ca6232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbfObJV8FByK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSMcABDNKW-",
        "outputId": "cd950c99-fb9e-48ea-81c7-71bcee5346b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.160 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 41.8/112.6 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "!pip install ultralytics\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QmuYEMI4UZAa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "47badc94-262c-4d71-92bb-f8f4c2a271e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'ultralytics'...\n",
            "remote: Enumerating objects: 62581, done.\u001b[K\n",
            "remote: Counting objects: 100% (233/233), done.\u001b[K\n",
            "remote: Compressing objects: 100% (153/153), done.\u001b[K\n",
            "remote: Total 62581 (delta 166), reused 80 (delta 80), pack-reused 62348 (from 3)\u001b[K\n",
            "Receiving objects: 100% (62581/62581), 33.64 MiB | 28.78 MiB/s, done.\n",
            "Resolving deltas: 100% (46594/46594), done.\n",
            "/content/ultralytics\n",
            "Obtaining file:///content/ultralytics\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.160) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.160) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.160) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.160) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.160) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.160) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.160) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.160) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.160) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.160) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.160) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.160) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.160) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.160) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.160) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.160) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.160) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.160) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.160) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.160) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.160) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.3.160) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.3.160) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.160) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.160) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.160) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.160) (2025.6.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.160) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics==8.3.160) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.3.160) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.3.160) (3.0.2)\n",
            "Building wheels for collected packages: ultralytics\n",
            "  Building editable for ultralytics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ultralytics: filename=ultralytics-8.3.160-0.editable-py3-none-any.whl size=23090 sha256=bb88b8302361295c93bebcd20d2899d55a54e57f0ac3ad9bfe6c58722425cc0a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0gf0dv9q/wheels/ea/71/6b/a9012dfb148489fd8125c2310e565414c996b3c7721defe799\n",
            "Successfully built ultralytics\n",
            "Installing collected packages: ultralytics\n",
            "  Attempting uninstall: ultralytics\n",
            "    Found existing installation: ultralytics 8.3.160\n",
            "    Uninstalling ultralytics-8.3.160:\n",
            "      Successfully uninstalled ultralytics-8.3.160\n",
            "Successfully installed ultralytics-8.3.160\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ultralytics"
                ]
              },
              "id": "80686e23844f41dda0486951ec2ff3b2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Git clone method (for development)\n",
        "\n",
        "import os\n",
        "HOME = os.getcwd()\n",
        "\n",
        "# Clone the Ultralytics repository\n",
        "%cd {HOME}\n",
        "!git clone https://github.com/ultralytics/ultralytics\n",
        "%cd {HOME}/ultralytics\n",
        "\n",
        "# Install the package in editable mode\n",
        "!pip install -e .\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x \"/content/ultralytics/ultralytics/nn/yolo_cam.rar\" \"/content/ultralytics/ultralytics/nn\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C56ST_k-bgrt",
        "outputId": "8f0c4bab-7651-4051-9ba7-48d51515f9bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/ultralytics/ultralytics/nn/yolo_cam.rar\n",
            "\n",
            "Creating    /content/ultralytics/ultralytics/nn/yolo_cam              OK\n",
            "Extracting  /content/ultralytics/ultralytics/nn/yolo_cam/activations_and_gradients.py     \b\b\b\b  9%\b\b\b\b\b  OK \n",
            "Extracting  /content/ultralytics/ultralytics/nn/yolo_cam/base_cam.py     \b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  /content/ultralytics/ultralytics/nn/yolo_cam/eigen_cam.py     \b\b\b\b 47%\b\b\b\b\b  OK \n",
            "Creating    /content/ultralytics/ultralytics/nn/yolo_cam/utils        OK\n",
            "Extracting  /content/ultralytics/ultralytics/nn/yolo_cam/utils/image.py     \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  /content/ultralytics/ultralytics/nn/yolo_cam/utils/model_targets.py     \b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  /content/ultralytics/ultralytics/nn/yolo_cam/utils/svd_on_activations.py     \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  /content/ultralytics/ultralytics/nn/yolo_cam/__init__.py     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSd93ZJzZZKt",
        "outputId": "ff485a5c-158e-4225-eea0-fa4b391d198a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hmkdir: cannot create directory ‘/content/datasets’: File exists\n",
            "/content/datasets\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in CPE-Dataset-16 to yolov8:: 100%|██████████| 68788/68788 [00:01<00:00, 57353.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to CPE-Dataset-16 in yolov8:: 100%|██████████| 7003/7003 [00:00<00:00, 8763.15it/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets\n",
        "\n",
        "!pip install roboflow --quiet\n",
        "\n",
        "from roboflow import Roboflow\n",
        "!mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets\n",
        "\n",
        "!pip install roboflow --quiet\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"mZIPBax8HfLFLrAlPIiw\")\n",
        "project = rf.workspace(\"aitech-a6cge\").project(\"cpe-dataset\")\n",
        "version = project.version(16)\n",
        "dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "## Custom Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/ultralytics/ultralytics/nn/yolo_cam /content/ultralytics/ultralytics/nn/modules/"
      ],
      "metadata": {
        "id": "sQba_I3wjLdA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ttach\n",
        "\n",
        "# Verify installation\n",
        "import ttach"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgMqz56llNYm",
        "outputId": "cdefa1f6-d84b-4508-b766-aab3f55ae530"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ttach in /usr/local/lib/python3.11/dist-packages (0.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shPQihJE7_lY",
        "outputId": "e3f05707-cef4-4a9a-fda7-d3c671712137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.432      2.112       2.41         10        640:   5% 19/416 [00:04<01:21,  4.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.446      2.121      2.431          9        640:   5% 20/416 [00:04<01:19,  4.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.429      2.101      2.407         10        640:   5% 21/416 [00:04<01:17,  5.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.455      2.138      2.433         12        640:   5% 22/416 [00:04<01:13,  5.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.449      2.142      2.425         10        640:   6% 23/416 [00:05<01:18,  5.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.414      2.117      2.393          8        640:   6% 24/416 [00:05<01:20,  4.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.406      2.103      2.389          8        640:   6% 25/416 [00:05<01:14,  5.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G        1.4       2.09      2.376          9        640:   6% 26/416 [00:05<01:07,  5.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.417      2.105      2.385         11        640:   6% 27/416 [00:05<01:15,  5.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.385      2.086      2.353          8        640:   7% 28/416 [00:06<01:07,  5.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.395      2.082       2.36          9        640:   7% 29/416 [00:06<01:07,  5.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.408      2.088       2.37          9        640:   7% 30/416 [00:06<01:12,  5.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.412      2.088      2.379          7        640:   7% 31/416 [00:06<01:13,  5.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.398      2.071      2.365          8        640:   8% 32/416 [00:06<01:18,  4.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.384      2.065      2.348          8        640:   8% 33/416 [00:06<01:10,  5.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.386      2.074      2.347         11        640:   8% 34/416 [00:07<01:09,  5.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.391      2.068      2.349         10        640:   8% 35/416 [00:07<01:14,  5.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.376      2.055       2.34          8        640:   9% 36/416 [00:07<01:13,  5.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.378      2.045      2.343         10        640:   9% 37/416 [00:07<01:10,  5.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.381      2.037      2.348          9        640:   9% 38/416 [00:08<01:17,  4.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.374      2.026      2.342          9        640:   9% 39/416 [00:08<01:12,  5.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.375      2.029      2.346         10        640:  10% 40/416 [00:08<01:06,  5.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.367      2.025      2.341          9        640:  10% 41/416 [00:08<01:11,  5.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.362       2.03      2.341          9        640:  10% 42/416 [00:08<01:13,  5.07it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.358       2.03      2.339          8        640:  10% 43/416 [00:08<01:13,  5.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.37      2.059      2.356         14        640:  11% 44/416 [00:09<01:05,  5.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.378      2.063      2.357         11        640:  11% 45/416 [00:09<01:11,  5.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.376       2.06      2.356          9        640:  11% 46/416 [00:09<01:16,  4.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.364      2.057      2.344          9        640:  11% 47/416 [00:09<01:12,  5.07it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.366      2.056      2.348          9        640:  12% 48/416 [00:09<01:11,  5.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.371      2.054      2.356         11        640:  12% 49/416 [00:10<01:10,  5.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.354      2.042      2.341          8        640:  12% 50/416 [00:10<01:06,  5.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.35      2.037      2.335          9        640:  12% 51/416 [00:10<01:15,  4.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.35      2.036      2.335         10        640:  12% 52/416 [00:10<01:06,  5.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.352      2.032      2.337          9        640:  13% 53/416 [00:10<01:08,  5.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.355      2.027      2.344         10        640:  13% 54/416 [00:11<01:07,  5.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.348      2.019      2.339          9        640:  13% 55/416 [00:11<01:07,  5.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.343      2.018      2.338         10        640:  13% 56/416 [00:11<01:05,  5.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.347      2.021      2.343         11        640:  14% 57/416 [00:11<01:00,  5.98it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.352      2.025      2.347         10        640:  14% 58/416 [00:11<01:12,  4.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.349       2.02      2.346          8        640:  14% 59/416 [00:11<01:08,  5.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.354      2.024       2.35         11        640:  14% 60/416 [00:12<01:10,  5.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.341      2.016      2.338          8        640:  15% 61/416 [00:12<01:12,  4.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.332      2.004      2.327          8        640:  15% 62/416 [00:12<01:21,  4.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.33          2      2.326          9        640:  15% 63/416 [00:12<01:19,  4.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.323      1.999      2.316          9        640:  15% 64/416 [00:13<01:24,  4.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.319      1.993      2.312          9        640:  16% 65/416 [00:13<01:35,  3.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.322      2.001      2.316          9        640:  16% 66/416 [00:13<01:38,  3.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.327      2.001      2.325          9        640:  16% 67/416 [00:14<01:44,  3.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.322          2      2.318          8        640:  16% 68/416 [00:14<01:35,  3.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.316      1.994      2.313         10        640:  17% 69/416 [00:14<01:35,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.317      1.996      2.316         11        640:  17% 70/416 [00:15<01:42,  3.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.322      1.998       2.32          8        640:  17% 71/416 [00:15<01:46,  3.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.324      1.994      2.324          9        640:  17% 72/416 [00:15<01:40,  3.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.316      1.987      2.315          7        640:  18% 73/416 [00:15<01:48,  3.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.307      1.983      2.308          8        640:  18% 74/416 [00:16<01:35,  3.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.302      1.977      2.306          8        640:  18% 75/416 [00:16<01:32,  3.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.295      1.972      2.299          8        640:  18% 76/416 [00:16<01:18,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.292       1.97      2.296          8        640:  19% 77/416 [00:16<01:09,  4.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.293       1.97      2.298         10        640:  19% 78/416 [00:16<01:05,  5.13it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.295      1.973      2.301         10        640:  19% 79/416 [00:17<01:12,  4.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.295      1.973      2.302          9        640:  19% 80/416 [00:17<01:13,  4.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.297      1.979      2.304          9        640:  19% 81/416 [00:17<01:14,  4.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.975      2.297          8        640:  20% 82/416 [00:17<01:04,  5.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.283       1.97       2.29          9        640:  20% 83/416 [00:17<01:04,  5.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.284      1.971      2.291          9        640:  20% 84/416 [00:18<01:02,  5.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.291      1.973      2.297          8        640:  20% 85/416 [00:18<01:07,  4.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.284      1.971      2.291          9        640:  21% 86/416 [00:18<01:04,  5.13it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.29      1.971        2.3          9        640:  21% 87/416 [00:18<00:59,  5.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.973      2.298          7        640:  21% 88/416 [00:18<00:55,  5.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.29      1.972      2.299         10        640:  21% 89/416 [00:19<01:01,  5.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.291      1.975      2.298          9        640:  22% 90/416 [00:19<01:03,  5.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.291       1.97      2.298          9        640:  22% 91/416 [00:19<01:04,  5.07it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.294      1.971      2.298         10        640:  22% 92/416 [00:19<01:03,  5.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.291      1.967      2.296         10        640:  22% 93/416 [00:19<00:58,  5.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.291      1.967      2.293         10        640:  23% 94/416 [00:19<00:59,  5.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.291      1.966      2.293         10        640:  23% 95/416 [00:20<00:57,  5.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.294      1.967      2.296          9        640:  23% 96/416 [00:20<00:56,  5.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.965      2.292          8        640:  23% 97/416 [00:20<00:58,  5.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.29      1.965       2.29          9        640:  24% 98/416 [00:20<00:54,  5.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.964       2.29         11        640:  24% 99/416 [00:20<01:00,  5.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.287      1.961      2.289          8        640:  24% 100/416 [00:21<01:04,  4.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.29      1.964      2.288         12        640:  24% 101/416 [00:21<01:06,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.294      1.967      2.293          9        640:  25% 102/416 [00:21<00:58,  5.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.296      1.971      2.296          9        640:  25% 103/416 [00:21<01:02,  5.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.299      1.973      2.302          7        640:  25% 104/416 [00:21<01:01,  5.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.292       1.97      2.295          8        640:  25% 105/416 [00:22<00:58,  5.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.291      1.971      2.292          9        640:  25% 106/416 [00:22<00:58,  5.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.972       2.29          6        640:  26% 107/416 [00:22<01:02,  4.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.294      1.973      2.294         10        640:  26% 108/416 [00:22<00:57,  5.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G        1.3      1.976      2.297         10        640:  26% 109/416 [00:22<00:58,  5.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.297      1.972      2.292          9        640:  26% 110/416 [00:22<00:54,  5.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.295      1.969       2.29         10        640:  27% 111/416 [00:23<00:52,  5.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.299      1.969      2.293          9        640:  27% 112/416 [00:23<00:53,  5.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.298       1.97      2.293          9        640:  27% 113/416 [00:23<00:55,  5.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.299      1.973      2.293         10        640:  27% 114/416 [00:23<00:57,  5.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.299      1.977      2.294         10        640:  28% 115/416 [00:23<00:58,  5.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.301      1.978      2.295          9        640:  28% 116/416 [00:24<00:54,  5.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.307      1.981        2.3         10        640:  28% 117/416 [00:24<00:50,  5.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.305      1.984      2.298          9        640:  28% 118/416 [00:24<01:01,  4.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.305      1.983      2.297         10        640:  29% 119/416 [00:24<00:57,  5.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.304      1.988      2.298          9        640:  29% 120/416 [00:24<00:56,  5.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.299      1.987      2.293          8        640:  29% 121/416 [00:25<01:02,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.302      1.992      2.296         10        640:  29% 122/416 [00:25<00:55,  5.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306      1.997      2.298          9        640:  30% 123/416 [00:25<01:01,  4.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.305      1.998      2.298         10        640:  30% 124/416 [00:25<01:01,  4.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.301      1.996      2.294          9        640:  30% 125/416 [00:25<00:54,  5.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.296      1.994       2.29          8        640:  30% 126/416 [00:26<00:50,  5.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G        1.3      1.995      2.294         10        640:  31% 127/416 [00:26<01:02,  4.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.304      1.994      2.299          8        640:  31% 128/416 [00:26<01:01,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.307      1.999      2.301         10        640:  31% 129/416 [00:26<01:10,  4.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306      1.998        2.3          9        640:  31% 130/416 [00:27<01:13,  3.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306          2        2.3          9        640:  31% 131/416 [00:27<01:21,  3.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.302          2      2.296          8        640:  32% 132/416 [00:27<01:16,  3.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.299          2      2.293          9        640:  32% 133/416 [00:28<01:24,  3.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.296      1.997       2.29          8        640:  32% 134/416 [00:28<01:19,  3.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.292      1.994      2.286          8        640:  32% 135/416 [00:28<01:14,  3.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.29      1.994      2.283         10        640:  33% 136/416 [00:28<01:25,  3.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.29      1.995      2.284          8        640:  33% 137/416 [00:29<01:15,  3.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.292      1.995      2.286         10        640:  33% 138/416 [00:29<01:20,  3.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.294      1.996      2.289         10        640:  33% 139/416 [00:29<01:19,  3.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.304      2.003      2.298         15        640:  34% 140/416 [00:29<01:13,  3.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.299      1.999      2.293          8        640:  34% 141/416 [00:30<01:17,  3.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.301      2.003      2.296         10        640:  34% 142/416 [00:30<01:08,  4.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      2.005      2.298          9        640:  34% 143/416 [00:30<01:07,  4.01it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306      2.006        2.3         10        640:  35% 144/416 [00:30<01:03,  4.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306      2.004      2.301          8        640:  35% 145/416 [00:31<01:02,  4.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306      2.003        2.3          9        640:  35% 146/416 [00:31<01:00,  4.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306      2.003      2.301          9        640:  35% 147/416 [00:31<01:02,  4.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.308      2.003      2.304          9        640:  36% 148/416 [00:31<00:53,  4.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.31      2.005      2.305          9        640:  36% 149/416 [00:31<00:50,  5.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.308      2.005      2.304         10        640:  36% 150/416 [00:32<00:52,  5.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306      2.002      2.303          9        640:  36% 151/416 [00:32<00:51,  5.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.307      2.003      2.306         11        640:  37% 152/416 [00:32<00:56,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.31      2.004       2.31          8        640:  37% 153/416 [00:32<00:54,  4.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.311      2.003       2.31          9        640:  37% 154/416 [00:32<00:53,  4.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.308      2.002      2.306          8        640:  37% 155/416 [00:33<01:01,  4.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.309      2.003      2.306         10        640:  38% 156/416 [00:33<00:52,  4.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.316      2.006      2.311         13        640:  38% 157/416 [00:33<00:52,  4.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.315       2.01      2.311         11        640:  38% 158/416 [00:33<00:48,  5.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.314      2.009      2.309          9        640:  38% 159/416 [00:33<00:51,  5.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.317      2.009      2.314          9        640:  38% 160/416 [00:34<00:45,  5.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.315      2.006      2.312          8        640:  39% 161/416 [00:34<00:53,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.312      2.004      2.309          9        640:  39% 162/416 [00:34<00:48,  5.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.312      2.002      2.309         12        640:  39% 163/416 [00:34<00:48,  5.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.313      2.002      2.311         10        640:  39% 164/416 [00:34<00:49,  5.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.311      1.999      2.308          8        640:  40% 165/416 [00:35<00:49,  5.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.314      2.002      2.312         13        640:  40% 166/416 [00:35<00:52,  4.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.311      1.998      2.308          8        640:  40% 167/416 [00:35<00:46,  5.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.313          2      2.309          8        640:  40% 168/416 [00:35<00:47,  5.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.31      1.997      2.306          8        640:  41% 169/416 [00:35<00:45,  5.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.311      1.996      2.308          9        640:  41% 170/416 [00:36<00:46,  5.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.311      1.994      2.308          9        640:  41% 171/416 [00:36<00:51,  4.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.308      1.991      2.305          8        640:  41% 172/416 [00:36<00:52,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.314      1.996      2.311         13        640:  42% 173/416 [00:36<00:50,  4.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.317      1.997      2.314         11        640:  42% 174/416 [00:36<00:51,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.313      1.994       2.31          9        640:  42% 175/416 [00:37<00:50,  4.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.311      1.992      2.308          8        640:  42% 176/416 [00:37<00:48,  4.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.317      1.994      2.314         11        640:  43% 177/416 [00:37<00:46,  5.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.317      1.994      2.314          9        640:  43% 178/416 [00:37<00:43,  5.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.315      1.991      2.313          8        640:  43% 179/416 [00:37<00:45,  5.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.314      1.992      2.313          8        640:  43% 180/416 [00:38<00:41,  5.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.309       1.99      2.309          7        640:  44% 181/416 [00:38<00:41,  5.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.31      1.989      2.309          8        640:  44% 182/416 [00:38<00:45,  5.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.31       1.99       2.31          8        640:  44% 183/416 [00:38<00:43,  5.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.311      1.991       2.31         10        640:  44% 184/416 [00:38<00:43,  5.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.31      1.989      2.309         12        640:  44% 185/416 [00:39<00:45,  5.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.308      1.989      2.308          9        640:  45% 186/416 [00:39<00:46,  4.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.308      1.988      2.309          9        640:  45% 187/416 [00:39<00:48,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      1.986      2.305          7        640:  45% 188/416 [00:39<00:47,  4.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306       1.99      2.308         12        640:  45% 189/416 [00:39<00:41,  5.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.311      1.997      2.311         15        640:  46% 190/416 [00:39<00:41,  5.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.309      1.995       2.31          7        640:  46% 191/416 [00:40<00:41,  5.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.309      1.994       2.31          9        640:  46% 192/416 [00:40<00:46,  4.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.31      1.992      2.311          9        640:  46% 193/416 [00:40<00:49,  4.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.308      1.993       2.31          7        640:  47% 194/416 [00:40<00:51,  4.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.308      1.996       2.31          8        640:  47% 195/416 [00:41<00:57,  3.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.307      1.992      2.309          8        640:  47% 196/416 [00:41<00:56,  3.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.304      1.991      2.306          6        640:  47% 197/416 [00:41<01:00,  3.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.302      1.988      2.304         10        640:  48% 198/416 [00:42<01:01,  3.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      1.989      2.304         10        640:  48% 199/416 [00:42<00:58,  3.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.304      1.989      2.306          9        640:  48% 200/416 [00:42<01:03,  3.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306      1.991      2.308          8        640:  48% 201/416 [00:42<00:59,  3.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306      1.991      2.308         10        640:  49% 202/416 [00:43<00:59,  3.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.307      1.991      2.309          7        640:  49% 203/416 [00:43<01:01,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.307      1.992      2.309         10        640:  49% 204/416 [00:43<00:58,  3.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306      1.991      2.308          9        640:  49% 205/416 [00:44<00:55,  3.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.305      1.988      2.307          9        640:  50% 206/416 [00:44<00:51,  4.05it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      1.987      2.305          9        640:  50% 207/416 [00:44<00:45,  4.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.305      1.991      2.307         17        640:  50% 208/416 [00:44<00:40,  5.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      1.989      2.306          9        640:  50% 209/416 [00:44<00:43,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      1.987      2.304         10        640:  50% 210/416 [00:44<00:41,  4.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.301      1.986      2.302          8        640:  51% 211/416 [00:45<00:44,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.305       1.99      2.305         10        640:  51% 212/416 [00:45<00:39,  5.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.307      1.991      2.306         11        640:  51% 213/416 [00:45<00:38,  5.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.308      1.991      2.305         11        640:  51% 214/416 [00:45<00:40,  5.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.309      1.994      2.305         12        640:  52% 215/416 [00:45<00:39,  5.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.309      1.996      2.305         11        640:  52% 216/416 [00:46<00:34,  5.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.311      1.996      2.307         11        640:  52% 217/416 [00:46<00:40,  4.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.311      1.997      2.307          9        640:  52% 218/416 [00:46<00:43,  4.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.311      1.998      2.308          8        640:  53% 219/416 [00:46<00:41,  4.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.313      1.998      2.308         10        640:  53% 220/416 [00:46<00:37,  5.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.312      1.998      2.308          9        640:  53% 221/416 [00:47<00:37,  5.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.313      1.999      2.308         10        640:  53% 222/416 [00:47<00:41,  4.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.313          2      2.308          9        640:  54% 223/416 [00:47<00:36,  5.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.312          2      2.306          9        640:  54% 224/416 [00:47<00:40,  4.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.314          2      2.309         10        640:  54% 225/416 [00:48<00:40,  4.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.312      1.999      2.306          8        640:  54% 226/416 [00:48<00:38,  4.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.312      1.996      2.305          7        640:  55% 227/416 [00:48<00:39,  4.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.312      1.996      2.305         10        640:  55% 228/416 [00:48<00:36,  5.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.315      1.997      2.309         10        640:  55% 229/416 [00:48<00:32,  5.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.315      1.998       2.31         10        640:  55% 230/416 [00:48<00:38,  4.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.314      1.997      2.308          7        640:  56% 231/416 [00:49<00:36,  5.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.311      1.995      2.306          9        640:  56% 232/416 [00:49<00:36,  5.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.311      1.996      2.306          9        640:  56% 233/416 [00:49<00:33,  5.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.31      1.993      2.304          9        640:  56% 234/416 [00:49<00:33,  5.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.308      1.991      2.303          8        640:  56% 235/416 [00:49<00:32,  5.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.309      1.992      2.304          9        640:  57% 236/416 [00:50<00:34,  5.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.31      1.992      2.304          8        640:  57% 237/416 [00:50<00:34,  5.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.309      1.991      2.303          9        640:  57% 238/416 [00:50<00:35,  5.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.309      1.991      2.302         10        640:  57% 239/416 [00:50<00:31,  5.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.308      1.989      2.302          8        640:  58% 240/416 [00:50<00:31,  5.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306      1.989      2.299         10        640:  58% 241/416 [00:51<00:34,  5.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.304      1.988      2.297          8        640:  58% 242/416 [00:51<00:31,  5.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.305      1.989      2.298         11        640:  58% 243/416 [00:51<00:40,  4.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.307      1.988        2.3         10        640:  59% 244/416 [00:51<00:35,  4.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306      1.989        2.3         11        640:  59% 245/416 [00:51<00:37,  4.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306      1.989        2.3          9        640:  59% 246/416 [00:52<00:37,  4.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.308       1.99      2.301         11        640:  59% 247/416 [00:52<00:36,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.305      1.989      2.298          8        640:  60% 248/416 [00:52<00:32,  5.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.305      1.989      2.297          8        640:  60% 249/416 [00:52<00:33,  4.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.305       1.99      2.298          9        640:  60% 250/416 [00:52<00:32,  5.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.304      1.989      2.297          8        640:  60% 251/416 [00:53<00:34,  4.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.301      1.987      2.294          8        640:  61% 252/416 [00:53<00:32,  5.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.301      1.989      2.295         12        640:  61% 253/416 [00:53<00:35,  4.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G        1.3      1.989      2.294          9        640:  61% 254/416 [00:53<00:34,  4.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.301       1.99      2.294          9        640:  61% 255/416 [00:54<00:35,  4.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.302      1.991      2.294          7        640:  62% 256/416 [00:54<00:38,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.299       1.99      2.292          8        640:  62% 257/416 [00:54<00:43,  3.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.298      1.988       2.29         10        640:  62% 258/416 [00:54<00:39,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.298      1.987       2.29         10        640:  62% 259/416 [00:55<00:45,  3.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G        1.3      1.989      2.292         10        640:  62% 260/416 [00:55<00:44,  3.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      1.992      2.295         11        640:  63% 261/416 [00:55<00:43,  3.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      1.994      2.294         10        640:  63% 262/416 [00:56<00:42,  3.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.304      1.995      2.297          9        640:  63% 263/416 [00:56<00:47,  3.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      1.995      2.296          7        640:  63% 264/416 [00:56<00:43,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.305      1.997      2.296         11        640:  64% 265/416 [00:56<00:43,  3.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306          2      2.298         11        640:  64% 266/416 [00:57<00:45,  3.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.306      1.999      2.299         10        640:  64% 267/416 [00:57<00:47,  3.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.305      1.998      2.298         11        640:  64% 268/416 [00:57<00:41,  3.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      1.996      2.296          8        640:  65% 269/416 [00:58<00:39,  3.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.304      1.997      2.297          8        640:  65% 270/416 [00:58<00:33,  4.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.302      1.996      2.296          9        640:  65% 271/416 [00:58<00:37,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.301      1.995      2.294          8        640:  65% 272/416 [00:58<00:35,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G        1.3      1.995      2.292         11        640:  66% 273/416 [00:58<00:32,  4.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G        1.3      1.993      2.292          8        640:  66% 274/416 [00:59<00:31,  4.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.299      1.992      2.291          8        640:  66% 275/416 [00:59<00:29,  4.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G        1.3      1.992      2.293          9        640:  66% 276/416 [00:59<00:28,  4.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.302      1.993      2.295         10        640:  67% 277/416 [00:59<00:31,  4.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.305      1.994      2.298         13        640:  67% 278/416 [00:59<00:29,  4.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.304      1.993      2.296          9        640:  67% 279/416 [01:00<00:28,  4.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      1.993      2.295          9        640:  67% 280/416 [01:00<00:26,  5.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      1.992      2.295          9        640:  68% 281/416 [01:00<00:23,  5.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.304      1.991      2.295          9        640:  68% 282/416 [01:00<00:26,  5.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      1.992      2.295          9        640:  68% 283/416 [01:00<00:28,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      1.992      2.294          8        640:  68% 284/416 [01:01<00:28,  4.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.302      1.992      2.293         10        640:  69% 285/416 [01:01<00:28,  4.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.301       1.99      2.292          9        640:  69% 286/416 [01:01<00:27,  4.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.302      1.991      2.293         13        640:  69% 287/416 [01:01<00:25,  5.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      1.992      2.295          9        640:  69% 288/416 [01:02<00:29,  4.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      1.992      2.295          9        640:  69% 289/416 [01:02<00:25,  4.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.303      1.991      2.294          9        640:  70% 290/416 [01:02<00:23,  5.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.304      1.991      2.294          9        640:  70% 291/416 [01:02<00:23,  5.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.302       1.99      2.293         10        640:  70% 292/416 [01:02<00:24,  5.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.301      1.989      2.293         10        640:  70% 293/416 [01:03<00:24,  4.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.301      1.986      2.292          8        640:  71% 294/416 [01:03<00:23,  5.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G        1.3      1.985      2.291          8        640:  71% 295/416 [01:03<00:24,  4.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.301      1.985      2.292         10        640:  71% 296/416 [01:03<00:22,  5.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.301      1.985      2.293          8        640:  71% 297/416 [01:03<00:21,  5.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.302      1.987      2.293         10        640:  72% 298/416 [01:03<00:20,  5.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.302      1.986      2.293          9        640:  72% 299/416 [01:04<00:25,  4.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G        1.3      1.986      2.292          8        640:  72% 300/416 [01:04<00:22,  5.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G        1.3      1.985      2.293         10        640:  72% 301/416 [01:04<00:20,  5.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.299      1.984      2.292          8        640:  73% 302/416 [01:04<00:20,  5.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.297      1.983       2.29          8        640:  73% 303/416 [01:04<00:21,  5.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.298      1.984      2.291          9        640:  73% 304/416 [01:05<00:23,  4.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.299      1.983      2.292         10        640:  73% 305/416 [01:05<00:24,  4.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.298      1.983      2.292          9        640:  74% 306/416 [01:05<00:21,  5.12it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.296      1.982       2.29          8        640:  74% 307/416 [01:05<00:21,  5.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.297      1.985      2.292         16        640:  74% 308/416 [01:05<00:19,  5.47it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.298      1.984      2.292         10        640:  74% 309/416 [01:06<00:20,  5.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.297      1.983      2.292          8        640:  75% 310/416 [01:06<00:21,  5.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.296      1.983       2.29          9        640:  75% 311/416 [01:06<00:22,  4.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.296      1.983      2.289          9        640:  75% 312/416 [01:06<00:24,  4.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.294      1.981      2.287          8        640:  75% 313/416 [01:06<00:21,  4.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.296      1.982      2.288         13        640:  75% 314/416 [01:07<00:20,  4.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.296      1.982      2.289         12        640:  76% 315/416 [01:07<00:20,  4.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.297      1.982      2.289          8        640:  76% 316/416 [01:07<00:21,  4.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.296      1.981      2.289          9        640:  76% 317/416 [01:07<00:21,  4.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.297      1.981      2.288         10        640:  76% 318/416 [01:08<00:23,  4.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.296       1.98      2.287          9        640:  77% 319/416 [01:08<00:23,  4.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.296      1.979      2.288         10        640:  77% 320/416 [01:08<00:25,  3.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.297       1.98       2.29          9        640:  77% 321/416 [01:08<00:23,  3.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.297      1.978       2.29         10        640:  77% 322/416 [01:09<00:25,  3.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.298      1.979       2.29          7        640:  78% 323/416 [01:09<00:28,  3.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G        1.3       1.98      2.292          8        640:  78% 324/416 [01:09<00:25,  3.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.298      1.978      2.291          8        640:  78% 325/416 [01:10<00:26,  3.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.298      1.977      2.291          9        640:  78% 326/416 [01:10<00:26,  3.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.298      1.976      2.291          9        640:  79% 327/416 [01:10<00:26,  3.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.298      1.975       2.29          7        640:  79% 328/416 [01:10<00:23,  3.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.298      1.975       2.29          8        640:  79% 329/416 [01:11<00:23,  3.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.296      1.974      2.289          9        640:  79% 330/416 [01:11<00:24,  3.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.295      1.973      2.288          8        640:  80% 331/416 [01:11<00:22,  3.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.294      1.971      2.286          9        640:  80% 332/416 [01:11<00:20,  4.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.293      1.971      2.286          8        640:  80% 333/416 [01:12<00:19,  4.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.293      1.969      2.287          9        640:  80% 334/416 [01:12<00:18,  4.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.291      1.968      2.285          8        640:  81% 335/416 [01:12<00:18,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.291      1.967      2.284          9        640:  81% 336/416 [01:12<00:16,  4.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.965      2.283          8        640:  81% 337/416 [01:12<00:16,  4.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.964      2.282          9        640:  81% 338/416 [01:13<00:16,  4.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.29      1.964      2.282         11        640:  81% 339/416 [01:13<00:16,  4.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.964      2.282         10        640:  82% 340/416 [01:13<00:15,  5.05it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.963      2.281         10        640:  82% 341/416 [01:13<00:15,  4.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.962      2.281          8        640:  82% 342/416 [01:14<00:15,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.961      2.281          9        640:  82% 343/416 [01:14<00:13,  5.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.29       1.96      2.282         10        640:  83% 344/416 [01:14<00:14,  4.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.959      2.281          9        640:  83% 345/416 [01:14<00:15,  4.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.29       1.96      2.283          8        640:  83% 346/416 [01:14<00:14,  4.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.288      1.958       2.28          7        640:  83% 347/416 [01:15<00:14,  4.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.288      1.958       2.28         10        640:  84% 348/416 [01:15<00:14,  4.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.288      1.957       2.28         10        640:  84% 349/416 [01:15<00:13,  4.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.957      2.282          9        640:  84% 350/416 [01:15<00:14,  4.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.957      2.282         10        640:  84% 351/416 [01:15<00:13,  4.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.957      2.283          9        640:  85% 352/416 [01:16<00:12,  4.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.957      2.282          8        640:  85% 353/416 [01:16<00:12,  5.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.956      2.282         10        640:  85% 354/416 [01:16<00:13,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.289      1.956      2.282          9        640:  85% 355/416 [01:16<00:15,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.287      1.955       2.28          9        640:  86% 356/416 [01:17<00:13,  4.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.287      1.954       2.28          8        640:  86% 357/416 [01:17<00:11,  5.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.287      1.955       2.28         10        640:  86% 358/416 [01:17<00:12,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.287      1.955      2.279          8        640:  86% 359/416 [01:17<00:12,  4.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.287      1.954      2.279         11        640:  87% 360/416 [01:17<00:12,  4.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.286      1.953      2.277          9        640:  87% 361/416 [01:18<00:10,  5.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.286      1.953      2.278          9        640:  87% 362/416 [01:18<00:10,  5.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.286      1.954      2.278          9        640:  87% 363/416 [01:18<00:09,  5.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.287      1.953      2.278          9        640:  88% 364/416 [01:18<00:11,  4.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.287      1.954      2.278         10        640:  88% 365/416 [01:18<00:10,  4.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.285      1.952      2.276          9        640:  88% 366/416 [01:19<00:10,  4.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.285      1.951      2.276          9        640:  88% 367/416 [01:19<00:09,  5.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.286      1.952      2.275         11        640:  88% 368/416 [01:19<00:09,  5.13it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.287      1.954      2.276         13        640:  89% 369/416 [01:19<00:08,  5.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.286      1.953      2.275          9        640:  89% 370/416 [01:19<00:09,  4.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.286      1.952      2.274          9        640:  89% 371/416 [01:19<00:08,  5.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.286      1.952      2.274         10        640:  89% 372/416 [01:20<00:08,  4.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.288      1.954      2.276         12        640:  90% 373/416 [01:20<00:08,  4.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.286      1.954      2.275          7        640:  90% 374/416 [01:20<00:08,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.286      1.952      2.275          8        640:  90% 375/416 [01:20<00:07,  5.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.285      1.952      2.274          8        640:  90% 376/416 [01:20<00:07,  5.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.284      1.951      2.273          9        640:  91% 377/416 [01:21<00:07,  5.05it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.284      1.951      2.273          9        640:  91% 378/416 [01:21<00:06,  5.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.284       1.95      2.273         10        640:  91% 379/416 [01:21<00:09,  3.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.285      1.951      2.274          8        640:  91% 380/416 [01:22<00:08,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.283      1.949      2.272          8        640:  92% 381/416 [01:22<00:09,  3.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.283      1.949      2.271          9        640:  92% 382/416 [01:22<00:08,  3.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.283       1.95      2.271          8        640:  92% 383/416 [01:22<00:09,  3.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.281      1.948      2.269          8        640:  92% 384/416 [01:23<00:09,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.282      1.948      2.269          9        640:  93% 385/416 [01:23<00:09,  3.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.281      1.947      2.269          9        640:  93% 386/416 [01:23<00:08,  3.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.282      1.948       2.27         10        640:  93% 387/416 [01:24<00:09,  3.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.281      1.948      2.269          9        640:  93% 388/416 [01:24<00:08,  3.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.281      1.948      2.268          9        640:  94% 389/416 [01:24<00:07,  3.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.281      1.947      2.269          9        640:  94% 390/416 [01:24<00:07,  3.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.282      1.947      2.271          9        640:  94% 391/416 [01:25<00:07,  3.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.282      1.946      2.271          9        640:  94% 392/416 [01:25<00:06,  3.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.282      1.946      2.271          8        640:  94% 393/416 [01:25<00:05,  3.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.281      1.945       2.27          8        640:  95% 394/416 [01:25<00:05,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.28      1.944      2.269          8        640:  95% 395/416 [01:26<00:05,  3.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.281      1.944      2.271          8        640:  95% 396/416 [01:26<00:05,  3.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.283      1.947      2.273         16        640:  95% 397/416 [01:26<00:04,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.283      1.946      2.272          8        640:  96% 398/416 [01:26<00:03,  4.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.282      1.946      2.271         10        640:  96% 399/416 [01:26<00:03,  5.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.283      1.945      2.271         10        640:  96% 400/416 [01:27<00:03,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.283      1.946      2.271         10        640:  96% 401/416 [01:27<00:02,  5.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.283      1.946      2.271          8        640:  97% 402/416 [01:27<00:03,  4.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.283      1.947      2.271         11        640:  97% 403/416 [01:27<00:02,  4.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.283      1.947      2.271         10        640:  97% 404/416 [01:28<00:02,  4.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.281      1.946      2.269          8        640:  97% 405/416 [01:28<00:02,  5.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.28      1.945      2.268          6        640:  98% 406/416 [01:28<00:01,  5.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.28      1.944      2.268         10        640:  98% 407/416 [01:28<00:01,  4.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.279      1.943      2.267          8        640:  98% 408/416 [01:28<00:01,  5.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.279      1.943      2.266         10        640:  98% 409/416 [01:28<00:01,  5.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.28      1.943      2.267          8        640:  99% 410/416 [01:29<00:01,  4.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.281      1.943      2.267          8        640:  99% 411/416 [01:29<00:01,  4.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.28      1.943      2.267          8        640:  99% 412/416 [01:29<00:00,  5.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.281      1.942      2.267         10        640:  99% 413/416 [01:29<00:00,  5.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G       1.28      1.942      2.266          8        640: 100% 414/416 [01:30<00:00,  4.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.281      1.942      2.267         10        640: 100% 415/416 [01:30<00:00,  4.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       5/10      1.36G      1.281      1.942      2.268          4        640: 100% 416/416 [01:30<00:00,  4.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 11/11 [00:01<00:00,  6.13it/s]\n",
            "                   all        174        200      0.272      0.548      0.358      0.246\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/416 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G     0.7896      1.293       1.88         10        640:   0% 1/416 [00:00<01:24,  4.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G     0.8302      1.674      1.859          9        640:   0% 2/416 [00:00<01:22,  5.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.099      1.839      1.992         11        640:   1% 3/416 [00:00<01:35,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.139      1.957       2.05         11        640:   1% 4/416 [00:00<01:23,  4.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.162      1.899      2.074          8        640:   1% 5/416 [00:00<01:12,  5.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.259      1.985      2.151         10        640:   1% 6/416 [00:01<01:18,  5.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G        1.2      1.984      2.098          9        640:   2% 7/416 [00:01<01:18,  5.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.249      2.022      2.144         12        640:   2% 8/416 [00:01<01:18,  5.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.165      1.959       2.06          8        640:   2% 9/416 [00:01<01:25,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.168       1.96      2.055         11        640:   2% 10/416 [00:02<01:27,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.143      1.918      2.036          8        640:   3% 11/416 [00:02<01:21,  4.98it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.179      1.922      2.089         10        640:   3% 12/416 [00:02<01:13,  5.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.153      1.894      2.069          9        640:   3% 13/416 [00:02<01:15,  5.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.103      1.857       2.02          8        640:   3% 14/416 [00:02<01:19,  5.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.115      1.839      2.031         10        640:   4% 15/416 [00:03<01:28,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G       1.12       1.82      2.036          9        640:   4% 16/416 [00:03<01:33,  4.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.122      1.809      2.038          9        640:   4% 17/416 [00:03<01:40,  3.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.122      1.808      2.041          9        640:   4% 18/416 [00:03<01:43,  3.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.099      1.781      2.022          8        640:   5% 19/416 [00:04<01:52,  3.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.091      1.773      2.015          9        640:   5% 20/416 [00:04<01:45,  3.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.081      1.758      2.013          8        640:   5% 21/416 [00:04<01:48,  3.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.36G      1.072      1.738      2.014          9        640:   5% 22/416 [00:05<01:48,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.085      1.751      2.028         10        640:   6% 23/416 [00:05<01:49,  3.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.105       1.75      2.056          7        640:   6% 24/416 [00:05<01:53,  3.47it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.115       1.75      2.068          8        640:   6% 25/416 [00:05<01:44,  3.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.116       1.74      2.075          9        640:   6% 26/416 [00:06<01:47,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.114      1.733      2.068         10        640:   6% 27/416 [00:06<02:02,  3.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.102      1.726       2.06          9        640:   7% 28/416 [00:06<01:55,  3.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.098      1.729      2.054         10        640:   7% 29/416 [00:06<01:43,  3.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.102      1.726      2.054          9        640:   7% 30/416 [00:07<01:45,  3.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.105       1.72      2.064          9        640:   7% 31/416 [00:07<01:36,  3.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.096      1.715      2.056          9        640:   8% 32/416 [00:07<01:36,  3.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G        1.1      1.717      2.057          9        640:   8% 33/416 [00:07<01:36,  3.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.115      1.718      2.076          9        640:   8% 34/416 [00:08<01:34,  4.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.107      1.713      2.072          9        640:   8% 35/416 [00:08<01:44,  3.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.11      1.721      2.074         10        640:   9% 36/416 [00:08<01:41,  3.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G        1.1      1.719      2.062          8        640:   9% 37/416 [00:08<01:32,  4.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.103      1.719      2.064          8        640:   9% 38/416 [00:09<01:32,  4.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.103      1.712      2.065         10        640:   9% 39/416 [00:09<01:19,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.111      1.712      2.072         10        640:  10% 40/416 [00:09<01:17,  4.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.108      1.719      2.068          9        640:  10% 41/416 [00:09<01:09,  5.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.113      1.724      2.075          9        640:  10% 42/416 [00:09<01:05,  5.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.105      1.719      2.066          9        640:  10% 43/416 [00:10<01:19,  4.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.099      1.714      2.058         10        640:  11% 44/416 [00:10<01:17,  4.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.109      1.724      2.064         11        640:  11% 45/416 [00:10<01:18,  4.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.108      1.722      2.061          8        640:  11% 46/416 [00:10<01:12,  5.13it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.122      1.742      2.075         12        640:  11% 47/416 [00:10<01:05,  5.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.118      1.739      2.071          9        640:  12% 48/416 [00:11<01:07,  5.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.124      1.749      2.073         15        640:  12% 49/416 [00:11<01:15,  4.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.128      1.761      2.081         14        640:  12% 50/416 [00:11<01:09,  5.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.141      1.769      2.092         13        640:  12% 51/416 [00:11<01:24,  4.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.131      1.767      2.083          8        640:  12% 52/416 [00:11<01:13,  4.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.123      1.765      2.078          9        640:  13% 53/416 [00:12<01:14,  4.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.125      1.766      2.081          9        640:  13% 54/416 [00:12<01:13,  4.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.117      1.764      2.072          9        640:  13% 55/416 [00:12<01:10,  5.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.117      1.761      2.073          9        640:  13% 56/416 [00:12<01:13,  4.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.113      1.758      2.071         10        640:  14% 57/416 [00:12<01:08,  5.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.105      1.756      2.062          9        640:  14% 58/416 [00:13<01:01,  5.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.099      1.758      2.054          7        640:  14% 59/416 [00:13<01:20,  4.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.112      1.763      2.067          8        640:  14% 60/416 [00:13<01:10,  5.07it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.12      1.764      2.071         10        640:  15% 61/416 [00:13<01:04,  5.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.123      1.765      2.074          9        640:  15% 62/416 [00:13<01:16,  4.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.122      1.768      2.074         10        640:  15% 63/416 [00:14<01:12,  4.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.118      1.773      2.073          9        640:  15% 64/416 [00:14<01:13,  4.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.117      1.766      2.074          9        640:  16% 65/416 [00:14<01:13,  4.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.123      1.764      2.081          9        640:  16% 66/416 [00:14<01:06,  5.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.117      1.758      2.076          7        640:  16% 67/416 [00:14<01:16,  4.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.118      1.754      2.079          8        640:  16% 68/416 [00:15<01:07,  5.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.125      1.761      2.086         12        640:  17% 69/416 [00:15<01:11,  4.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.121       1.76      2.082          9        640:  17% 70/416 [00:15<01:03,  5.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.126      1.759      2.084          9        640:  17% 71/416 [00:15<01:00,  5.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.125      1.763      2.083         10        640:  17% 72/416 [00:15<01:05,  5.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.118      1.761      2.074          8        640:  18% 73/416 [00:16<01:09,  4.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.122      1.764       2.08         10        640:  18% 74/416 [00:16<01:12,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.127      1.765      2.085         10        640:  18% 75/416 [00:16<01:12,  4.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.136      1.767      2.092          9        640:  18% 76/416 [00:16<01:15,  4.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.139      1.769      2.094          9        640:  19% 77/416 [00:17<01:21,  4.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.136      1.769      2.091          9        640:  19% 78/416 [00:17<01:26,  3.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.141      1.769      2.092          9        640:  19% 79/416 [00:17<01:32,  3.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.138      1.768      2.091          8        640:  19% 80/416 [00:18<01:37,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.146       1.77      2.095         11        640:  19% 81/416 [00:18<01:27,  3.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.147      1.768      2.095          9        640:  20% 82/416 [00:18<01:33,  3.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.143      1.769      2.093          8        640:  20% 83/416 [00:18<01:44,  3.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.144       1.77      2.094         10        640:  20% 84/416 [00:19<01:31,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.776      2.105         10        640:  20% 85/416 [00:19<01:38,  3.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.151      1.774      2.106          9        640:  21% 86/416 [00:19<01:34,  3.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.156      1.776      2.106         10        640:  21% 87/416 [00:20<01:40,  3.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.161      1.778       2.11         10        640:  21% 88/416 [00:20<01:42,  3.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.161       1.78       2.11         11        640:  21% 89/416 [00:20<01:32,  3.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.165      1.779      2.114         11        640:  22% 90/416 [00:20<01:32,  3.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.161       1.78      2.111          8        640:  22% 91/416 [00:21<01:24,  3.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163      1.791      2.115         13        640:  22% 92/416 [00:21<01:16,  4.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.16       1.79      2.114          9        640:  22% 93/416 [00:21<01:21,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163       1.79      2.117         10        640:  23% 94/416 [00:21<01:17,  4.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162      1.786      2.116          9        640:  23% 95/416 [00:22<01:15,  4.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.16      1.786      2.114          9        640:  23% 96/416 [00:22<01:15,  4.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.166       1.79      2.119         12        640:  23% 97/416 [00:22<01:09,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162      1.787      2.115          9        640:  24% 98/416 [00:22<01:00,  5.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.158      1.787      2.111          9        640:  24% 99/416 [00:22<01:13,  4.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.16       1.79      2.113         10        640:  24% 100/416 [00:23<01:07,  4.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.161      1.788      2.113         10        640:  24% 101/416 [00:23<01:11,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.165      1.794      2.118         12        640:  25% 102/416 [00:23<01:10,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.166      1.793      2.118          9        640:  25% 103/416 [00:23<01:01,  5.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.164      1.792      2.116          8        640:  25% 104/416 [00:23<01:08,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163      1.794      2.116          7        640:  25% 105/416 [00:24<00:59,  5.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.161      1.795      2.115          8        640:  25% 106/416 [00:24<01:06,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.795      2.121         10        640:  26% 107/416 [00:24<01:06,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.165      1.794      2.119          9        640:  26% 108/416 [00:24<01:04,  4.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.797      2.124          8        640:  26% 109/416 [00:25<01:09,  4.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.171      1.798      2.128          9        640:  26% 110/416 [00:25<01:03,  4.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.172        1.8      2.127         12        640:  27% 111/416 [00:25<00:56,  5.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.172      1.797      2.126          8        640:  27% 112/416 [00:25<01:01,  4.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.177      1.798       2.13          9        640:  27% 113/416 [00:25<01:00,  5.01it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.176        1.8       2.13          9        640:  27% 114/416 [00:25<01:04,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.174      1.798      2.128          9        640:  28% 115/416 [00:26<01:08,  4.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.173      1.798      2.125         10        640:  28% 116/416 [00:26<01:06,  4.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.174      1.797      2.126         10        640:  28% 117/416 [00:26<01:08,  4.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.175      1.794      2.126         10        640:  28% 118/416 [00:26<01:02,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.176      1.798      2.127         10        640:  29% 119/416 [00:27<00:55,  5.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.176      1.796      2.128          8        640:  29% 120/416 [00:27<01:04,  4.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.176      1.795      2.129          9        640:  29% 121/416 [00:27<01:04,  4.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.174      1.793      2.127          8        640:  29% 122/416 [00:27<01:02,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.174       1.79      2.127          8        640:  30% 123/416 [00:27<01:04,  4.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.171       1.79      2.125          8        640:  30% 124/416 [00:28<00:58,  4.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.171      1.788      2.126          8        640:  30% 125/416 [00:28<01:03,  4.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.173      1.792      2.128         11        640:  30% 126/416 [00:28<01:05,  4.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.169       1.79      2.125          8        640:  31% 127/416 [00:28<00:57,  4.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.17      1.791      2.125         10        640:  31% 128/416 [00:28<01:00,  4.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.17      1.787      2.125          9        640:  31% 129/416 [00:29<01:02,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.785      2.121          8        640:  31% 130/416 [00:29<01:01,  4.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.165      1.783       2.12          7        640:  31% 131/416 [00:29<01:01,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.165      1.787       2.12          8        640:  32% 132/416 [00:29<01:01,  4.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.165      1.789       2.12          8        640:  32% 133/416 [00:30<00:55,  5.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.166      1.788      2.122          9        640:  32% 134/416 [00:30<00:49,  5.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.785      2.124          8        640:  32% 135/416 [00:30<00:54,  5.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.785      2.123         10        640:  33% 136/416 [00:30<00:50,  5.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.166      1.784       2.12          9        640:  33% 137/416 [00:30<01:01,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.164      1.784       2.12          9        640:  33% 138/416 [00:31<01:09,  4.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163      1.781      2.117          8        640:  33% 139/416 [00:31<01:22,  3.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.164      1.781      2.119         11        640:  34% 140/416 [00:31<01:14,  3.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.166      1.789       2.12         10        640:  34% 141/416 [00:32<01:14,  3.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.166      1.788       2.12         10        640:  34% 142/416 [00:32<01:21,  3.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162      1.789      2.116          8        640:  34% 143/416 [00:32<01:18,  3.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162       1.79      2.116         11        640:  35% 144/416 [00:32<01:19,  3.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.164      1.793      2.119         10        640:  35% 145/416 [00:33<01:22,  3.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162      1.793      2.118          8        640:  35% 146/416 [00:33<01:23,  3.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.165      1.792      2.122         10        640:  35% 147/416 [00:33<01:26,  3.12it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163      1.792      2.121          7        640:  36% 148/416 [00:34<01:23,  3.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.168      1.801      2.126         10        640:  36% 149/416 [00:34<01:16,  3.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.171      1.804      2.127         10        640:  36% 150/416 [00:34<01:08,  3.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.171      1.805      2.126          8        640:  36% 151/416 [00:34<01:06,  3.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.172      1.806      2.127         12        640:  37% 152/416 [00:35<01:03,  4.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.169      1.805      2.124          8        640:  37% 153/416 [00:35<01:03,  4.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.17      1.808      2.127          9        640:  37% 154/416 [00:35<00:59,  4.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.171      1.807       2.13         11        640:  37% 155/416 [00:35<01:02,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.173      1.808      2.132          9        640:  38% 156/416 [00:36<00:59,  4.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.17      1.804      2.129          9        640:  38% 157/416 [00:36<00:56,  4.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.169      1.801      2.128          9        640:  38% 158/416 [00:36<00:54,  4.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.169        1.8      2.128          9        640:  38% 159/416 [00:36<00:49,  5.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.797      2.126          9        640:  38% 160/416 [00:36<00:54,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.168      1.797      2.127         10        640:  39% 161/416 [00:37<00:53,  4.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.164      1.796      2.124          7        640:  39% 162/416 [00:37<00:52,  4.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162      1.794      2.122          8        640:  39% 163/416 [00:37<01:00,  4.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.164      1.795      2.123         10        640:  39% 164/416 [00:37<00:52,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.799      2.126         11        640:  40% 165/416 [00:37<00:52,  4.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.168      1.801      2.127          7        640:  40% 166/416 [00:38<00:54,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.165      1.799      2.125          8        640:  40% 167/416 [00:38<00:50,  4.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.164      1.796      2.124          9        640:  40% 168/416 [00:38<00:52,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.164      1.795      2.126         10        640:  41% 169/416 [00:38<00:46,  5.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.165      1.796      2.127         12        640:  41% 170/416 [00:38<00:52,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.169      1.799       2.13         12        640:  41% 171/416 [00:39<00:54,  4.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.171      1.802      2.133         10        640:  41% 172/416 [00:39<00:50,  4.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.798       2.13          7        640:  42% 173/416 [00:39<00:51,  4.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.17      1.797      2.132         10        640:  42% 174/416 [00:39<00:51,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.173      1.803      2.136          9        640:  42% 175/416 [00:40<00:54,  4.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.172      1.801      2.136          9        640:  42% 176/416 [00:40<00:49,  4.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.173      1.801      2.138          8        640:  43% 177/416 [00:40<00:50,  4.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.173        1.8      2.137         10        640:  43% 178/416 [00:40<00:51,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.17      1.797      2.135          8        640:  43% 179/416 [00:40<00:49,  4.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.172      1.797      2.135          9        640:  43% 180/416 [00:41<00:50,  4.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.17      1.795      2.133          9        640:  44% 181/416 [00:41<00:45,  5.13it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.17      1.794      2.132          9        640:  44% 182/416 [00:41<00:41,  5.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.171      1.794      2.133         10        640:  44% 183/416 [00:41<00:44,  5.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.171      1.792      2.133          7        640:  44% 184/416 [00:41<00:49,  4.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.17      1.791      2.132         10        640:  44% 185/416 [00:42<00:51,  4.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.173      1.794      2.132         11        640:  45% 186/416 [00:42<00:44,  5.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.173      1.795      2.133          8        640:  45% 187/416 [00:42<00:49,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.177      1.798      2.137          9        640:  45% 188/416 [00:42<00:48,  4.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.177        1.8      2.137         12        640:  45% 189/416 [00:42<00:43,  5.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.175      1.799      2.135          7        640:  46% 190/416 [00:43<00:48,  4.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.178      1.799      2.137         11        640:  46% 191/416 [00:43<00:42,  5.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.179      1.801      2.139          9        640:  46% 192/416 [00:43<00:42,  5.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.179        1.8      2.138          9        640:  46% 193/416 [00:43<00:48,  4.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.181      1.801      2.139          9        640:  47% 194/416 [00:43<00:46,  4.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.18      1.803      2.138          8        640:  47% 195/416 [00:44<00:44,  4.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.181      1.802      2.138          8        640:  47% 196/416 [00:44<00:49,  4.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.181      1.801      2.138          8        640:  47% 197/416 [00:44<00:55,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.186      1.807      2.142         19        640:  48% 198/416 [00:45<01:01,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.185      1.805      2.141         10        640:  48% 199/416 [00:45<00:58,  3.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.184      1.804       2.14          8        640:  48% 200/416 [00:45<01:00,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.187      1.804      2.142          8        640:  48% 201/416 [00:45<00:56,  3.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.187      1.804      2.142         12        640:  49% 202/416 [00:46<01:00,  3.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.185      1.803      2.139          9        640:  49% 203/416 [00:46<01:07,  3.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.185      1.802       2.14         11        640:  49% 204/416 [00:46<01:04,  3.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.185      1.803       2.14          9        640:  49% 205/416 [00:47<01:00,  3.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.185      1.801       2.14          9        640:  50% 206/416 [00:47<01:01,  3.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.184      1.802       2.14          8        640:  50% 207/416 [00:47<01:00,  3.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.186      1.805      2.142         10        640:  50% 208/416 [00:47<01:00,  3.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.185      1.806      2.141         10        640:  50% 209/416 [00:48<01:04,  3.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.184      1.807      2.141          8        640:  50% 210/416 [00:48<00:59,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.188       1.81      2.144         10        640:  51% 211/416 [00:48<00:56,  3.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.191      1.812      2.145         11        640:  51% 212/416 [00:48<00:52,  3.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.191      1.811      2.145          9        640:  51% 213/416 [00:49<00:50,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.19       1.81      2.144          6        640:  51% 214/416 [00:49<00:52,  3.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.189      1.809      2.143          9        640:  52% 215/416 [00:49<00:56,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.19      1.809      2.145          8        640:  52% 216/416 [00:50<00:53,  3.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.187      1.806      2.142          8        640:  52% 217/416 [00:50<00:51,  3.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.187      1.806      2.142          9        640:  52% 218/416 [00:50<00:48,  4.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.186      1.803      2.141          7        640:  53% 219/416 [00:50<00:54,  3.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.184        1.8      2.138          8        640:  53% 220/416 [00:51<00:48,  4.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.184      1.803       2.14         10        640:  53% 221/416 [00:51<00:49,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.184      1.802      2.139         10        640:  53% 222/416 [00:51<00:48,  3.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.181      1.799      2.137          8        640:  54% 223/416 [00:51<00:50,  3.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.181      1.798      2.136          9        640:  54% 224/416 [00:52<00:45,  4.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.18      1.796      2.135          9        640:  54% 225/416 [00:52<00:43,  4.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.179      1.799      2.135          7        640:  54% 226/416 [00:52<00:41,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.177      1.797      2.133          7        640:  55% 227/416 [00:52<00:42,  4.47it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.176      1.798      2.132          8        640:  55% 228/416 [00:52<00:38,  4.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.178      1.801      2.136         14        640:  55% 229/416 [00:53<00:40,  4.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.178        1.8      2.136          9        640:  55% 230/416 [00:53<00:40,  4.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.179        1.8      2.136         10        640:  56% 231/416 [00:53<00:42,  4.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.177      1.799      2.135          8        640:  56% 232/416 [00:53<00:42,  4.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.177      1.797      2.135          8        640:  56% 233/416 [00:54<00:43,  4.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.174      1.796      2.132          8        640:  56% 234/416 [00:54<00:42,  4.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.173      1.796      2.132         10        640:  56% 235/416 [00:54<00:43,  4.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.172      1.795      2.131          9        640:  57% 236/416 [00:54<00:43,  4.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.171      1.795       2.13          9        640:  57% 237/416 [00:55<00:43,  4.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.172      1.799      2.132          9        640:  57% 238/416 [00:55<00:47,  3.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.174        1.8      2.134         10        640:  57% 239/416 [00:55<00:44,  3.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.174        1.8      2.134         10        640:  58% 240/416 [00:55<00:44,  3.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.173        1.8      2.134         10        640:  58% 241/416 [00:56<00:44,  3.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.173        1.8      2.134         10        640:  58% 242/416 [00:56<00:43,  4.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.175        1.8      2.137         10        640:  58% 243/416 [00:56<00:39,  4.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.172      1.799      2.134          7        640:  59% 244/416 [00:56<00:36,  4.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.17      1.798      2.133          8        640:  59% 245/416 [00:56<00:37,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.172      1.799      2.134         11        640:  59% 246/416 [00:57<00:38,  4.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.169      1.797      2.131          8        640:  59% 247/416 [00:57<00:38,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.168      1.796       2.13          9        640:  60% 248/416 [00:57<00:41,  4.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.168      1.795       2.13         10        640:  60% 249/416 [00:57<00:36,  4.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.168      1.795       2.13         10        640:  60% 250/416 [00:58<00:37,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.169      1.795       2.13         11        640:  60% 251/416 [00:58<00:36,  4.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.169      1.794       2.13          9        640:  61% 252/416 [00:58<00:38,  4.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.168      1.794       2.13          9        640:  61% 253/416 [00:58<00:38,  4.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.168      1.794      2.129          9        640:  61% 254/416 [00:58<00:36,  4.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.166      1.793      2.128          9        640:  61% 255/416 [00:59<00:43,  3.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.164      1.791      2.126          8        640:  62% 256/416 [00:59<00:43,  3.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.164       1.79      2.125         10        640:  62% 257/416 [00:59<00:40,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163       1.79      2.125          9        640:  62% 258/416 [01:00<00:46,  3.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.161      1.789      2.123          8        640:  62% 259/416 [01:00<00:48,  3.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.16      1.789      2.122          9        640:  62% 260/416 [01:00<00:44,  3.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.16      1.787      2.122          9        640:  63% 261/416 [01:01<00:44,  3.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.16      1.787      2.122         10        640:  63% 262/416 [01:01<00:41,  3.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.159      1.786      2.121         10        640:  63% 263/416 [01:01<00:45,  3.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.158      1.787       2.12          8        640:  63% 264/416 [01:01<00:43,  3.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.158      1.787      2.121         10        640:  64% 265/416 [01:02<00:44,  3.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.159      1.787      2.122         10        640:  64% 266/416 [01:02<00:41,  3.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.161      1.788      2.124         10        640:  64% 267/416 [01:02<00:41,  3.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163      1.792      2.127         13        640:  64% 268/416 [01:03<00:39,  3.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.164      1.794      2.127         12        640:  65% 269/416 [01:03<00:37,  3.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.164      1.795      2.128          9        640:  65% 270/416 [01:03<00:35,  4.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163      1.795      2.127          9        640:  65% 271/416 [01:03<00:33,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162      1.794      2.125          7        640:  65% 272/416 [01:03<00:30,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162      1.794      2.124          9        640:  66% 273/416 [01:04<00:30,  4.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.16      1.792      2.123          8        640:  66% 274/416 [01:04<00:30,  4.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.16      1.792      2.124          7        640:  66% 275/416 [01:04<00:33,  4.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.161      1.793      2.124         10        640:  66% 276/416 [01:04<00:30,  4.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.16      1.792      2.123          7        640:  67% 277/416 [01:05<00:34,  4.01it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.16      1.793      2.124         10        640:  67% 278/416 [01:05<00:30,  4.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.16      1.792      2.124         10        640:  67% 279/416 [01:05<00:27,  4.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.159      1.791      2.123          9        640:  67% 280/416 [01:05<00:28,  4.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.16       1.79      2.123         11        640:  68% 281/416 [01:05<00:30,  4.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.159       1.79      2.123         11        640:  68% 282/416 [01:05<00:26,  5.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.161       1.79      2.124          7        640:  68% 283/416 [01:06<00:31,  4.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162      1.791      2.127          8        640:  68% 284/416 [01:06<00:28,  4.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163       1.79      2.128          9        640:  69% 285/416 [01:06<00:26,  4.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.164      1.792      2.129         12        640:  69% 286/416 [01:06<00:31,  4.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163       1.79      2.128          9        640:  69% 287/416 [01:07<00:28,  4.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163      1.789      2.128          8        640:  69% 288/416 [01:07<00:24,  5.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162      1.788      2.127          8        640:  69% 289/416 [01:07<00:23,  5.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162      1.789      2.126         11        640:  70% 290/416 [01:07<00:27,  4.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163      1.789      2.127          9        640:  70% 291/416 [01:07<00:26,  4.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163       1.79      2.127         10        640:  70% 292/416 [01:08<00:23,  5.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163      1.789      2.126         10        640:  70% 293/416 [01:08<00:23,  5.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163      1.789      2.127          9        640:  71% 294/416 [01:08<00:26,  4.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162      1.789      2.126         10        640:  71% 295/416 [01:08<00:24,  5.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162      1.789      2.126         11        640:  71% 296/416 [01:08<00:25,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163      1.788      2.127         10        640:  71% 297/416 [01:09<00:24,  4.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163      1.787      2.126          9        640:  72% 298/416 [01:09<00:23,  5.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162      1.786      2.125          9        640:  72% 299/416 [01:09<00:23,  5.01it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163      1.786      2.126          9        640:  72% 300/416 [01:09<00:21,  5.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162      1.787      2.125         10        640:  72% 301/416 [01:09<00:24,  4.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162      1.786      2.124          8        640:  73% 302/416 [01:10<00:23,  4.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.162      1.786      2.124         10        640:  73% 303/416 [01:10<00:25,  4.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.164      1.787      2.126         10        640:  73% 304/416 [01:10<00:22,  4.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163      1.786      2.126          8        640:  73% 305/416 [01:10<00:22,  4.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.166      1.791      2.128         18        640:  74% 306/416 [01:10<00:20,  5.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.168      1.793      2.129         13        640:  74% 307/416 [01:11<00:22,  4.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.792      2.128          9        640:  74% 308/416 [01:11<00:21,  5.12it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.791      2.128          9        640:  74% 309/416 [01:11<00:19,  5.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.791      2.128          9        640:  75% 310/416 [01:11<00:20,  5.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.166       1.79      2.127          8        640:  75% 311/416 [01:11<00:22,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.789      2.128          8        640:  75% 312/416 [01:12<00:22,  4.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.789      2.129          9        640:  75% 313/416 [01:12<00:20,  5.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.789      2.128         10        640:  75% 314/416 [01:12<00:25,  4.07it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.165      1.787      2.126          8        640:  76% 315/416 [01:13<00:27,  3.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.166      1.789      2.127          9        640:  76% 316/416 [01:13<00:25,  3.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.789      2.127         11        640:  76% 317/416 [01:13<00:26,  3.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.169      1.789      2.129         11        640:  76% 318/416 [01:13<00:27,  3.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.788      2.127          8        640:  77% 319/416 [01:14<00:25,  3.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.788      2.127          8        640:  77% 320/416 [01:14<00:26,  3.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.788      2.127          9        640:  77% 321/416 [01:14<00:25,  3.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.166      1.787      2.126          9        640:  77% 322/416 [01:14<00:26,  3.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.168      1.788      2.127         12        640:  78% 323/416 [01:15<00:26,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.787      2.126          9        640:  78% 324/416 [01:15<00:24,  3.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.167      1.788      2.125          9        640:  78% 325/416 [01:15<00:25,  3.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.166      1.788      2.124          7        640:  78% 326/416 [01:16<00:25,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.165      1.787      2.122          8        640:  79% 327/416 [01:16<00:25,  3.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.165      1.786      2.124         10        640:  79% 328/416 [01:16<00:26,  3.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.164      1.786      2.123          7        640:  79% 329/416 [01:16<00:21,  4.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.163      1.786      2.122          8        640:  79% 330/416 [01:17<00:22,  3.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.161      1.784       2.12          8        640:  80% 331/416 [01:17<00:22,  3.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.161      1.782      2.119          7        640:  80% 332/416 [01:17<00:20,  4.01it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.16      1.781      2.119          9        640:  80% 333/416 [01:17<00:19,  4.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.16      1.781      2.119         11        640:  80% 334/416 [01:18<00:17,  4.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.158      1.781      2.116          8        640:  81% 335/416 [01:18<00:19,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.157      1.779      2.115          9        640:  81% 336/416 [01:18<00:18,  4.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.157      1.779      2.116          9        640:  81% 337/416 [01:18<00:19,  4.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.155      1.779      2.114          7        640:  81% 338/416 [01:19<00:19,  4.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.156      1.778      2.113         10        640:  81% 339/416 [01:19<00:21,  3.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.155      1.777      2.112          8        640:  82% 340/416 [01:19<00:20,  3.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.156      1.778      2.112         11        640:  82% 341/416 [01:19<00:19,  3.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.154      1.775       2.11          8        640:  82% 342/416 [01:20<00:19,  3.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.156      1.776      2.112         11        640:  82% 343/416 [01:20<00:19,  3.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.154      1.774       2.11          7        640:  83% 344/416 [01:20<00:16,  4.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.156      1.774      2.113          9        640:  83% 345/416 [01:20<00:17,  4.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.156      1.774      2.114         10        640:  83% 346/416 [01:21<00:16,  4.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.155      1.774      2.113          9        640:  83% 347/416 [01:21<00:15,  4.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.155      1.774      2.112          8        640:  84% 348/416 [01:21<00:16,  4.05it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.154      1.772      2.111          8        640:  84% 349/416 [01:21<00:14,  4.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.155      1.772      2.111         10        640:  84% 350/416 [01:21<00:14,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.771      2.109          8        640:  84% 351/416 [01:22<00:14,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.771      2.109          9        640:  85% 352/416 [01:22<00:13,  4.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.154      1.771      2.111         10        640:  85% 353/416 [01:22<00:14,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153       1.77       2.11          8        640:  85% 354/416 [01:22<00:13,  4.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.769       2.11          8        640:  85% 355/416 [01:23<00:13,  4.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.152      1.768      2.109          9        640:  86% 356/416 [01:23<00:12,  4.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.152      1.767      2.109         11        640:  86% 357/416 [01:23<00:13,  4.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.766       2.11          8        640:  86% 358/416 [01:23<00:11,  4.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.152      1.764      2.109          9        640:  86% 359/416 [01:23<00:10,  5.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.765       2.11         10        640:  87% 360/416 [01:24<00:11,  4.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.152      1.765       2.11          8        640:  87% 361/416 [01:24<00:10,  5.13it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.766       2.11          8        640:  87% 362/416 [01:24<00:11,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.767       2.11          9        640:  87% 363/416 [01:24<00:12,  4.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.154      1.768       2.11         11        640:  88% 364/416 [01:25<00:12,  4.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.155      1.768      2.112         11        640:  88% 365/416 [01:25<00:11,  4.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.156      1.769      2.112         10        640:  88% 366/416 [01:25<00:11,  4.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.156      1.768      2.112          8        640:  88% 367/416 [01:25<00:11,  4.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.154      1.767       2.11          8        640:  88% 368/416 [01:25<00:10,  4.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.154      1.766       2.11          9        640:  89% 369/416 [01:26<00:10,  4.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.154      1.765      2.109         10        640:  89% 370/416 [01:26<00:09,  4.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.764      2.109          8        640:  89% 371/416 [01:26<00:09,  4.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.763      2.108         10        640:  89% 372/416 [01:26<00:08,  5.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.151      1.762      2.106          7        640:  90% 373/416 [01:26<00:09,  4.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.151      1.763      2.107         10        640:  90% 374/416 [01:27<00:10,  3.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.152      1.763      2.107          9        640:  90% 375/416 [01:27<00:10,  4.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.151      1.763      2.107          9        640:  90% 376/416 [01:27<00:10,  3.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.763      2.109         11        640:  91% 377/416 [01:28<00:10,  3.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.763      2.109         11        640:  91% 378/416 [01:28<00:10,  3.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.762      2.109          8        640:  91% 379/416 [01:28<00:10,  3.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.761      2.109         10        640:  91% 380/416 [01:28<00:09,  3.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.761       2.11          9        640:  92% 381/416 [01:29<00:10,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.152      1.761      2.109          8        640:  92% 382/416 [01:29<00:10,  3.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.761       2.11         10        640:  92% 383/416 [01:29<00:10,  3.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.154      1.762      2.111         10        640:  92% 384/416 [01:30<00:10,  3.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.153      1.761       2.11         10        640:  93% 385/416 [01:30<00:09,  3.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.152      1.762      2.109          9        640:  93% 386/416 [01:30<00:08,  3.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.152      1.762      2.109          9        640:  93% 387/416 [01:31<00:08,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.151      1.761      2.108          9        640:  93% 388/416 [01:31<00:06,  4.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.151      1.762      2.108          8        640:  94% 389/416 [01:31<00:07,  3.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.151      1.763      2.109         10        640:  94% 390/416 [01:31<00:06,  4.05it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G       1.15      1.762      2.107          9        640:  94% 391/416 [01:31<00:06,  4.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.148      1.761      2.105          6        640:  94% 392/416 [01:32<00:05,  4.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.147      1.761      2.104          8        640:  94% 393/416 [01:32<00:05,  4.01it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.147       1.76      2.104         10        640:  95% 394/416 [01:32<00:05,  4.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.146      1.761      2.103          7        640:  95% 395/416 [01:33<00:05,  3.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.146       1.76      2.103         10        640:  95% 396/416 [01:33<00:04,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.145       1.76      2.103          7        640:  95% 397/416 [01:33<00:04,  3.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.145      1.759      2.102         10        640:  96% 398/416 [01:33<00:04,  4.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.144      1.759      2.101          9        640:  96% 399/416 [01:33<00:04,  3.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.144       1.76      2.101         10        640:  96% 400/416 [01:34<00:03,  4.07it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.143      1.759        2.1          8        640:  96% 401/416 [01:34<00:03,  3.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.144       1.76      2.101         10        640:  97% 402/416 [01:34<00:03,  3.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.143      1.759      2.101          8        640:  97% 403/416 [01:35<00:03,  3.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.142      1.758        2.1          9        640:  97% 404/416 [01:35<00:03,  3.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.142      1.758        2.1          8        640:  97% 405/416 [01:35<00:02,  4.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.142      1.758        2.1         10        640:  98% 406/416 [01:35<00:02,  4.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.142      1.758        2.1         10        640:  98% 407/416 [01:35<00:01,  5.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.141      1.756      2.099          8        640:  98% 408/416 [01:36<00:01,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.141      1.757      2.099         10        640:  98% 409/416 [01:36<00:01,  4.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.141      1.757      2.099          8        640:  99% 410/416 [01:36<00:01,  4.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.141      1.758      2.099         10        640:  99% 411/416 [01:36<00:01,  4.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.142      1.758      2.099          8        640:  99% 412/416 [01:36<00:00,  4.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.143      1.759      2.101         10        640:  99% 413/416 [01:37<00:00,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.144       1.76      2.102         10        640: 100% 414/416 [01:37<00:00,  4.12it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.143      1.758      2.101          9        640: 100% 415/416 [01:37<00:00,  4.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       6/10      1.37G      1.143      1.758      2.101          3        640: 100% 416/416 [01:37<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 11/11 [00:01<00:00,  5.82it/s]\n",
            "                   all        174        200      0.332      0.526      0.423      0.286\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/416 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      2.257      2.625      2.814         14        640:   0% 1/416 [00:00<01:36,  4.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.849        2.3      2.585         11        640:   0% 2/416 [00:00<01:30,  4.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.543       1.99      2.397          9        640:   1% 3/416 [00:00<01:26,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G        1.5      1.867      2.372          8        640:   1% 4/416 [00:00<01:35,  4.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.399      1.803      2.247          9        640:   1% 5/416 [00:01<01:29,  4.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.306      1.759      2.175          8        640:   1% 6/416 [00:01<01:45,  3.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.275      1.733      2.132          8        640:   2% 7/416 [00:01<01:56,  3.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.371      1.799      2.219         11        640:   2% 8/416 [00:02<01:49,  3.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.341      1.763      2.184          9        640:   2% 9/416 [00:02<01:51,  3.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.323      1.751       2.18          9        640:   2% 10/416 [00:02<01:55,  3.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.313       1.74       2.18          9        640:   3% 11/416 [00:02<02:06,  3.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.304      1.759      2.155         11        640:   3% 12/416 [00:03<01:55,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.28      1.754       2.14          9        640:   3% 13/416 [00:03<02:00,  3.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.256      1.716      2.134          7        640:   3% 14/416 [00:03<02:04,  3.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.226      1.727      2.108          7        640:   4% 15/416 [00:04<02:04,  3.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.22      1.739      2.099         10        640:   4% 16/416 [00:04<02:03,  3.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.184       1.71      2.058          8        640:   4% 17/416 [00:04<02:01,  3.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.197      1.718      2.075          9        640:   4% 18/416 [00:04<01:47,  3.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.175        1.7       2.05         10        640:   5% 19/416 [00:05<01:53,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.208      1.721       2.08         12        640:   5% 20/416 [00:05<01:47,  3.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.191      1.718       2.06          9        640:   5% 21/416 [00:05<01:50,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.181      1.713      2.054          9        640:   5% 22/416 [00:06<01:43,  3.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.179      1.707      2.065          9        640:   6% 23/416 [00:06<01:45,  3.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.19      1.715      2.067         11        640:   6% 24/416 [00:06<01:44,  3.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.189      1.702      2.074          9        640:   6% 25/416 [00:06<01:40,  3.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.192      1.708      2.076         11        640:   6% 26/416 [00:07<01:40,  3.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.204      1.741      2.091         16        640:   6% 27/416 [00:07<01:40,  3.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.192      1.734      2.079          8        640:   7% 28/416 [00:07<01:28,  4.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.178      1.725      2.067          8        640:   7% 29/416 [00:07<01:37,  3.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.166       1.74      2.057          9        640:   7% 30/416 [00:08<01:34,  4.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.163      1.744      2.053          9        640:   7% 31/416 [00:08<01:38,  3.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.17      1.747      2.059         10        640:   8% 32/416 [00:08<01:27,  4.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.177      1.751      2.067          9        640:   8% 33/416 [00:08<01:37,  3.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.169      1.752       2.06          8        640:   8% 34/416 [00:08<01:26,  4.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.148      1.737      2.042          7        640:   8% 35/416 [00:09<01:28,  4.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.14       1.73      2.032          9        640:   9% 36/416 [00:09<01:23,  4.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.139      1.724      2.033          9        640:   9% 37/416 [00:09<01:29,  4.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.135      1.721      2.032          8        640:   9% 38/416 [00:09<01:32,  4.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.143      1.725      2.043         10        640:   9% 39/416 [00:10<01:27,  4.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.14       1.72      2.044          8        640:  10% 40/416 [00:10<01:30,  4.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.147      1.721      2.054         10        640:  10% 41/416 [00:10<01:18,  4.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.149       1.72      2.044         10        640:  10% 42/416 [00:10<01:21,  4.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.139      1.713      2.036          9        640:  10% 43/416 [00:11<01:22,  4.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.145      1.712       2.04          8        640:  11% 44/416 [00:11<01:21,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.159      1.717      2.062          8        640:  11% 45/416 [00:11<01:28,  4.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.159      1.713      2.059          8        640:  11% 46/416 [00:11<01:33,  3.98it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.147      1.717       2.05          8        640:  11% 47/416 [00:12<01:32,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.147      1.715      2.054          7        640:  12% 48/416 [00:12<01:30,  4.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.145      1.715      2.051          9        640:  12% 49/416 [00:12<01:19,  4.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.143      1.713      2.048          9        640:  12% 50/416 [00:12<01:30,  4.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.135      1.706      2.041          8        640:  12% 51/416 [00:12<01:31,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.142      1.707      2.052         10        640:  12% 52/416 [00:13<01:26,  4.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.135      1.698      2.045          8        640:  13% 53/416 [00:13<01:25,  4.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.133      1.699      2.041          9        640:  13% 54/416 [00:13<01:26,  4.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.135      1.691      2.046          9        640:  13% 55/416 [00:13<01:17,  4.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.138      1.699      2.047         14        640:  13% 56/416 [00:14<01:22,  4.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.133      1.695      2.043          9        640:  14% 57/416 [00:14<01:24,  4.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.125      1.695      2.037          9        640:  14% 58/416 [00:14<01:23,  4.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.128      1.699      2.039         11        640:  14% 59/416 [00:14<01:32,  3.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.133       1.71      2.044         11        640:  14% 60/416 [00:15<01:33,  3.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.128      1.701      2.039          8        640:  15% 61/416 [00:15<01:34,  3.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.121      1.694      2.031          7        640:  15% 62/416 [00:15<01:42,  3.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.12      1.692      2.029          9        640:  15% 63/416 [00:16<01:35,  3.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.125      1.694      2.035         10        640:  15% 64/416 [00:16<01:37,  3.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.13      1.692      2.038         11        640:  16% 65/416 [00:16<01:36,  3.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.136      1.697      2.043          9        640:  16% 66/416 [00:16<01:46,  3.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.143      1.709      2.052         11        640:  16% 67/416 [00:17<01:37,  3.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.143      1.709      2.049          9        640:  16% 68/416 [00:17<01:36,  3.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.137      1.708      2.042         10        640:  17% 69/416 [00:17<01:39,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.137      1.706      2.043          9        640:  17% 70/416 [00:18<01:47,  3.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.13      1.696      2.034          8        640:  17% 71/416 [00:18<01:37,  3.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.127      1.693      2.032         10        640:  17% 72/416 [00:18<01:39,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.14      1.711      2.043         15        640:  18% 73/416 [00:18<01:40,  3.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.149      1.715      2.048         11        640:  18% 74/416 [00:19<01:37,  3.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.154      1.718      2.054          8        640:  18% 75/416 [00:19<01:32,  3.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.152      1.713      2.054          8        640:  18% 76/416 [00:19<01:38,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.158      1.715      2.057         17        640:  19% 77/416 [00:20<01:31,  3.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.154      1.713      2.055          9        640:  19% 78/416 [00:20<01:20,  4.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.15      1.715      2.051          8        640:  19% 79/416 [00:20<01:24,  4.01it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.15      1.718      2.053          9        640:  19% 80/416 [00:20<01:29,  3.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.15      1.718      2.053          7        640:  19% 81/416 [00:20<01:24,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.147      1.716       2.05          9        640:  20% 82/416 [00:21<01:29,  3.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.144      1.712      2.048         11        640:  20% 83/416 [00:21<01:29,  3.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.146      1.712      2.047         10        640:  20% 84/416 [00:21<01:24,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.143      1.711      2.045         10        640:  20% 85/416 [00:22<01:23,  3.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.141      1.712      2.044          7        640:  21% 86/416 [00:22<01:24,  3.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.142      1.719      2.047         10        640:  21% 87/416 [00:22<01:24,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.144      1.728      2.048         11        640:  21% 88/416 [00:22<01:26,  3.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.138      1.719      2.043          8        640:  21% 89/416 [00:23<01:20,  4.05it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.143      1.718      2.047         12        640:  22% 90/416 [00:23<01:26,  3.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.142      1.717      2.046          8        640:  22% 91/416 [00:23<01:17,  4.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.138      1.716      2.041          8        640:  22% 92/416 [00:23<01:06,  4.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.132       1.71      2.036          8        640:  22% 93/416 [00:23<01:17,  4.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.13      1.705      2.035          9        640:  23% 94/416 [00:24<01:09,  4.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.131      1.707      2.038         10        640:  23% 95/416 [00:24<01:15,  4.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.128      1.705      2.034          7        640:  23% 96/416 [00:24<01:06,  4.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.132       1.71      2.038         10        640:  23% 97/416 [00:24<00:58,  5.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.13      1.708      2.037          8        640:  24% 98/416 [00:24<01:04,  4.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.135      1.713      2.042         10        640:  24% 99/416 [00:25<01:13,  4.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.136      1.714      2.042          8        640:  24% 100/416 [00:25<01:12,  4.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.138      1.712      2.047          9        640:  24% 101/416 [00:25<01:06,  4.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.14      1.711      2.048         10        640:  25% 102/416 [00:25<01:05,  4.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.135      1.707      2.043          8        640:  25% 103/416 [00:26<01:03,  4.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.131      1.705      2.039          9        640:  25% 104/416 [00:26<01:05,  4.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.127      1.705      2.035         10        640:  25% 105/416 [00:26<01:03,  4.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.132      1.712      2.038         10        640:  25% 106/416 [00:26<01:05,  4.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.13      1.707      2.036          8        640:  26% 107/416 [00:26<01:05,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.13      1.709      2.036         10        640:  26% 108/416 [00:27<01:00,  5.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.134      1.713      2.039          8        640:  26% 109/416 [00:27<01:03,  4.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.132       1.71      2.038          7        640:  26% 110/416 [00:27<01:03,  4.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.133      1.709       2.04          9        640:  27% 111/416 [00:27<01:03,  4.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.133      1.709       2.04          7        640:  27% 112/416 [00:27<01:06,  4.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.134       1.71      2.043          7        640:  27% 113/416 [00:28<00:59,  5.07it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.134      1.706      2.044          8        640:  27% 114/416 [00:28<01:01,  4.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.13      1.703       2.04          8        640:  28% 115/416 [00:28<01:11,  4.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.133      1.705      2.044         10        640:  28% 116/416 [00:28<01:02,  4.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.131      1.703      2.043          9        640:  28% 117/416 [00:28<00:55,  5.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.131      1.701      2.043          8        640:  28% 118/416 [00:29<01:05,  4.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.135      1.704      2.048          9        640:  29% 119/416 [00:29<01:14,  4.01it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.131      1.704      2.043          7        640:  29% 120/416 [00:29<01:05,  4.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.127      1.702      2.039          8        640:  29% 121/416 [00:30<01:18,  3.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.127      1.701       2.04         11        640:  29% 122/416 [00:30<01:25,  3.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.126        1.7       2.04          9        640:  30% 123/416 [00:30<01:30,  3.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.127      1.703      2.043         10        640:  30% 124/416 [00:30<01:26,  3.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.127      1.702      2.042          9        640:  30% 125/416 [00:31<01:29,  3.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.129      1.703      2.044         10        640:  30% 126/416 [00:31<01:33,  3.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.127      1.701      2.043          8        640:  31% 127/416 [00:31<01:31,  3.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.124      1.699      2.041          8        640:  31% 128/416 [00:32<01:25,  3.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.123      1.698      2.039         10        640:  31% 129/416 [00:32<01:25,  3.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.124      1.696      2.042          9        640:  31% 130/416 [00:32<01:30,  3.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.124      1.698      2.043         10        640:  31% 131/416 [00:33<01:27,  3.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.125      1.696      2.044          8        640:  32% 132/416 [00:33<01:18,  3.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.127      1.696      2.047         12        640:  32% 133/416 [00:33<01:15,  3.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.127      1.695      2.048          9        640:  32% 134/416 [00:33<01:09,  4.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.129      1.694       2.05         10        640:  32% 135/416 [00:34<01:12,  3.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.129      1.693      2.051          9        640:  33% 136/416 [00:34<01:11,  3.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.129      1.692      2.051         10        640:  33% 137/416 [00:34<01:07,  4.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.125       1.69      2.047          8        640:  33% 138/416 [00:34<01:02,  4.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.127      1.692      2.048          9        640:  33% 139/416 [00:35<01:13,  3.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.125       1.69      2.045          9        640:  34% 140/416 [00:35<01:07,  4.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.124      1.689      2.045         10        640:  34% 141/416 [00:35<01:10,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.124       1.69      2.044         10        640:  34% 142/416 [00:35<01:15,  3.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.127      1.692      2.048          8        640:  34% 143/416 [00:36<01:08,  3.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.128       1.69      2.048          8        640:  35% 144/416 [00:36<01:00,  4.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.127      1.687      2.047         10        640:  35% 145/416 [00:36<01:03,  4.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.124      1.685      2.045          9        640:  35% 146/416 [00:36<00:54,  4.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.125      1.684      2.047          8        640:  35% 147/416 [00:36<01:03,  4.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.124      1.682      2.046          9        640:  36% 148/416 [00:37<01:02,  4.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.125       1.68      2.048          8        640:  36% 149/416 [00:37<00:59,  4.47it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.122      1.677      2.046          9        640:  36% 150/416 [00:37<00:55,  4.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.122      1.679      2.046         10        640:  36% 151/416 [00:37<00:50,  5.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.123       1.68      2.047         10        640:  37% 152/416 [00:37<00:56,  4.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.12      1.681      2.044          7        640:  37% 153/416 [00:38<00:57,  4.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.122      1.682      2.046         10        640:  37% 154/416 [00:38<00:58,  4.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.124      1.683      2.047          9        640:  37% 155/416 [00:38<01:02,  4.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.125      1.683      2.049         10        640:  38% 156/416 [00:38<00:54,  4.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.124      1.683      2.048          9        640:  38% 157/416 [00:39<00:57,  4.47it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.122      1.682      2.046         11        640:  38% 158/416 [00:39<00:51,  5.01it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.121      1.679      2.044          9        640:  38% 159/416 [00:39<00:57,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.119      1.678      2.041          9        640:  38% 160/416 [00:39<00:52,  4.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.121      1.681      2.043         12        640:  39% 161/416 [00:40<00:59,  4.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.123      1.683      2.045         10        640:  39% 162/416 [00:40<00:52,  4.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.123      1.683      2.045          9        640:  39% 163/416 [00:40<00:52,  4.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.124      1.686      2.046         10        640:  39% 164/416 [00:40<00:48,  5.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.122      1.687      2.043          8        640:  40% 165/416 [00:40<00:56,  4.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.122      1.687      2.043          9        640:  40% 166/416 [00:41<00:53,  4.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.122      1.686      2.044         12        640:  40% 167/416 [00:41<01:00,  4.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.12      1.688      2.041          7        640:  40% 168/416 [00:41<00:57,  4.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.117      1.685      2.038          9        640:  41% 169/416 [00:41<00:54,  4.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.115      1.688      2.035          6        640:  41% 170/416 [00:41<00:52,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.114      1.691      2.035          9        640:  41% 171/416 [00:42<00:50,  4.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.112       1.69      2.034          9        640:  41% 172/416 [00:42<00:54,  4.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.114      1.692      2.036          9        640:  42% 173/416 [00:42<00:51,  4.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.111       1.69      2.033          9        640:  42% 174/416 [00:42<00:51,  4.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.113       1.69      2.036         10        640:  42% 175/416 [00:42<00:48,  4.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.108      1.688      2.031          8        640:  42% 176/416 [00:43<00:59,  4.01it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.106      1.686       2.03          8        640:  43% 177/416 [00:43<01:04,  3.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.104      1.686      2.029         10        640:  43% 178/416 [00:43<01:06,  3.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.104      1.685      2.028          9        640:  43% 179/416 [00:44<01:15,  3.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.107      1.686      2.031         11        640:  43% 180/416 [00:44<01:07,  3.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.103      1.683      2.026          8        640:  44% 181/416 [00:44<01:09,  3.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G        1.1      1.684      2.023          8        640:  44% 182/416 [00:45<01:07,  3.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.099      1.682      2.022          9        640:  44% 183/416 [00:45<01:08,  3.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.101      1.683      2.023         10        640:  44% 184/416 [00:45<01:05,  3.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G        1.1      1.685      2.024          7        640:  44% 185/416 [00:45<01:05,  3.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.102      1.685      2.025         10        640:  45% 186/416 [00:46<01:06,  3.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.102      1.684      2.025          9        640:  45% 187/416 [00:46<01:12,  3.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.103      1.686      2.027          9        640:  45% 188/416 [00:46<01:04,  3.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.103      1.687      2.027          9        640:  45% 189/416 [00:47<01:02,  3.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.103      1.687      2.028         10        640:  46% 190/416 [00:47<00:57,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.102      1.687      2.027          9        640:  46% 191/416 [00:47<00:53,  4.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G        1.1      1.685      2.026          8        640:  46% 192/416 [00:47<00:56,  3.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.099      1.684      2.024          9        640:  46% 193/416 [00:48<01:00,  3.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.097      1.683      2.023          9        640:  47% 194/416 [00:48<00:59,  3.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.096      1.682      2.022         10        640:  47% 195/416 [00:48<00:59,  3.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.097      1.682      2.023         10        640:  47% 196/416 [00:48<00:54,  4.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.096      1.681      2.022          9        640:  47% 197/416 [00:49<00:49,  4.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.096       1.68      2.022          9        640:  48% 198/416 [00:49<00:51,  4.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.095      1.679      2.021          9        640:  48% 199/416 [00:49<00:51,  4.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.096      1.681      2.021          8        640:  48% 200/416 [00:49<00:50,  4.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.097      1.685      2.023         13        640:  48% 201/416 [00:50<00:53,  3.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.095      1.684      2.021          9        640:  49% 202/416 [00:50<00:52,  4.05it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.094      1.686       2.02          8        640:  49% 203/416 [00:50<00:58,  3.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.093      1.685      2.019          8        640:  49% 204/416 [00:50<00:57,  3.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.091      1.683      2.018          8        640:  49% 205/416 [00:51<00:54,  3.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.09      1.681      2.016          9        640:  50% 206/416 [00:51<00:48,  4.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.096      1.683      2.024          8        640:  50% 207/416 [00:51<00:52,  3.98it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.096      1.682      2.023          8        640:  50% 208/416 [00:51<00:52,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.095      1.682      2.023         10        640:  50% 209/416 [00:52<00:48,  4.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.094       1.68      2.022          7        640:  50% 210/416 [00:52<00:51,  3.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.097      1.682      2.025         11        640:  51% 211/416 [00:52<00:50,  4.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.096      1.681      2.023          8        640:  51% 212/416 [00:52<00:42,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.095      1.679      2.022         10        640:  51% 213/416 [00:52<00:44,  4.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.094      1.679      2.021         10        640:  51% 214/416 [00:53<00:47,  4.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.094      1.678      2.022          9        640:  52% 215/416 [00:53<00:47,  4.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.092      1.677       2.02          9        640:  52% 216/416 [00:53<00:41,  4.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.088      1.674      2.017          8        640:  52% 217/416 [00:53<00:37,  5.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.087      1.672      2.015          9        640:  52% 218/416 [00:53<00:35,  5.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.086      1.671      2.015          9        640:  53% 219/416 [00:54<00:45,  4.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.085      1.672      2.014         10        640:  53% 220/416 [00:54<00:39,  4.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.085      1.673      2.015         10        640:  53% 221/416 [00:54<00:40,  4.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.086      1.673      2.014          9        640:  53% 222/416 [00:54<00:36,  5.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.087      1.673      2.015          8        640:  54% 223/416 [00:54<00:37,  5.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.09      1.677      2.019         10        640:  54% 224/416 [00:55<00:37,  5.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.09      1.679      2.019          8        640:  54% 225/416 [00:55<00:37,  5.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.087      1.677      2.016          8        640:  54% 226/416 [00:55<00:41,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.088      1.679      2.018         10        640:  55% 227/416 [00:55<00:45,  4.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.087      1.679      2.018         10        640:  55% 228/416 [00:56<00:45,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.085      1.679      2.016          8        640:  55% 229/416 [00:56<00:45,  4.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.084      1.679      2.015          9        640:  55% 230/416 [00:56<00:42,  4.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.088      1.686      2.019         12        640:  56% 231/416 [00:56<00:45,  4.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.088      1.685      2.018         10        640:  56% 232/416 [00:57<00:46,  3.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.089      1.686       2.02         14        640:  56% 233/416 [00:57<00:49,  3.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.09      1.687      2.022         10        640:  56% 234/416 [00:57<00:50,  3.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.09      1.686      2.022          8        640:  56% 235/416 [00:58<00:52,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.09      1.686      2.023          8        640:  57% 236/416 [00:58<00:48,  3.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.091      1.688      2.024         10        640:  57% 237/416 [00:58<00:50,  3.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.09       1.69      2.023          8        640:  57% 238/416 [00:58<00:49,  3.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.09      1.688      2.023          8        640:  57% 239/416 [00:59<00:52,  3.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.093      1.688      2.028         10        640:  58% 240/416 [00:59<00:50,  3.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.093      1.688      2.027          9        640:  58% 241/416 [00:59<00:50,  3.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.094      1.688      2.028          9        640:  58% 242/416 [01:00<00:48,  3.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.097      1.694       2.03         12        640:  58% 243/416 [01:00<00:55,  3.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.096      1.693      2.029          9        640:  59% 244/416 [01:00<00:51,  3.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.097      1.692       2.03         10        640:  59% 245/416 [01:00<00:49,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.097      1.695       2.03          9        640:  59% 246/416 [01:01<00:46,  3.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.099      1.695      2.031         10        640:  59% 247/416 [01:01<00:48,  3.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.101      1.695      2.033         11        640:  60% 248/416 [01:01<00:46,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G        1.1      1.693      2.032          9        640:  60% 249/416 [01:01<00:42,  3.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G        1.1      1.695      2.032         11        640:  60% 250/416 [01:02<00:43,  3.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.101      1.694      2.032          9        640:  60% 251/416 [01:02<00:43,  3.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.101      1.694      2.032          8        640:  61% 252/416 [01:02<00:37,  4.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.101      1.694      2.033          8        640:  61% 253/416 [01:02<00:39,  4.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.101      1.695      2.033         10        640:  61% 254/416 [01:03<00:39,  4.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G        1.1      1.694      2.032          9        640:  61% 255/416 [01:03<00:38,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G        1.1      1.692      2.034          8        640:  62% 256/416 [01:03<00:39,  4.05it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.101      1.693      2.035         11        640:  62% 257/416 [01:03<00:37,  4.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.101      1.693      2.034          7        640:  62% 258/416 [01:04<00:36,  4.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G        1.1      1.692      2.034          9        640:  62% 259/416 [01:04<00:41,  3.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.102      1.692      2.035         10        640:  62% 260/416 [01:04<00:41,  3.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G        1.1      1.692      2.034         10        640:  63% 261/416 [01:04<00:39,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.099      1.691      2.033          8        640:  63% 262/416 [01:05<00:40,  3.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G        1.1      1.691      2.035         10        640:  63% 263/416 [01:05<00:35,  4.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.101      1.689      2.035          9        640:  63% 264/416 [01:05<00:31,  4.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.102      1.693      2.036         10        640:  64% 265/416 [01:05<00:35,  4.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.102      1.693      2.036          9        640:  64% 266/416 [01:06<00:34,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.101      1.691      2.034          8        640:  64% 267/416 [01:06<00:32,  4.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.099       1.69      2.033          9        640:  64% 268/416 [01:06<00:35,  4.12it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.099       1.69      2.033          9        640:  65% 269/416 [01:06<00:30,  4.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.097      1.687      2.032          8        640:  65% 270/416 [01:06<00:30,  4.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.099      1.687      2.034          9        640:  65% 271/416 [01:07<00:30,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.098      1.687      2.033          9        640:  65% 272/416 [01:07<00:30,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.097      1.687      2.032          7        640:  66% 273/416 [01:07<00:29,  4.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.096      1.687      2.031          8        640:  66% 274/416 [01:07<00:27,  5.12it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.098      1.689      2.032         10        640:  66% 275/416 [01:07<00:32,  4.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.098      1.689      2.033         10        640:  66% 276/416 [01:08<00:31,  4.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.098      1.689      2.033          6        640:  67% 277/416 [01:08<00:29,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.098      1.689      2.034          9        640:  67% 278/416 [01:08<00:32,  4.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.101      1.692      2.036         18        640:  67% 279/416 [01:08<00:28,  4.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.101      1.693      2.036          9        640:  67% 280/416 [01:08<00:26,  5.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.099      1.691      2.034          9        640:  68% 281/416 [01:09<00:29,  4.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G        1.1       1.69      2.035          8        640:  68% 282/416 [01:09<00:27,  4.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G        1.1      1.692      2.036         11        640:  68% 283/416 [01:09<00:30,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G        1.1      1.693      2.036          8        640:  68% 284/416 [01:09<00:31,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.099      1.692      2.035         10        640:  69% 285/416 [01:10<00:32,  4.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.099      1.691      2.035          8        640:  69% 286/416 [01:10<00:32,  3.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.097       1.69      2.033          8        640:  69% 287/416 [01:10<00:29,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.097      1.689      2.032          8        640:  69% 288/416 [01:10<00:32,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.098       1.69      2.033         12        640:  69% 289/416 [01:11<00:35,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.097      1.689      2.032          9        640:  70% 290/416 [01:11<00:35,  3.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.096      1.688      2.031          8        640:  70% 291/416 [01:11<00:38,  3.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.096      1.689       2.03          8        640:  70% 292/416 [01:12<00:35,  3.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.094      1.687      2.028          8        640:  70% 293/416 [01:12<00:37,  3.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.094      1.687      2.029          9        640:  71% 294/416 [01:12<00:31,  3.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.094      1.687      2.029          9        640:  71% 295/416 [01:13<00:33,  3.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.094      1.687      2.029          9        640:  71% 296/416 [01:13<00:33,  3.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.094      1.687      2.028         10        640:  71% 297/416 [01:13<00:35,  3.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.093      1.688      2.028         10        640:  72% 298/416 [01:13<00:33,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.092      1.686      2.026          8        640:  72% 299/416 [01:14<00:35,  3.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.091      1.685      2.026         10        640:  72% 300/416 [01:14<00:35,  3.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.092      1.685      2.027         11        640:  72% 301/416 [01:14<00:33,  3.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.093      1.688      2.029         12        640:  73% 302/416 [01:15<00:30,  3.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.093      1.687      2.029          9        640:  73% 303/416 [01:15<00:29,  3.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.094      1.687       2.03         12        640:  73% 304/416 [01:15<00:29,  3.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.095      1.687      2.031         11        640:  73% 305/416 [01:15<00:28,  3.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.093      1.685      2.029          8        640:  74% 306/416 [01:16<00:28,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.094      1.684      2.029          9        640:  74% 307/416 [01:16<00:30,  3.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.093      1.683      2.028          9        640:  74% 308/416 [01:16<00:27,  3.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.092      1.681      2.027          7        640:  74% 309/416 [01:16<00:29,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.092      1.681      2.027          8        640:  75% 310/416 [01:17<00:26,  3.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.091       1.68      2.025          9        640:  75% 311/416 [01:17<00:27,  3.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.09      1.679      2.024          9        640:  75% 312/416 [01:17<00:26,  3.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.089      1.678      2.024          9        640:  75% 313/416 [01:17<00:26,  3.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.09      1.679      2.023         10        640:  75% 314/416 [01:18<00:26,  3.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.091      1.681      2.025          9        640:  76% 315/416 [01:18<00:28,  3.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.093      1.682      2.026          9        640:  76% 316/416 [01:18<00:26,  3.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.091       1.68      2.024          8        640:  76% 317/416 [01:19<00:27,  3.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.093      1.682      2.026          9        640:  76% 318/416 [01:19<00:24,  4.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.091      1.681      2.025          9        640:  77% 319/416 [01:19<00:25,  3.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.091       1.68      2.024         10        640:  77% 320/416 [01:19<00:23,  4.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.091       1.68      2.025         10        640:  77% 321/416 [01:19<00:22,  4.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.091       1.68      2.025          9        640:  77% 322/416 [01:20<00:19,  4.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.089      1.679      2.023          6        640:  78% 323/416 [01:20<00:21,  4.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.09      1.678      2.024          9        640:  78% 324/416 [01:20<00:18,  4.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.09      1.678      2.023          8        640:  78% 325/416 [01:20<00:16,  5.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.093      1.679      2.026          9        640:  78% 326/416 [01:20<00:17,  5.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.093      1.678      2.026          9        640:  79% 327/416 [01:21<00:19,  4.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.092      1.677      2.025          9        640:  79% 328/416 [01:21<00:20,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.093      1.679      2.026         13        640:  79% 329/416 [01:21<00:19,  4.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.092      1.679      2.025          8        640:  79% 330/416 [01:21<00:18,  4.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.092      1.678      2.024          9        640:  80% 331/416 [01:21<00:18,  4.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.092      1.678      2.025          9        640:  80% 332/416 [01:22<00:17,  4.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.092      1.677      2.025         11        640:  80% 333/416 [01:22<00:19,  4.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.091      1.676      2.024          9        640:  80% 334/416 [01:22<00:17,  4.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.091      1.675      2.024          9        640:  81% 335/416 [01:22<00:19,  4.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.091      1.673      2.024          9        640:  81% 336/416 [01:23<00:18,  4.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.093      1.673      2.026         10        640:  81% 337/416 [01:23<00:17,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.092      1.673      2.026          9        640:  81% 338/416 [01:23<00:16,  4.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.092      1.673      2.025         11        640:  81% 339/416 [01:23<00:15,  5.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.092      1.675      2.025         12        640:  82% 340/416 [01:23<00:15,  4.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.092      1.675      2.025          9        640:  82% 341/416 [01:24<00:16,  4.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.092      1.675      2.025         10        640:  82% 342/416 [01:24<00:15,  4.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.091      1.674      2.024          9        640:  82% 343/416 [01:24<00:16,  4.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.09      1.673      2.022          8        640:  83% 344/416 [01:24<00:16,  4.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.088      1.671      2.021          9        640:  83% 345/416 [01:25<00:18,  3.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.088      1.672       2.02          9        640:  83% 346/416 [01:25<00:18,  3.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.087      1.671      2.019          9        640:  83% 347/416 [01:25<00:20,  3.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.086      1.671      2.018         10        640:  84% 348/416 [01:26<00:17,  3.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.086      1.671      2.018          9        640:  84% 349/416 [01:26<00:19,  3.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.086      1.671      2.018         10        640:  84% 350/416 [01:26<00:17,  3.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.087      1.672      2.018         12        640:  84% 351/416 [01:26<00:18,  3.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.087      1.672      2.019         10        640:  85% 352/416 [01:27<00:18,  3.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.088      1.673      2.021         11        640:  85% 353/416 [01:27<00:18,  3.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.088      1.673      2.021          9        640:  85% 354/416 [01:27<00:18,  3.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.088      1.672       2.02         10        640:  85% 355/416 [01:28<00:20,  2.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.087      1.671       2.02          9        640:  86% 356/416 [01:28<00:18,  3.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.087       1.67       2.02         10        640:  86% 357/416 [01:28<00:17,  3.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.086       1.67      2.019          9        640:  86% 358/416 [01:29<00:16,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.086       1.67      2.019          8        640:  86% 359/416 [01:29<00:14,  3.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.086       1.67       2.02          9        640:  87% 360/416 [01:29<00:12,  4.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.087      1.669      2.022          9        640:  87% 361/416 [01:29<00:13,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.087      1.669      2.021         10        640:  87% 362/416 [01:29<00:13,  3.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.087      1.668      2.021         11        640:  87% 363/416 [01:30<00:13,  3.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.086      1.667       2.02          8        640:  88% 364/416 [01:30<00:13,  3.98it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.087      1.667      2.021         11        640:  88% 365/416 [01:30<00:10,  4.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.086      1.666       2.02         11        640:  88% 366/416 [01:30<00:11,  4.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.086      1.666      2.019          9        640:  88% 367/416 [01:31<00:11,  4.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.086      1.666       2.02          9        640:  88% 368/416 [01:31<00:10,  4.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.085      1.665      2.019          8        640:  89% 369/416 [01:31<00:08,  5.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.086      1.665       2.02          9        640:  89% 370/416 [01:31<00:09,  4.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.086      1.665       2.02         11        640:  89% 371/416 [01:31<00:09,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.086      1.663      2.019         10        640:  89% 372/416 [01:32<00:08,  4.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.086      1.663      2.019         11        640:  90% 373/416 [01:32<00:09,  4.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.087      1.664       2.02         12        640:  90% 374/416 [01:32<00:08,  4.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.085      1.663       2.02          8        640:  90% 375/416 [01:32<00:09,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.084      1.662      2.018          8        640:  90% 376/416 [01:33<00:09,  4.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.084      1.662      2.018          9        640:  91% 377/416 [01:33<00:09,  4.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.083      1.663      2.017          8        640:  91% 378/416 [01:33<00:08,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.083      1.665      2.018          8        640:  91% 379/416 [01:33<00:10,  3.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.084      1.665      2.018         11        640:  91% 380/416 [01:33<00:08,  4.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.085      1.665      2.019          9        640:  92% 381/416 [01:34<00:07,  4.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.084      1.663      2.018          9        640:  92% 382/416 [01:34<00:06,  5.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.084      1.663      2.019          9        640:  92% 383/416 [01:34<00:07,  4.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.084      1.663      2.019         10        640:  92% 384/416 [01:34<00:06,  5.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.083      1.662      2.018          9        640:  93% 385/416 [01:34<00:06,  5.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.083      1.662      2.019          9        640:  93% 386/416 [01:35<00:05,  5.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.083      1.661      2.018          9        640:  93% 387/416 [01:35<00:06,  4.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.082       1.66      2.017          9        640:  93% 388/416 [01:35<00:05,  4.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.082       1.66      2.018          9        640:  94% 389/416 [01:35<00:05,  4.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.082       1.66      2.017          8        640:  94% 390/416 [01:35<00:04,  5.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.081      1.659      2.016          8        640:  94% 391/416 [01:36<00:04,  5.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.08      1.657      2.015          6        640:  94% 392/416 [01:36<00:05,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.08      1.657      2.015         11        640:  94% 393/416 [01:36<00:04,  5.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.08      1.656      2.014          9        640:  95% 394/416 [01:36<00:04,  5.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.08      1.656      2.014          9        640:  95% 395/416 [01:37<00:04,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.08      1.656      2.015         10        640:  95% 396/416 [01:37<00:04,  4.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.08      1.656      2.015         10        640:  95% 397/416 [01:37<00:04,  4.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G       1.08      1.655      2.014          8        640:  96% 398/416 [01:37<00:03,  4.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.079      1.655      2.014          7        640:  96% 399/416 [01:37<00:03,  4.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.079      1.655      2.014          9        640:  96% 400/416 [01:38<00:03,  4.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.078      1.655      2.012          8        640:  96% 401/416 [01:38<00:03,  4.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.077      1.655      2.011          7        640:  97% 402/416 [01:38<00:03,  4.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.076      1.654      2.011          9        640:  97% 403/416 [01:38<00:03,  3.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.076      1.654      2.011          9        640:  97% 404/416 [01:39<00:03,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.076      1.654      2.011         12        640:  97% 405/416 [01:39<00:03,  3.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.076      1.654       2.01          9        640:  98% 406/416 [01:39<00:02,  3.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.077      1.653       2.01          9        640:  98% 407/416 [01:40<00:02,  3.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.077      1.654       2.01         10        640:  98% 408/416 [01:40<00:02,  3.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.076      1.653      2.009         10        640:  98% 409/416 [01:40<00:01,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.075      1.652      2.009          9        640:  99% 410/416 [01:41<00:01,  3.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.074       1.65      2.008          7        640:  99% 411/416 [01:41<00:01,  3.07it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.074      1.651      2.007         10        640:  99% 412/416 [01:41<00:01,  3.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.073      1.651      2.007          9        640:  99% 413/416 [01:41<00:00,  3.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.074      1.652      2.007         10        640: 100% 414/416 [01:42<00:00,  3.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.073      1.652      2.007         12        640: 100% 415/416 [01:42<00:00,  3.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       7/10      1.37G      1.073      1.652      2.007          4        640: 100% 416/416 [01:42<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 11/11 [00:01<00:00,  5.59it/s]\n",
            "                   all        174        200      0.351      0.599      0.416       0.28\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/416 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.307      1.757      2.237          9        640:   0% 1/416 [00:00<00:51,  8.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.375      1.816      2.304         10        640:   0% 2/416 [00:00<01:31,  4.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.182      1.656       2.13          8        640:   1% 3/416 [00:00<01:47,  3.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9945      1.502      1.938          8        640:   1% 4/416 [00:00<01:30,  4.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.8539      1.389      1.799          8        640:   1% 5/416 [00:01<01:42,  4.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      0.866      1.493      1.811          9        640:   1% 6/416 [00:01<01:35,  4.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9048      1.484      1.834          9        640:   2% 7/416 [00:01<01:36,  4.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9153      1.492      1.854          9        640:   2% 8/416 [00:01<01:36,  4.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.8865      1.487      1.834          9        640:   2% 9/416 [00:02<01:39,  4.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       0.92      1.603      1.857         10        640:   2% 10/416 [00:02<01:42,  3.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9399      1.583      1.893          7        640:   3% 11/416 [00:02<01:56,  3.47it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9578      1.569      1.913          8        640:   3% 12/416 [00:03<01:50,  3.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      0.965      1.579      1.923          8        640:   3% 13/416 [00:03<01:46,  3.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      0.994       1.58       1.95         11        640:   3% 14/416 [00:03<01:40,  4.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.015      1.582      1.973         11        640:   4% 15/416 [00:03<01:39,  4.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9962       1.57      1.955          9        640:   4% 16/416 [00:03<01:34,  4.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9967      1.573      1.954         10        640:   4% 17/416 [00:04<01:37,  4.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.005      1.565      1.966          9        640:   4% 18/416 [00:04<01:22,  4.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.01      1.571      1.971          9        640:   5% 19/416 [00:04<01:48,  3.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.035      1.593      1.995         13        640:   5% 20/416 [00:04<01:31,  4.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.019      1.591      1.988          8        640:   5% 21/416 [00:05<01:33,  4.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.023      1.572      2.003          8        640:   5% 22/416 [00:05<01:29,  4.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.019      1.545      2.008          8        640:   6% 23/416 [00:05<01:23,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.04      1.551      2.025          9        640:   6% 24/416 [00:05<01:23,  4.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.074      1.555      2.047         11        640:   6% 25/416 [00:05<01:24,  4.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.075      1.549      2.046          8        640:   6% 26/416 [00:06<01:25,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.062      1.533       2.03          9        640:   6% 27/416 [00:06<01:19,  4.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.06      1.535      2.026          8        640:   7% 28/416 [00:06<01:20,  4.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.058      1.543      2.018          9        640:   7% 29/416 [00:06<01:14,  5.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.043      1.544      2.003          9        640:   7% 30/416 [00:06<01:15,  5.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.034      1.534      1.993          8        640:   7% 31/416 [00:07<01:14,  5.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03      1.537      1.987         10        640:   8% 32/416 [00:07<01:12,  5.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.019      1.526      1.978          8        640:   8% 33/416 [00:07<01:15,  5.05it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.014      1.522      1.969          9        640:   8% 34/416 [00:07<01:15,  5.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9996      1.513      1.958          8        640:   8% 35/416 [00:08<01:40,  3.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.006      1.512      1.961         10        640:   9% 36/416 [00:08<01:41,  3.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.002      1.509      1.958          8        640:   9% 37/416 [00:08<01:40,  3.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9975      1.518      1.955          7        640:   9% 38/416 [00:08<01:43,  3.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9879      1.521      1.947          8        640:   9% 39/416 [00:09<01:45,  3.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9977      1.542      1.964          8        640:  10% 40/416 [00:09<01:45,  3.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9872      1.539      1.955          8        640:  10% 41/416 [00:09<01:44,  3.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      0.991      1.536      1.957          9        640:  10% 42/416 [00:10<01:49,  3.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9888      1.542      1.951          9        640:  10% 43/416 [00:10<01:58,  3.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9886      1.555      1.948         10        640:  11% 44/416 [00:10<01:50,  3.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9991      1.574       1.96         10        640:  11% 45/416 [00:10<01:46,  3.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9948      1.574      1.956          8        640:  11% 46/416 [00:11<01:45,  3.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      0.999      1.579      1.958         10        640:  11% 47/416 [00:11<01:45,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.001      1.575      1.957          9        640:  12% 48/416 [00:11<01:41,  3.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.01      1.573      1.966         10        640:  12% 49/416 [00:11<01:29,  4.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.015      1.586       1.97          7        640:  12% 50/416 [00:12<01:39,  3.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.017      1.586      1.972         10        640:  12% 51/416 [00:12<01:36,  3.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.034      1.588      1.984         10        640:  12% 52/416 [00:12<01:33,  3.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.038      1.586      1.987          9        640:  13% 53/416 [00:13<01:30,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.035      1.578      1.986          9        640:  13% 54/416 [00:13<01:20,  4.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.033       1.58      1.985          8        640:  13% 55/416 [00:13<01:33,  3.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.578      1.977          8        640:  13% 56/416 [00:13<01:24,  4.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.569      1.974          9        640:  14% 57/416 [00:13<01:18,  4.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.023      1.565       1.97          9        640:  14% 58/416 [00:14<01:11,  4.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.023      1.567      1.969          8        640:  14% 59/416 [00:14<01:31,  3.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.017      1.561      1.963          8        640:  14% 60/416 [00:14<01:32,  3.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.013      1.555      1.961          8        640:  15% 61/416 [00:14<01:24,  4.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.017      1.556      1.963         10        640:  15% 62/416 [00:15<01:26,  4.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.021      1.559      1.968          9        640:  15% 63/416 [00:15<01:24,  4.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.016      1.554      1.965          8        640:  15% 64/416 [00:15<01:26,  4.07it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.011      1.549      1.958          8        640:  16% 65/416 [00:15<01:17,  4.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.004      1.537      1.951          8        640:  16% 66/416 [00:16<01:17,  4.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.001      1.542      1.945          8        640:  16% 67/416 [00:16<01:23,  4.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9988      1.542      1.942         10        640:  16% 68/416 [00:16<01:13,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9968      1.545      1.943          8        640:  17% 69/416 [00:16<01:12,  4.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9934      1.543      1.942          8        640:  17% 70/416 [00:16<01:06,  5.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      0.992      1.544      1.942         11        640:  17% 71/416 [00:17<01:12,  4.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9911      1.543      1.941          8        640:  17% 72/416 [00:17<01:09,  4.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9881      1.541      1.938          7        640:  18% 73/416 [00:17<01:04,  5.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9897      1.542      1.939          9        640:  18% 74/416 [00:17<01:09,  4.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9943      1.544      1.943         10        640:  18% 75/416 [00:17<01:20,  4.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G          1      1.544      1.949         10        640:  18% 76/416 [00:18<01:13,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.004       1.55      1.954          9        640:  19% 77/416 [00:18<01:12,  4.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.004       1.55      1.959          8        640:  19% 78/416 [00:18<01:20,  4.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.004      1.549      1.958         11        640:  19% 79/416 [00:18<01:14,  4.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.002      1.546      1.957         10        640:  19% 80/416 [00:19<01:13,  4.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.006      1.544      1.963          8        640:  19% 81/416 [00:19<01:09,  4.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G          1      1.539      1.957          9        640:  20% 82/416 [00:19<01:09,  4.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9928      1.533      1.949          8        640:  20% 83/416 [00:19<01:14,  4.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9948      1.533      1.951          9        640:  20% 84/416 [00:19<01:07,  4.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9951      1.531      1.952          9        640:  20% 85/416 [00:20<01:15,  4.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9904       1.53      1.946          9        640:  21% 86/416 [00:20<01:12,  4.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      0.986       1.53      1.942          9        640:  21% 87/416 [00:20<01:19,  4.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9844       1.53      1.941          9        640:  21% 88/416 [00:20<01:14,  4.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9831       1.53      1.938          8        640:  21% 89/416 [00:20<01:09,  4.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      0.984      1.536       1.94         11        640:  22% 90/416 [00:21<01:08,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9866      1.539      1.943          9        640:  22% 91/416 [00:21<01:13,  4.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9856       1.54      1.942         10        640:  22% 92/416 [00:21<01:06,  4.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9888      1.539      1.946          9        640:  22% 93/416 [00:21<01:22,  3.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9907      1.541      1.949         10        640:  23% 94/416 [00:22<01:27,  3.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9943       1.54      1.955          8        640:  23% 95/416 [00:22<01:24,  3.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9989      1.543      1.958         12        640:  23% 96/416 [00:22<01:32,  3.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G          1       1.55       1.96          9        640:  23% 97/416 [00:23<01:32,  3.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.006      1.553      1.968          9        640:  24% 98/416 [00:23<01:29,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.009      1.556      1.968         14        640:  24% 99/416 [00:23<01:33,  3.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.004      1.553      1.963          8        640:  24% 100/416 [00:24<01:37,  3.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.002      1.551      1.961          8        640:  24% 101/416 [00:24<01:36,  3.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.002      1.551      1.961          8        640:  25% 102/416 [00:24<01:34,  3.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.001      1.547       1.96          9        640:  25% 103/416 [00:24<01:30,  3.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.001      1.544       1.96          9        640:  25% 104/416 [00:25<01:30,  3.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G          1      1.543      1.957          8        640:  25% 105/416 [00:25<01:29,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9955      1.539      1.952          9        640:  25% 106/416 [00:25<01:13,  4.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9973      1.545      1.954         11        640:  26% 107/416 [00:25<01:21,  3.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9975      1.545      1.954         10        640:  26% 108/416 [00:26<01:17,  3.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.001      1.546      1.957         11        640:  26% 109/416 [00:26<01:17,  3.98it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.002      1.547      1.957          9        640:  26% 110/416 [00:26<01:08,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.001      1.547      1.956         10        640:  27% 111/416 [00:26<01:15,  4.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9973      1.549      1.953          7        640:  27% 112/416 [00:27<01:20,  3.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9948       1.55       1.95          8        640:  27% 113/416 [00:27<01:25,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9923      1.545      1.948          8        640:  27% 114/416 [00:27<01:20,  3.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9971      1.549      1.951         13        640:  28% 115/416 [00:28<01:30,  3.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9973      1.548       1.95         10        640:  28% 116/416 [00:28<01:26,  3.47it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9956      1.549      1.948          9        640:  28% 117/416 [00:28<01:21,  3.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G     0.9985       1.55      1.951          7        640:  28% 118/416 [00:28<01:18,  3.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.001      1.554      1.953          8        640:  29% 119/416 [00:29<01:09,  4.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.002      1.554      1.954         10        640:  29% 120/416 [00:29<01:03,  4.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.002      1.551      1.953         10        640:  29% 121/416 [00:29<01:03,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.003      1.551      1.954          9        640:  29% 122/416 [00:29<01:06,  4.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.003       1.55      1.953          9        640:  30% 123/416 [00:29<01:01,  4.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.001      1.549      1.952          8        640:  30% 124/416 [00:30<01:02,  4.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.003      1.552      1.954         10        640:  30% 125/416 [00:30<01:02,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.008      1.553      1.961          9        640:  30% 126/416 [00:30<00:59,  4.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.008      1.557      1.961          9        640:  31% 127/416 [00:30<01:01,  4.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.007      1.555      1.959          9        640:  31% 128/416 [00:30<01:00,  4.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.009      1.556      1.961          9        640:  31% 129/416 [00:31<00:57,  4.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.008      1.553      1.959          8        640:  31% 130/416 [00:31<00:59,  4.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.009      1.555       1.96          8        640:  31% 131/416 [00:31<00:58,  4.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.01      1.553       1.96          9        640:  32% 132/416 [00:31<00:58,  4.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.008      1.551      1.959          9        640:  32% 133/416 [00:31<00:55,  5.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.007      1.553      1.958          8        640:  32% 134/416 [00:32<00:59,  4.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.009      1.556      1.959          9        640:  32% 135/416 [00:32<01:00,  4.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.013      1.561      1.962         16        640:  33% 136/416 [00:32<00:58,  4.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.012      1.561       1.96          8        640:  33% 137/416 [00:32<01:03,  4.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.012      1.562      1.959         10        640:  33% 138/416 [00:33<01:05,  4.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.013      1.561      1.961         10        640:  33% 139/416 [00:33<01:05,  4.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.018      1.565      1.965         13        640:  34% 140/416 [00:33<00:58,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.017      1.564      1.964          8        640:  34% 141/416 [00:33<01:01,  4.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.016      1.562      1.963         10        640:  34% 142/416 [00:34<01:04,  4.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.015      1.561      1.962          8        640:  34% 143/416 [00:34<01:03,  4.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.016      1.561      1.962         10        640:  35% 144/416 [00:34<01:02,  4.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.013       1.56      1.959          8        640:  35% 145/416 [00:34<00:59,  4.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.01      1.557      1.957          9        640:  35% 146/416 [00:34<00:53,  5.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.011      1.559      1.958          8        640:  35% 147/416 [00:35<01:02,  4.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.014      1.562       1.96         10        640:  36% 148/416 [00:35<00:58,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.013      1.561       1.96          9        640:  36% 149/416 [00:35<00:54,  4.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.013       1.56      1.959          9        640:  36% 150/416 [00:35<01:09,  3.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.012      1.558      1.957          9        640:  36% 151/416 [00:36<01:12,  3.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.013      1.563      1.958         11        640:  37% 152/416 [00:36<01:17,  3.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.015      1.566      1.959          9        640:  37% 153/416 [00:36<01:14,  3.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.012      1.563      1.956          8        640:  37% 154/416 [00:37<01:16,  3.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.011      1.561      1.954         10        640:  37% 155/416 [00:37<01:22,  3.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.011       1.56      1.955          9        640:  38% 156/416 [00:37<01:17,  3.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.012      1.562      1.956         10        640:  38% 157/416 [00:38<01:17,  3.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.014      1.562      1.959          9        640:  38% 158/416 [00:38<01:20,  3.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.013      1.562      1.958         10        640:  38% 159/416 [00:38<01:11,  3.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.01      1.559      1.955          8        640:  38% 160/416 [00:38<01:11,  3.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.012      1.559      1.958          9        640:  39% 161/416 [00:39<01:12,  3.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.012       1.56      1.956          9        640:  39% 162/416 [00:39<01:14,  3.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.013      1.561      1.956         11        640:  39% 163/416 [00:39<01:14,  3.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.015      1.562      1.957         12        640:  39% 164/416 [00:39<01:04,  3.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.015      1.564      1.955          9        640:  40% 165/416 [00:40<00:58,  4.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.017      1.565      1.957         11        640:  40% 166/416 [00:40<01:05,  3.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.016      1.565      1.957         10        640:  40% 167/416 [00:40<01:03,  3.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.019      1.567      1.959         15        640:  40% 168/416 [00:40<01:04,  3.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.019      1.566      1.958          9        640:  41% 169/416 [00:41<01:02,  3.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.019      1.563      1.959         10        640:  41% 170/416 [00:41<01:00,  4.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.018      1.564      1.958         11        640:  41% 171/416 [00:41<01:02,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.018      1.565      1.959          9        640:  41% 172/416 [00:41<00:59,  4.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.019      1.568      1.959         11        640:  42% 173/416 [00:42<00:59,  4.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.018      1.567      1.958          8        640:  42% 174/416 [00:42<01:02,  3.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.018      1.566      1.959         12        640:  42% 175/416 [00:42<01:04,  3.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.017      1.564      1.957          9        640:  42% 176/416 [00:42<00:59,  4.07it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.016      1.561      1.955          9        640:  43% 177/416 [00:43<00:57,  4.12it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.016       1.56      1.955         10        640:  43% 178/416 [00:43<00:56,  4.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.018      1.563      1.959         11        640:  43% 179/416 [00:43<01:03,  3.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.019      1.566      1.961          7        640:  43% 180/416 [00:43<00:53,  4.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.022      1.567      1.963         11        640:  44% 181/416 [00:44<00:50,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.021      1.567      1.961         10        640:  44% 182/416 [00:44<00:44,  5.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.019      1.566      1.958          7        640:  44% 183/416 [00:44<00:57,  4.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.019      1.565      1.957         10        640:  44% 184/416 [00:44<00:56,  4.07it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.021      1.565      1.959         10        640:  44% 185/416 [00:45<00:54,  4.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.022      1.565       1.96         10        640:  45% 186/416 [00:45<00:51,  4.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.021      1.565      1.959          8        640:  45% 187/416 [00:45<00:48,  4.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.021      1.565      1.959          7        640:  45% 188/416 [00:45<00:52,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.02      1.564      1.959          8        640:  45% 189/416 [00:45<00:51,  4.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.021      1.566      1.961         10        640:  46% 190/416 [00:46<00:47,  4.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.021      1.566      1.962          9        640:  46% 191/416 [00:46<00:54,  4.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.569      1.964         13        640:  46% 192/416 [00:46<00:55,  4.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024       1.57      1.964          8        640:  46% 193/416 [00:46<00:50,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.569      1.964         10        640:  47% 194/416 [00:47<00:50,  4.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.574      1.968          8        640:  47% 195/416 [00:47<00:54,  4.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.574      1.968         11        640:  47% 196/416 [00:47<00:50,  4.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.031      1.575      1.969          9        640:  47% 197/416 [00:47<00:51,  4.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.032      1.576       1.97          9        640:  48% 198/416 [00:47<00:49,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.032      1.577      1.969          8        640:  48% 199/416 [00:48<00:52,  4.12it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03      1.576      1.967          8        640:  48% 200/416 [00:48<00:49,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.027      1.574      1.964          8        640:  48% 201/416 [00:48<00:48,  4.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.572      1.963          9        640:  49% 202/416 [00:48<00:45,  4.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.027      1.573      1.963         11        640:  49% 203/416 [00:49<00:48,  4.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.027      1.572      1.964         10        640:  49% 204/416 [00:49<00:41,  5.05it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.574      1.966          9        640:  49% 205/416 [00:49<00:40,  5.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.573      1.965         10        640:  50% 206/416 [00:49<00:50,  4.12it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.033      1.577      1.969         14        640:  50% 207/416 [00:50<00:51,  4.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.033      1.581      1.969         11        640:  50% 208/416 [00:50<00:53,  3.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.033       1.58      1.969         10        640:  50% 209/416 [00:50<00:57,  3.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.031      1.581      1.967          8        640:  50% 210/416 [00:50<00:58,  3.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.032      1.582      1.968          8        640:  51% 211/416 [00:51<01:02,  3.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.034      1.583      1.971         12        640:  51% 212/416 [00:51<01:00,  3.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.034      1.582      1.971          8        640:  51% 213/416 [00:51<00:58,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.032      1.581       1.97          8        640:  51% 214/416 [00:52<00:58,  3.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03      1.579      1.968          9        640:  52% 215/416 [00:52<01:00,  3.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03      1.579      1.967          8        640:  52% 216/416 [00:52<00:55,  3.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03       1.58      1.968          9        640:  52% 217/416 [00:53<00:58,  3.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.032      1.581      1.969         10        640:  52% 218/416 [00:53<00:53,  3.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03       1.58      1.968          8        640:  53% 219/416 [00:53<01:01,  3.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.031       1.58       1.97         10        640:  53% 220/416 [00:53<00:56,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.581      1.969          9        640:  53% 221/416 [00:54<00:47,  4.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.031      1.583       1.97          8        640:  53% 222/416 [00:54<00:51,  3.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03      1.581      1.969          8        640:  54% 223/416 [00:54<00:49,  3.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.578      1.967          9        640:  54% 224/416 [00:54<00:49,  3.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03       1.58      1.968         11        640:  54% 225/416 [00:54<00:44,  4.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.579      1.967         11        640:  54% 226/416 [00:55<00:46,  4.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.579      1.967         10        640:  55% 227/416 [00:55<00:50,  3.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.576      1.967          8        640:  55% 228/416 [00:55<00:47,  3.98it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.027      1.574      1.966          9        640:  55% 229/416 [00:56<00:46,  4.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.578      1.969         12        640:  55% 230/416 [00:56<00:45,  4.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.578      1.968          7        640:  56% 231/416 [00:56<00:47,  3.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.577      1.965          8        640:  56% 232/416 [00:56<00:42,  4.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.577      1.965          9        640:  56% 233/416 [00:56<00:43,  4.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.577      1.963          9        640:  56% 234/416 [00:57<00:39,  4.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.577      1.963          9        640:  56% 235/416 [00:57<00:42,  4.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.576      1.962         10        640:  57% 236/416 [00:57<00:41,  4.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.575      1.963          9        640:  57% 237/416 [00:57<00:37,  4.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.023      1.574      1.961          9        640:  57% 238/416 [00:58<00:40,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.579      1.964         14        640:  57% 239/416 [00:58<00:41,  4.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.578      1.962          8        640:  58% 240/416 [00:58<00:39,  4.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026       1.58      1.963         10        640:  58% 241/416 [00:58<00:36,  4.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.027      1.578      1.965          8        640:  58% 242/416 [00:59<00:42,  4.13it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03      1.582      1.968         14        640:  58% 243/416 [00:59<00:41,  4.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03      1.582      1.968          9        640:  59% 244/416 [00:59<00:41,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.583      1.966         10        640:  59% 245/416 [00:59<00:38,  4.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.582      1.964          8        640:  59% 246/416 [00:59<00:35,  4.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.583      1.965         10        640:  59% 247/416 [01:00<00:33,  5.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.582      1.964          7        640:  60% 248/416 [01:00<00:36,  4.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.581      1.964         11        640:  60% 249/416 [01:00<00:35,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.582      1.965         10        640:  60% 250/416 [01:00<00:40,  4.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.031      1.583      1.967         10        640:  60% 251/416 [01:01<00:43,  3.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.035      1.585      1.973          7        640:  61% 252/416 [01:01<00:35,  4.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.035      1.582      1.973          8        640:  61% 253/416 [01:01<00:38,  4.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.033      1.582      1.972          8        640:  61% 254/416 [01:01<00:41,  3.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.032       1.58      1.971         10        640:  61% 255/416 [01:01<00:35,  4.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.032      1.581       1.97         10        640:  62% 256/416 [01:02<00:34,  4.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03      1.581      1.968          8        640:  62% 257/416 [01:02<00:32,  4.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.031      1.583      1.969          8        640:  62% 258/416 [01:02<00:32,  4.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03      1.583      1.969         10        640:  62% 259/416 [01:02<00:34,  4.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03      1.583      1.968          8        640:  62% 260/416 [01:03<00:34,  4.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.032      1.585       1.97         10        640:  63% 261/416 [01:03<00:33,  4.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.032      1.585       1.97         10        640:  63% 262/416 [01:03<00:35,  4.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.031      1.585      1.969          9        640:  63% 263/416 [01:03<00:39,  3.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.031      1.585      1.969         12        640:  63% 264/416 [01:04<00:39,  3.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03      1.584      1.968         10        640:  64% 265/416 [01:04<00:43,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.583      1.965          8        640:  64% 266/416 [01:04<00:41,  3.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.027      1.583      1.964          9        640:  64% 267/416 [01:05<00:47,  3.13it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025       1.58      1.962          8        640:  64% 268/416 [01:05<00:42,  3.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025       1.58      1.963          8        640:  65% 269/416 [01:05<00:41,  3.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.578      1.963          7        640:  65% 270/416 [01:05<00:44,  3.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.581      1.966         16        640:  65% 271/416 [01:06<00:43,  3.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029       1.58      1.966          8        640:  65% 272/416 [01:06<00:43,  3.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.032       1.58      1.969          9        640:  66% 273/416 [01:06<00:43,  3.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.034       1.58       1.97         10        640:  66% 274/416 [01:07<00:43,  3.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.032       1.58      1.968          9        640:  66% 275/416 [01:07<00:45,  3.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.033      1.582      1.969         10        640:  66% 276/416 [01:07<00:42,  3.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.035      1.584       1.97         13        640:  67% 277/416 [01:08<00:40,  3.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.037      1.586      1.971         10        640:  67% 278/416 [01:08<00:36,  3.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.036      1.587       1.97          8        640:  67% 279/416 [01:08<00:33,  4.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.037      1.586      1.972          9        640:  67% 280/416 [01:08<00:34,  3.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.037      1.586      1.971          7        640:  68% 281/416 [01:09<00:34,  3.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.037      1.587      1.972         10        640:  68% 282/416 [01:09<00:34,  3.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.038      1.587      1.973          9        640:  68% 283/416 [01:09<00:38,  3.47it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.038      1.588      1.973          9        640:  68% 284/416 [01:09<00:36,  3.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.038      1.587      1.974         10        640:  69% 285/416 [01:10<00:36,  3.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.038      1.587      1.973          9        640:  69% 286/416 [01:10<00:35,  3.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.038      1.586      1.974          9        640:  69% 287/416 [01:10<00:29,  4.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.037      1.584      1.972         10        640:  69% 288/416 [01:10<00:30,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.036      1.583      1.972          8        640:  69% 289/416 [01:11<00:31,  4.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.036      1.583      1.972          9        640:  70% 290/416 [01:11<00:29,  4.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.035      1.582      1.971          8        640:  70% 291/416 [01:11<00:32,  3.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.036      1.583      1.972         10        640:  70% 292/416 [01:11<00:28,  4.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.037      1.583      1.973         10        640:  70% 293/416 [01:11<00:27,  4.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.035      1.582      1.971          8        640:  71% 294/416 [01:12<00:26,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.034      1.582       1.97          9        640:  71% 295/416 [01:12<00:28,  4.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.034      1.582      1.969          8        640:  71% 296/416 [01:12<00:31,  3.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.032       1.58      1.969          9        640:  71% 297/416 [01:12<00:29,  4.05it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.032      1.579      1.969         10        640:  72% 298/416 [01:13<00:28,  4.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.031      1.579      1.968         10        640:  72% 299/416 [01:13<00:26,  4.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.031      1.579      1.968         10        640:  72% 300/416 [01:13<00:23,  4.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03      1.578      1.967          9        640:  72% 301/416 [01:13<00:24,  4.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03       1.58      1.967         10        640:  73% 302/416 [01:14<00:26,  4.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.032      1.582      1.969         12        640:  73% 303/416 [01:14<00:26,  4.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.032      1.582      1.968         10        640:  73% 304/416 [01:14<00:26,  4.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.032      1.582      1.968         10        640:  73% 305/416 [01:14<00:26,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.031      1.582      1.967          9        640:  74% 306/416 [01:14<00:24,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.031      1.581      1.965          9        640:  74% 307/416 [01:15<00:23,  4.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03       1.58      1.965          9        640:  74% 308/416 [01:15<00:22,  4.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03       1.58      1.965          8        640:  74% 309/416 [01:15<00:21,  4.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03      1.579      1.966          9        640:  75% 310/416 [01:15<00:23,  4.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.031       1.58      1.967          8        640:  75% 311/416 [01:16<00:23,  4.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.579      1.965          8        640:  75% 312/416 [01:16<00:22,  4.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.578      1.964          9        640:  75% 313/416 [01:16<00:19,  5.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.578      1.964         11        640:  75% 314/416 [01:16<00:19,  5.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.577      1.964          9        640:  76% 315/416 [01:16<00:21,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.578      1.964         14        640:  76% 316/416 [01:17<00:22,  4.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.578      1.966         10        640:  76% 317/416 [01:17<00:20,  4.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.577      1.965         10        640:  76% 318/416 [01:17<00:19,  4.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.575      1.966          8        640:  77% 319/416 [01:17<00:21,  4.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.027      1.574      1.965          9        640:  77% 320/416 [01:18<00:24,  3.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.574      1.964          8        640:  77% 321/416 [01:18<00:24,  3.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.573      1.964          9        640:  77% 322/416 [01:18<00:24,  3.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.027      1.574      1.965         11        640:  78% 323/416 [01:18<00:23,  3.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.027      1.574      1.965         11        640:  78% 324/416 [01:19<00:26,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.573      1.964          8        640:  78% 325/416 [01:19<00:25,  3.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.572      1.964          9        640:  78% 326/416 [01:19<00:25,  3.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.572      1.963          8        640:  79% 327/416 [01:19<00:23,  3.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.571      1.963         10        640:  79% 328/416 [01:20<00:23,  3.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024       1.57      1.962          9        640:  79% 329/416 [01:20<00:25,  3.47it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025       1.57      1.963          7        640:  79% 330/416 [01:20<00:25,  3.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024       1.57      1.963          9        640:  80% 331/416 [01:21<00:27,  3.05it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024       1.57      1.962          9        640:  80% 332/416 [01:21<00:25,  3.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.569      1.963         10        640:  80% 333/416 [01:21<00:24,  3.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.569      1.962          8        640:  80% 334/416 [01:22<00:23,  3.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.569      1.963          9        640:  81% 335/416 [01:22<00:23,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.569      1.964          8        640:  81% 336/416 [01:22<00:23,  3.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.569      1.965          8        640:  81% 337/416 [01:22<00:22,  3.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.567      1.963          8        640:  81% 338/416 [01:23<00:18,  4.12it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.567      1.962          8        640:  81% 339/416 [01:23<00:18,  4.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.568      1.964         16        640:  82% 340/416 [01:23<00:16,  4.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.568      1.963          8        640:  82% 341/416 [01:23<00:17,  4.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.567      1.963          9        640:  82% 342/416 [01:23<00:16,  4.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.567      1.962         10        640:  82% 343/416 [01:24<00:18,  4.05it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.568      1.963          8        640:  83% 344/416 [01:24<00:15,  4.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.568      1.963         10        640:  83% 345/416 [01:24<00:14,  4.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.568      1.963          9        640:  83% 346/416 [01:24<00:15,  4.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.568      1.961         10        640:  83% 347/416 [01:25<00:15,  4.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.023      1.568      1.961          9        640:  84% 348/416 [01:25<00:15,  4.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.569      1.961          9        640:  84% 349/416 [01:25<00:13,  4.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.569      1.961         10        640:  84% 350/416 [01:25<00:13,  5.07it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.568       1.96          9        640:  84% 351/416 [01:25<00:11,  5.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.023      1.567       1.96          8        640:  85% 352/416 [01:26<00:14,  4.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.023      1.566       1.96          9        640:  85% 353/416 [01:26<00:12,  5.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.566      1.961          9        640:  85% 354/416 [01:26<00:12,  5.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.566      1.961         10        640:  85% 355/416 [01:26<00:13,  4.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.566      1.961         10        640:  86% 356/416 [01:26<00:12,  4.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.565      1.962         11        640:  86% 357/416 [01:27<00:11,  5.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.564      1.962          8        640:  86% 358/416 [01:27<00:11,  5.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.565      1.961          8        640:  86% 359/416 [01:27<00:10,  5.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.564       1.96         10        640:  87% 360/416 [01:27<00:12,  4.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.562       1.96          9        640:  87% 361/416 [01:27<00:11,  4.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.023      1.561      1.959          8        640:  87% 362/416 [01:28<00:11,  4.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.561       1.96          9        640:  87% 363/416 [01:28<00:10,  4.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.561       1.96          9        640:  88% 364/416 [01:28<00:09,  5.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.023       1.56       1.96         10        640:  88% 365/416 [01:28<00:11,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024       1.56       1.96         10        640:  88% 366/416 [01:28<00:11,  4.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024       1.56      1.961         10        640:  88% 367/416 [01:29<00:10,  4.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.023       1.56       1.96          8        640:  88% 368/416 [01:29<00:08,  5.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.562      1.962         10        640:  89% 369/416 [01:29<00:08,  5.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.561      1.962          9        640:  89% 370/416 [01:29<00:09,  4.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.023      1.561      1.961          8        640:  89% 371/416 [01:29<00:09,  4.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.561      1.962          9        640:  89% 372/416 [01:30<00:08,  5.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.561      1.962          9        640:  90% 373/416 [01:30<00:08,  4.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.023       1.56      1.962          8        640:  90% 374/416 [01:30<00:08,  4.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.023      1.559      1.962          9        640:  90% 375/416 [01:30<00:08,  5.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.558      1.963          9        640:  90% 376/416 [01:30<00:08,  4.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.558      1.963         10        640:  91% 377/416 [01:31<00:07,  5.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.558      1.964          9        640:  91% 378/416 [01:31<00:06,  5.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.024      1.557      1.963          8        640:  91% 379/416 [01:31<00:08,  4.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.557      1.964          8        640:  91% 380/416 [01:31<00:08,  4.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.556      1.964          8        640:  92% 381/416 [01:32<00:08,  4.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.556      1.964          8        640:  92% 382/416 [01:32<00:08,  3.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.025      1.556      1.964         10        640:  92% 383/416 [01:32<00:08,  3.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.557      1.964         10        640:  92% 384/416 [01:32<00:08,  3.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.557      1.965          9        640:  93% 385/416 [01:33<00:08,  3.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.557      1.965         10        640:  93% 386/416 [01:33<00:08,  3.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.027      1.557      1.965         10        640:  93% 387/416 [01:33<00:08,  3.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.027      1.557      1.966          9        640:  93% 388/416 [01:34<00:08,  3.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.557      1.967          9        640:  94% 389/416 [01:34<00:07,  3.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.027      1.556      1.965          8        640:  94% 390/416 [01:34<00:07,  3.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.557      1.966         13        640:  94% 391/416 [01:35<00:07,  3.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.559      1.967         10        640:  94% 392/416 [01:35<00:07,  3.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.558      1.968         10        640:  94% 393/416 [01:35<00:07,  3.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.557      1.968         11        640:  95% 394/416 [01:35<00:05,  3.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03      1.557      1.968          8        640:  95% 395/416 [01:36<00:05,  3.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03      1.558      1.969         13        640:  95% 396/416 [01:36<00:04,  4.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.031      1.558      1.969          8        640:  95% 397/416 [01:36<00:04,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G       1.03      1.558      1.969          8        640:  96% 398/416 [01:36<00:04,  3.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.556      1.968          8        640:  96% 399/416 [01:37<00:04,  4.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.556      1.967         10        640:  96% 400/416 [01:37<00:03,  4.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.556      1.966          9        640:  96% 401/416 [01:37<00:03,  3.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.556      1.966         10        640:  97% 402/416 [01:37<00:03,  3.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.027      1.556      1.965          9        640:  97% 403/416 [01:38<00:03,  3.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.557      1.966          9        640:  97% 404/416 [01:38<00:02,  4.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.557      1.966         10        640:  97% 405/416 [01:38<00:02,  3.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.558      1.966          8        640:  98% 406/416 [01:38<00:02,  3.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.557      1.965          9        640:  98% 407/416 [01:39<00:02,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.558      1.966         10        640:  98% 408/416 [01:39<00:01,  4.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.557      1.965          9        640:  98% 409/416 [01:39<00:01,  4.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.029      1.558      1.965         10        640:  99% 410/416 [01:39<00:01,  4.13it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.557      1.964          8        640:  99% 411/416 [01:40<00:01,  3.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.557      1.964          8        640:  99% 412/416 [01:40<00:00,  4.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.028      1.556      1.964          8        640:  99% 413/416 [01:40<00:00,  5.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.027      1.556      1.963         10        640: 100% 414/416 [01:40<00:00,  4.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.026      1.555      1.962          8        640: 100% 415/416 [01:40<00:00,  4.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       8/10      1.38G      1.027      1.556      1.963          3        640: 100% 416/416 [01:41<00:00,  4.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 11/11 [00:01<00:00,  5.63it/s]\n",
            "                   all        174        200      0.357      0.704      0.499      0.335\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/416 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.148      1.725      1.903         12        640:   0% 1/416 [00:00<00:56,  7.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.222      1.501      2.103         10        640:   0% 2/416 [00:00<00:58,  7.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.113      1.472      1.974          9        640:   1% 3/416 [00:00<01:24,  4.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.161      1.512      2.009         12        640:   1% 4/416 [00:00<01:25,  4.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.153      1.631      1.995         10        640:   1% 5/416 [00:01<01:30,  4.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.131      1.649          2          8        640:   1% 6/416 [00:01<01:38,  4.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G       1.12      1.656      1.988         10        640:   2% 7/416 [00:01<01:35,  4.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.109      1.642      1.978          9        640:   2% 8/416 [00:01<01:26,  4.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.084      1.639      1.969          8        640:   2% 9/416 [00:01<01:30,  4.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.065      1.599      1.936          9        640:   2% 10/416 [00:02<01:32,  4.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.054      1.591      1.929          8        640:   3% 11/416 [00:02<01:45,  3.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.045      1.603      1.932         11        640:   3% 12/416 [00:02<01:38,  4.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.089       1.62      1.956         12        640:   3% 13/416 [00:03<01:52,  3.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.053      1.596      1.928          9        640:   3% 14/416 [00:03<01:57,  3.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.051      1.607      1.925          9        640:   4% 15/416 [00:03<01:54,  3.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.035       1.57      1.919          9        640:   4% 16/416 [00:03<01:52,  3.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G       1.06      1.595      1.936          9        640:   4% 17/416 [00:04<01:53,  3.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.054      1.632      1.937          8        640:   4% 18/416 [00:04<01:52,  3.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.048      1.613      1.934          8        640:   5% 19/416 [00:04<02:04,  3.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.029      1.617      1.918          8        640:   5% 20/416 [00:05<01:55,  3.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.012      1.601      1.904          8        640:   5% 21/416 [00:05<01:56,  3.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.039        1.6      1.931          9        640:   5% 22/416 [00:05<01:58,  3.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.026      1.595      1.914         10        640:   6% 23/416 [00:06<02:02,  3.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.025      1.587      1.921         10        640:   6% 24/416 [00:06<02:00,  3.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.032      1.572      1.932          9        640:   6% 25/416 [00:06<01:58,  3.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.029      1.561      1.936          9        640:   6% 26/416 [00:06<01:53,  3.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.033      1.555      1.939         11        640:   6% 27/416 [00:07<02:02,  3.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.035      1.572      1.944         12        640:   7% 28/416 [00:07<01:53,  3.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.023      1.557      1.931          9        640:   7% 29/416 [00:07<01:48,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.021      1.549      1.933         10        640:   7% 30/416 [00:08<01:40,  3.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.027      1.553      1.945          7        640:   7% 31/416 [00:08<01:35,  4.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.031      1.549      1.952          9        640:   8% 32/416 [00:08<01:36,  3.98it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.058      1.573      1.975         20        640:   8% 33/416 [00:08<01:35,  3.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.068      1.584      1.982         14        640:   8% 34/416 [00:08<01:30,  4.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G       1.06      1.579      1.974          8        640:   8% 35/416 [00:09<01:43,  3.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.047      1.563      1.964          9        640:   9% 36/416 [00:09<01:48,  3.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.052      1.564      1.969         10        640:   9% 37/416 [00:09<01:40,  3.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G       1.05      1.562      1.966          9        640:   9% 38/416 [00:10<01:32,  4.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.041      1.548      1.957          8        640:   9% 39/416 [00:10<01:23,  4.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.028      1.543      1.943          8        640:  10% 40/416 [00:10<01:24,  4.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.024      1.539      1.938         10        640:  10% 41/416 [00:10<01:16,  4.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.025      1.538      1.939         10        640:  10% 42/416 [00:10<01:18,  4.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.024      1.535      1.934          8        640:  10% 43/416 [00:10<01:13,  5.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G       1.03      1.544       1.94          8        640:  11% 44/416 [00:11<01:24,  4.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.029      1.542      1.942          9        640:  11% 45/416 [00:11<01:20,  4.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.022       1.54      1.936          9        640:  11% 46/416 [00:11<01:29,  4.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G       1.03      1.541      1.943          9        640:  11% 47/416 [00:11<01:26,  4.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.023      1.539      1.934          7        640:  12% 48/416 [00:12<01:22,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G       1.01      1.527      1.922          8        640:  12% 49/416 [00:12<01:16,  4.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.018      1.526      1.932         10        640:  12% 50/416 [00:12<01:14,  4.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.017      1.524      1.934          8        640:  12% 51/416 [00:12<01:17,  4.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.012      1.519      1.929          8        640:  12% 52/416 [00:12<01:12,  4.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.014      1.521       1.93          9        640:  13% 53/416 [00:13<01:15,  4.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.017      1.523      1.932          9        640:  13% 54/416 [00:13<01:11,  5.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.028      1.528      1.944         10        640:  13% 55/416 [00:13<01:08,  5.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.025      1.528      1.944          9        640:  13% 56/416 [00:13<01:16,  4.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.027       1.53      1.949          9        640:  14% 57/416 [00:13<01:13,  4.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.019      1.524      1.943          9        640:  14% 58/416 [00:14<01:17,  4.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.021      1.528      1.944          9        640:  14% 59/416 [00:14<01:16,  4.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.024      1.528      1.947          9        640:  14% 60/416 [00:14<01:20,  4.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.021      1.522      1.942          9        640:  15% 61/416 [00:14<01:12,  4.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.014      1.518      1.933          7        640:  15% 62/416 [00:14<01:04,  5.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G       1.02      1.522      1.939          9        640:  15% 63/416 [00:15<01:15,  4.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.017      1.525      1.935          8        640:  15% 64/416 [00:15<01:19,  4.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.019      1.523      1.939          8        640:  16% 65/416 [00:15<01:15,  4.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.016      1.525      1.936          9        640:  16% 66/416 [00:15<01:22,  4.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.014      1.519      1.933          8        640:  16% 67/416 [00:16<01:16,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.006       1.51      1.925          8        640:  16% 68/416 [00:16<01:27,  3.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.001      1.508      1.921          9        640:  17% 69/416 [00:16<01:34,  3.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.003       1.51      1.925          9        640:  17% 70/416 [00:17<01:35,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.003      1.512      1.919          9        640:  17% 71/416 [00:17<01:30,  3.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.002      1.516      1.919          8        640:  17% 72/416 [00:17<01:37,  3.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9951      1.511      1.912          9        640:  18% 73/416 [00:17<01:35,  3.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9943      1.506       1.91          9        640:  18% 74/416 [00:18<01:35,  3.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9907      1.507      1.905          8        640:  18% 75/416 [00:18<01:44,  3.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9901      1.504      1.906         10        640:  18% 76/416 [00:18<01:37,  3.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9962      1.506      1.911         10        640:  19% 77/416 [00:19<01:38,  3.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.012      1.517      1.924         15        640:  19% 78/416 [00:19<01:36,  3.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.013      1.518      1.924          8        640:  19% 79/416 [00:19<01:35,  3.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.009      1.513      1.919          8        640:  19% 80/416 [00:19<01:34,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.013      1.519      1.927         10        640:  19% 81/416 [00:20<01:35,  3.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.009      1.518      1.923          7        640:  20% 82/416 [00:20<01:34,  3.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.011      1.518      1.925          9        640:  20% 83/416 [00:20<01:33,  3.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.016      1.516      1.932          9        640:  20% 84/416 [00:21<01:30,  3.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.014      1.514      1.931         10        640:  20% 85/416 [00:21<01:31,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.012      1.514      1.929          9        640:  21% 86/416 [00:21<01:29,  3.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.011      1.511      1.929         10        640:  21% 87/416 [00:21<01:21,  4.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.012      1.512      1.928          7        640:  21% 88/416 [00:21<01:13,  4.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.006      1.511      1.922          8        640:  21% 89/416 [00:22<01:21,  4.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.003      1.508      1.918          8        640:  22% 90/416 [00:22<01:24,  3.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.002       1.51       1.92          8        640:  22% 91/416 [00:22<01:29,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.004      1.509      1.922         10        640:  22% 92/416 [00:23<01:24,  3.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.003       1.51      1.921          9        640:  22% 93/416 [00:23<01:27,  3.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.007      1.513      1.926          9        640:  23% 94/416 [00:23<01:28,  3.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.005      1.514      1.923          7        640:  23% 95/416 [00:23<01:21,  3.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G          1      1.512      1.919          8        640:  23% 96/416 [00:24<01:21,  3.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9992      1.511      1.917         10        640:  23% 97/416 [00:24<01:11,  4.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.998      1.511      1.916         10        640:  24% 98/416 [00:24<01:07,  4.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9953      1.509      1.912          8        640:  24% 99/416 [00:24<01:04,  4.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9943      1.507      1.913         10        640:  24% 100/416 [00:24<01:10,  4.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9936      1.507      1.912         10        640:  24% 101/416 [00:25<01:06,  4.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9964      1.509      1.915          8        640:  25% 102/416 [00:25<01:02,  5.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9978      1.509      1.915          9        640:  25% 103/416 [00:25<01:01,  5.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9961      1.505      1.915          8        640:  25% 104/416 [00:25<01:06,  4.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9996      1.508      1.915         11        640:  25% 105/416 [00:25<01:00,  5.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.006       1.51      1.918         11        640:  25% 106/416 [00:26<01:01,  5.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.003      1.507      1.915          9        640:  26% 107/416 [00:26<01:02,  4.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9976      1.505       1.91          9        640:  26% 108/416 [00:26<01:03,  4.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9989      1.504      1.912         11        640:  26% 109/416 [00:26<01:00,  5.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9971        1.5      1.911          8        640:  26% 110/416 [00:26<00:55,  5.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9933      1.495      1.907          7        640:  27% 111/416 [00:27<01:01,  4.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9923      1.497      1.906         10        640:  27% 112/416 [00:27<01:03,  4.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9934      1.497      1.907         12        640:  27% 113/416 [00:27<00:57,  5.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9891      1.494      1.903          8        640:  27% 114/416 [00:27<00:59,  5.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9882      1.494      1.902          9        640:  28% 115/416 [00:27<01:03,  4.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9856      1.489        1.9          8        640:  28% 116/416 [00:28<01:04,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9892      1.492      1.902         10        640:  28% 117/416 [00:28<00:59,  5.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.987       1.49        1.9          7        640:  28% 118/416 [00:28<00:58,  5.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9829      1.486      1.895          8        640:  29% 119/416 [00:28<00:54,  5.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.979      1.482      1.891          8        640:  29% 120/416 [00:28<00:57,  5.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.981      1.485      1.893         10        640:  29% 121/416 [00:29<00:57,  5.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9796      1.483      1.892          9        640:  29% 122/416 [00:29<01:04,  4.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9775      1.484       1.89         10        640:  30% 123/416 [00:29<01:07,  4.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9818      1.486      1.894         11        640:  30% 124/416 [00:29<01:07,  4.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9823      1.484      1.893         10        640:  30% 125/416 [00:30<01:05,  4.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9833      1.486      1.895         15        640:  30% 126/416 [00:30<01:09,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9811      1.486      1.893          7        640:  31% 127/416 [00:30<01:03,  4.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9804      1.486      1.892         10        640:  31% 128/416 [00:30<00:59,  4.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G       0.98      1.485      1.892          9        640:  31% 129/416 [00:30<01:05,  4.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9817      1.488      1.894         11        640:  31% 130/416 [00:31<01:12,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9807      1.487      1.893          9        640:  31% 131/416 [00:31<01:22,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9805      1.485      1.893          9        640:  32% 132/416 [00:31<01:18,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9857      1.488      1.899          9        640:  32% 133/416 [00:32<01:15,  3.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9835      1.485      1.897          9        640:  32% 134/416 [00:32<01:22,  3.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9792      1.481      1.893          8        640:  32% 135/416 [00:32<01:15,  3.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9791       1.48      1.893         10        640:  33% 136/416 [00:32<01:18,  3.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9808      1.481      1.894         10        640:  33% 137/416 [00:33<01:20,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9779      1.478      1.891          8        640:  33% 138/416 [00:33<01:20,  3.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9771      1.479       1.89         10        640:  33% 139/416 [00:33<01:26,  3.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9773      1.479      1.889          9        640:  34% 140/416 [00:34<01:23,  3.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9756      1.477      1.886          9        640:  34% 141/416 [00:34<01:21,  3.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9752      1.476      1.887          8        640:  34% 142/416 [00:34<01:14,  3.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9732      1.472      1.885          9        640:  34% 143/416 [00:35<01:17,  3.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9729      1.473      1.887          9        640:  35% 144/416 [00:35<01:14,  3.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9708      1.472      1.884          8        640:  35% 145/416 [00:35<01:13,  3.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9739      1.472      1.888         10        640:  35% 146/416 [00:35<01:12,  3.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9757      1.471      1.889         10        640:  35% 147/416 [00:36<01:14,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9761      1.472       1.89         13        640:  36% 148/416 [00:36<01:04,  4.12it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9804       1.48      1.894         14        640:  36% 149/416 [00:36<00:55,  4.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.978       1.48      1.891          8        640:  36% 150/416 [00:36<01:02,  4.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.979      1.482      1.894          8        640:  36% 151/416 [00:36<00:56,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9773       1.48      1.894          9        640:  37% 152/416 [00:37<00:55,  4.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9769      1.478      1.894          7        640:  37% 153/416 [00:37<00:54,  4.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9773      1.478      1.897          8        640:  37% 154/416 [00:37<00:52,  5.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9784      1.477      1.899          8        640:  37% 155/416 [00:37<00:55,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9815      1.479      1.903          9        640:  38% 156/416 [00:37<00:57,  4.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.981      1.479      1.902          8        640:  38% 157/416 [00:38<00:58,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9832      1.481      1.904         10        640:  38% 158/416 [00:38<01:01,  4.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9807      1.479      1.902          8        640:  38% 159/416 [00:38<00:58,  4.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9869      1.484      1.907         11        640:  38% 160/416 [00:38<00:54,  4.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9858      1.484      1.906          9        640:  39% 161/416 [00:39<00:55,  4.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9868      1.484      1.907          9        640:  39% 162/416 [00:39<00:51,  4.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9845      1.482      1.905          9        640:  39% 163/416 [00:39<00:55,  4.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9857      1.481      1.906         11        640:  39% 164/416 [00:39<00:48,  5.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9878      1.483      1.908         12        640:  40% 165/416 [00:39<00:50,  4.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9859       1.48      1.906          9        640:  40% 166/416 [00:39<00:50,  4.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9878      1.484      1.907         10        640:  40% 167/416 [00:40<00:49,  5.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9865      1.482      1.907          8        640:  40% 168/416 [00:40<00:47,  5.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9869      1.481      1.907          9        640:  41% 169/416 [00:40<00:48,  5.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9862      1.479      1.906          8        640:  41% 170/416 [00:40<00:53,  4.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9854      1.477      1.905          8        640:  41% 171/416 [00:41<00:54,  4.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9877      1.483      1.908         11        640:  41% 172/416 [00:41<00:47,  5.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9868      1.484      1.906         10        640:  42% 173/416 [00:41<00:51,  4.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9878      1.483      1.909         10        640:  42% 174/416 [00:41<00:50,  4.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9881      1.482      1.909          8        640:  42% 175/416 [00:41<00:49,  4.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.986      1.481      1.906          7        640:  42% 176/416 [00:42<00:52,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9862      1.479      1.906          9        640:  43% 177/416 [00:42<00:52,  4.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9864      1.479      1.906         10        640:  43% 178/416 [00:42<00:46,  5.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9913      1.486      1.911          7        640:  43% 179/416 [00:42<00:57,  4.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9902      1.486      1.911          9        640:  43% 180/416 [00:43<00:56,  4.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9915      1.486      1.913          9        640:  44% 181/416 [00:43<00:59,  3.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9973      1.493      1.918         14        640:  44% 182/416 [00:43<00:58,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9958      1.492      1.916          8        640:  44% 183/416 [00:43<00:55,  4.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9951      1.491      1.915          9        640:  44% 184/416 [00:44<01:01,  3.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9955       1.49      1.916          8        640:  44% 185/416 [00:44<00:52,  4.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9993      1.494       1.92         11        640:  45% 186/416 [00:44<00:51,  4.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.001      1.495      1.922         10        640:  45% 187/416 [00:44<01:03,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.001      1.494      1.921          8        640:  45% 188/416 [00:45<00:56,  4.01it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.004      1.496      1.923         10        640:  45% 189/416 [00:45<01:03,  3.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.003      1.495      1.924          8        640:  46% 190/416 [00:45<01:05,  3.47it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.004      1.498      1.924         10        640:  46% 191/416 [00:46<01:07,  3.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.004      1.497      1.924          9        640:  46% 192/416 [00:46<01:05,  3.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.003      1.495      1.923          8        640:  46% 193/416 [00:46<01:05,  3.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.003      1.493      1.923          9        640:  47% 194/416 [00:46<01:05,  3.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.001      1.492      1.921          9        640:  47% 195/416 [00:47<01:17,  2.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9998      1.492       1.92          9        640:  47% 196/416 [00:47<01:06,  3.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9972      1.491      1.917          8        640:  47% 197/416 [00:47<01:08,  3.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9952      1.489      1.915          8        640:  48% 198/416 [00:48<01:08,  3.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9932      1.487      1.913          8        640:  48% 199/416 [00:48<00:58,  3.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9911      1.489      1.911          8        640:  48% 200/416 [00:48<00:58,  3.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9878      1.488      1.907          8        640:  48% 201/416 [00:49<01:03,  3.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9874      1.487      1.906          9        640:  49% 202/416 [00:49<00:54,  3.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9862      1.486      1.906         10        640:  49% 203/416 [00:49<00:56,  3.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9855      1.485      1.905          9        640:  49% 204/416 [00:49<00:58,  3.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9858      1.486      1.905         10        640:  49% 205/416 [00:49<00:55,  3.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9848      1.484      1.905          8        640:  50% 206/416 [00:50<00:50,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9834      1.484      1.903          8        640:  50% 207/416 [00:50<00:54,  3.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9844      1.486      1.905          7        640:  50% 208/416 [00:50<00:55,  3.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9828      1.485      1.904          8        640:  50% 209/416 [00:50<00:52,  3.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9832      1.484      1.905         10        640:  50% 210/416 [00:51<00:52,  3.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9855      1.486      1.907         12        640:  51% 211/416 [00:51<00:53,  3.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9847      1.485      1.906          9        640:  51% 212/416 [00:51<00:45,  4.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9836      1.484      1.905          9        640:  51% 213/416 [00:51<00:40,  5.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9815      1.482      1.903          9        640:  51% 214/416 [00:52<00:43,  4.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9803      1.481      1.902          8        640:  52% 215/416 [00:52<00:46,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9831      1.481      1.904         12        640:  52% 216/416 [00:52<00:44,  4.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9844      1.482      1.905          8        640:  52% 217/416 [00:52<00:42,  4.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9869      1.483      1.907         11        640:  52% 218/416 [00:53<00:47,  4.13it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9877      1.484      1.909         10        640:  53% 219/416 [00:53<00:44,  4.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9884      1.484      1.909         10        640:  53% 220/416 [00:53<00:40,  4.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9921       1.49      1.912         13        640:  53% 221/416 [00:53<00:41,  4.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.993      1.489      1.914          9        640:  53% 222/416 [00:53<00:44,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9926       1.49      1.913         10        640:  54% 223/416 [00:54<00:42,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9907      1.489      1.912          8        640:  54% 224/416 [00:54<00:40,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.991      1.489      1.912          9        640:  54% 225/416 [00:54<00:44,  4.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9923       1.49      1.913         11        640:  54% 226/416 [00:54<00:43,  4.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9914       1.49      1.912          9        640:  55% 227/416 [00:55<00:48,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9904      1.489      1.911         11        640:  55% 228/416 [00:55<00:47,  3.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9903      1.488       1.91         10        640:  55% 229/416 [00:55<00:42,  4.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.992      1.488      1.912          9        640:  55% 230/416 [00:55<00:46,  4.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9935      1.487      1.913         10        640:  56% 231/416 [00:55<00:41,  4.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9952      1.489      1.915          9        640:  56% 232/416 [00:56<00:41,  4.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9975       1.49      1.917          9        640:  56% 233/416 [00:56<00:39,  4.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.997      1.487      1.917          9        640:  56% 234/416 [00:56<00:42,  4.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9985      1.489       1.92         11        640:  56% 235/416 [00:56<00:42,  4.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9993      1.489      1.921          9        640:  57% 236/416 [00:57<00:40,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9993      1.489      1.921          9        640:  57% 237/416 [00:57<00:38,  4.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G          1      1.489      1.922          9        640:  57% 238/416 [00:57<00:33,  5.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G          1      1.489      1.922          9        640:  57% 239/416 [00:57<00:37,  4.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.001      1.488      1.923          9        640:  58% 240/416 [00:57<00:40,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      1.003      1.488      1.926         10        640:  58% 241/416 [00:58<00:38,  4.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9999      1.487      1.923          9        640:  58% 242/416 [00:58<00:39,  4.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9989      1.486      1.923          9        640:  58% 243/416 [00:58<00:45,  3.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9966      1.483       1.92          9        640:  59% 244/416 [00:59<00:45,  3.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9955      1.483      1.919         10        640:  59% 245/416 [00:59<00:47,  3.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9966      1.485      1.921         10        640:  59% 246/416 [00:59<00:47,  3.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9966      1.485      1.922         10        640:  59% 247/416 [00:59<00:49,  3.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9954      1.485      1.921          8        640:  60% 248/416 [01:00<00:45,  3.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9981      1.487      1.923         11        640:  60% 249/416 [01:00<00:48,  3.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9968      1.486      1.922          7        640:  60% 250/416 [01:00<00:49,  3.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9966      1.487      1.921         10        640:  60% 251/416 [01:01<00:52,  3.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9948      1.487      1.919          9        640:  61% 252/416 [01:01<00:49,  3.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9953      1.487       1.92         11        640:  61% 253/416 [01:01<00:48,  3.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9944      1.488      1.919          8        640:  61% 254/416 [01:02<00:48,  3.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9926      1.485      1.917          8        640:  61% 255/416 [01:02<00:51,  3.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9955      1.486       1.92         11        640:  62% 256/416 [01:02<00:46,  3.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.994      1.486      1.918          8        640:  62% 257/416 [01:02<00:43,  3.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9936      1.486      1.919          8        640:  62% 258/416 [01:03<00:39,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9941      1.486      1.919         10        640:  62% 259/416 [01:03<00:44,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9925      1.485      1.917          8        640:  62% 260/416 [01:03<00:39,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9904      1.483      1.915          8        640:  63% 261/416 [01:03<00:42,  3.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9896      1.482      1.914          9        640:  63% 262/416 [01:04<00:43,  3.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9915      1.483      1.916         13        640:  63% 263/416 [01:04<00:38,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9913      1.483      1.916         10        640:  63% 264/416 [01:04<00:35,  4.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9905      1.484      1.915         11        640:  64% 265/416 [01:04<00:37,  4.07it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9903      1.484      1.914         10        640:  64% 266/416 [01:05<00:38,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9913      1.484      1.914         12        640:  64% 267/416 [01:05<00:44,  3.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9908      1.484      1.913          9        640:  64% 268/416 [01:05<00:39,  3.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9924      1.485      1.915         12        640:  65% 269/416 [01:05<00:37,  3.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.992      1.486      1.915          7        640:  65% 270/416 [01:06<00:34,  4.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9919      1.486      1.915         10        640:  65% 271/416 [01:06<00:34,  4.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9924      1.486      1.916         10        640:  65% 272/416 [01:06<00:32,  4.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9909      1.486      1.914          8        640:  66% 273/416 [01:06<00:29,  4.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9916      1.487      1.915         13        640:  66% 274/416 [01:06<00:27,  5.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9924      1.487      1.915          9        640:  66% 275/416 [01:07<00:31,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.992      1.489      1.915         10        640:  66% 276/416 [01:07<00:31,  4.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9908      1.488      1.914          8        640:  67% 277/416 [01:07<00:29,  4.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9909      1.488      1.915          8        640:  67% 278/416 [01:07<00:32,  4.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9913      1.489      1.916          8        640:  67% 279/416 [01:08<00:29,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9931      1.492      1.919          8        640:  67% 280/416 [01:08<00:29,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9942      1.491       1.92          9        640:  68% 281/416 [01:08<00:28,  4.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9958       1.49      1.921          9        640:  68% 282/416 [01:08<00:29,  4.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9962       1.49      1.922         11        640:  68% 283/416 [01:08<00:28,  4.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9972       1.49      1.922         10        640:  68% 284/416 [01:09<00:26,  4.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9961       1.49      1.921          8        640:  69% 285/416 [01:09<00:26,  5.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9946       1.49       1.92          8        640:  69% 286/416 [01:09<00:28,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9943       1.49      1.919         10        640:  69% 287/416 [01:09<00:24,  5.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9948       1.49       1.92          8        640:  69% 288/416 [01:09<00:22,  5.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.997      1.491      1.922          8        640:  69% 289/416 [01:09<00:20,  6.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9966      1.494      1.922          9        640:  70% 290/416 [01:10<00:25,  5.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.995      1.493       1.92          9        640:  70% 291/416 [01:10<00:28,  4.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9933      1.493      1.919          8        640:  70% 292/416 [01:10<00:28,  4.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9928      1.493      1.918         10        640:  70% 293/416 [01:11<00:28,  4.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9921      1.493      1.918         11        640:  71% 294/416 [01:11<00:29,  4.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9919      1.493      1.917          9        640:  71% 295/416 [01:11<00:25,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.991      1.491      1.916          7        640:  71% 296/416 [01:11<00:28,  4.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9901      1.492      1.915          9        640:  71% 297/416 [01:11<00:28,  4.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9894      1.492      1.914          8        640:  72% 298/416 [01:12<00:30,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9915      1.492      1.915         13        640:  72% 299/416 [01:12<00:33,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9897      1.491      1.912          8        640:  72% 300/416 [01:12<00:32,  3.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9901      1.492      1.912         10        640:  72% 301/416 [01:13<00:34,  3.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9904      1.491      1.913          9        640:  73% 302/416 [01:13<00:31,  3.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9911      1.492      1.913         10        640:  73% 303/416 [01:13<00:32,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9905       1.49      1.914          8        640:  73% 304/416 [01:14<00:34,  3.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9891       1.49      1.912          9        640:  73% 305/416 [01:14<00:32,  3.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9885      1.489      1.911         10        640:  74% 306/416 [01:14<00:31,  3.47it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.988      1.489      1.911         10        640:  74% 307/416 [01:15<00:35,  3.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9888      1.489      1.911         11        640:  74% 308/416 [01:15<00:33,  3.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9878      1.488       1.91         10        640:  74% 309/416 [01:15<00:31,  3.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9867      1.487      1.909          9        640:  75% 310/416 [01:15<00:31,  3.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9863      1.486      1.908          8        640:  75% 311/416 [01:16<00:32,  3.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9861      1.486      1.908          8        640:  75% 312/416 [01:16<00:28,  3.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9854      1.487      1.908         10        640:  75% 313/416 [01:16<00:28,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9846      1.487      1.907          9        640:  75% 314/416 [01:16<00:26,  3.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9829      1.485      1.905          7        640:  76% 315/416 [01:17<00:29,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9842      1.486      1.906         11        640:  76% 316/416 [01:17<00:28,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9866      1.488      1.908         12        640:  76% 317/416 [01:17<00:25,  3.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9891       1.49       1.91         11        640:  76% 318/416 [01:17<00:21,  4.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9888       1.49       1.91          9        640:  77% 319/416 [01:18<00:23,  4.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9908      1.491      1.912         10        640:  77% 320/416 [01:18<00:24,  3.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9922      1.492      1.914         12        640:  77% 321/416 [01:18<00:24,  3.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9946      1.494      1.916         12        640:  77% 322/416 [01:18<00:23,  4.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9945      1.493      1.916          9        640:  78% 323/416 [01:19<00:25,  3.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9949      1.494      1.916         10        640:  78% 324/416 [01:19<00:21,  4.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9953      1.495      1.916         11        640:  78% 325/416 [01:19<00:22,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9958      1.495      1.917          8        640:  78% 326/416 [01:19<00:23,  3.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9951      1.494      1.916          9        640:  79% 327/416 [01:20<00:23,  3.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9948      1.494      1.916         10        640:  79% 328/416 [01:20<00:22,  3.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9953      1.493      1.916         11        640:  79% 329/416 [01:20<00:21,  4.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9943      1.492      1.915          9        640:  79% 330/416 [01:20<00:20,  4.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9938      1.492      1.914          9        640:  80% 331/416 [01:21<00:19,  4.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9932      1.492      1.914          9        640:  80% 332/416 [01:21<00:19,  4.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9932      1.493      1.914          8        640:  80% 333/416 [01:21<00:17,  4.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9923      1.492      1.913         10        640:  80% 334/416 [01:21<00:16,  5.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9927      1.492      1.913         11        640:  81% 335/416 [01:21<00:15,  5.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9938      1.493      1.915          9        640:  81% 336/416 [01:22<00:17,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9938      1.493      1.915         11        640:  81% 337/416 [01:22<00:16,  4.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9944      1.495      1.916          9        640:  81% 338/416 [01:22<00:16,  4.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.994      1.495      1.915          8        640:  81% 339/416 [01:22<00:17,  4.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9957      1.497      1.917         11        640:  82% 340/416 [01:23<00:16,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9939      1.496      1.915          8        640:  82% 341/416 [01:23<00:17,  4.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9936      1.496      1.915          9        640:  82% 342/416 [01:23<00:17,  4.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9942      1.497      1.915          9        640:  82% 343/416 [01:23<00:17,  4.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9942      1.497      1.915         10        640:  83% 344/416 [01:24<00:16,  4.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9946      1.496      1.915         10        640:  83% 345/416 [01:24<00:16,  4.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9939      1.495      1.915          9        640:  83% 346/416 [01:24<00:17,  4.07it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9923      1.494      1.914          8        640:  83% 347/416 [01:24<00:17,  3.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9927      1.493      1.914         10        640:  84% 348/416 [01:25<00:15,  4.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9918      1.493      1.914          8        640:  84% 349/416 [01:25<00:15,  4.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9905      1.493      1.913          8        640:  84% 350/416 [01:25<00:14,  4.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9895      1.492      1.913          8        640:  84% 351/416 [01:25<00:13,  4.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9892      1.492      1.913          8        640:  85% 352/416 [01:25<00:12,  5.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9885      1.491      1.913          8        640:  85% 353/416 [01:26<00:13,  4.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9885      1.491      1.913          8        640:  85% 354/416 [01:26<00:12,  4.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9891      1.492      1.914          9        640:  85% 355/416 [01:26<00:12,  4.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9898      1.494      1.914          8        640:  86% 356/416 [01:26<00:13,  4.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9887      1.493      1.913          9        640:  86% 357/416 [01:27<00:15,  3.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9889      1.492      1.914          8        640:  86% 358/416 [01:27<00:15,  3.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9892      1.492      1.914         11        640:  86% 359/416 [01:27<00:15,  3.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9881      1.491      1.913          9        640:  87% 360/416 [01:27<00:15,  3.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9891      1.491      1.914         13        640:  87% 361/416 [01:28<00:15,  3.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9895      1.491      1.914          9        640:  87% 362/416 [01:28<00:15,  3.47it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9887       1.49      1.912          8        640:  87% 363/416 [01:28<00:16,  3.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9875      1.489      1.911          9        640:  88% 364/416 [01:29<00:15,  3.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.986      1.488       1.91          8        640:  88% 365/416 [01:29<00:14,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.985      1.487      1.909          9        640:  88% 366/416 [01:29<00:14,  3.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9859      1.488      1.909         11        640:  88% 367/416 [01:29<00:14,  3.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9847      1.487      1.908          8        640:  88% 368/416 [01:30<00:14,  3.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9842      1.485      1.908          9        640:  89% 369/416 [01:30<00:13,  3.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.984      1.485      1.907          9        640:  89% 370/416 [01:30<00:11,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9852      1.486      1.908          9        640:  89% 371/416 [01:31<00:13,  3.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9859      1.486      1.908         11        640:  89% 372/416 [01:31<00:11,  3.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9842      1.486      1.907          8        640:  90% 373/416 [01:31<00:10,  3.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9854      1.487      1.908         10        640:  90% 374/416 [01:31<00:10,  3.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9849      1.486      1.908          7        640:  90% 375/416 [01:32<00:10,  3.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9851      1.487      1.908          8        640:  90% 376/416 [01:32<00:10,  3.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9836      1.485      1.907          7        640:  91% 377/416 [01:32<00:10,  3.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9825      1.485      1.906          7        640:  91% 378/416 [01:32<00:09,  3.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9815      1.485      1.905          8        640:  91% 379/416 [01:33<00:09,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9803      1.483      1.904          8        640:  91% 380/416 [01:33<00:09,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9786      1.483      1.902          7        640:  92% 381/416 [01:33<00:07,  4.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9782      1.482      1.902         10        640:  92% 382/416 [01:33<00:08,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9784      1.482      1.902          9        640:  92% 383/416 [01:34<00:07,  4.13it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9774      1.481      1.902          6        640:  92% 384/416 [01:34<00:07,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9772      1.481      1.901         11        640:  93% 385/416 [01:34<00:07,  4.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9776      1.483      1.901         12        640:  93% 386/416 [01:34<00:06,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9773      1.484      1.901         10        640:  93% 387/416 [01:35<00:07,  3.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9792      1.485      1.903         10        640:  93% 388/416 [01:35<00:06,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9798      1.487      1.903         11        640:  94% 389/416 [01:35<00:06,  4.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9789      1.486      1.903          8        640:  94% 390/416 [01:35<00:06,  4.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9775      1.485      1.901          8        640:  94% 391/416 [01:35<00:05,  4.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9761      1.484        1.9          8        640:  94% 392/416 [01:35<00:04,  5.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9773      1.485      1.902          9        640:  94% 393/416 [01:36<00:04,  5.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9781      1.485      1.902         13        640:  95% 394/416 [01:36<00:04,  4.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9786      1.484      1.904         10        640:  95% 395/416 [01:36<00:04,  4.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9782      1.484      1.903          8        640:  95% 396/416 [01:36<00:04,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9795      1.484      1.905          9        640:  95% 397/416 [01:37<00:03,  4.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9791      1.483      1.905          9        640:  96% 398/416 [01:37<00:03,  5.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9786      1.483      1.904          7        640:  96% 399/416 [01:37<00:03,  4.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9787      1.483      1.905          8        640:  96% 400/416 [01:37<00:03,  5.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.978      1.482      1.904          9        640:  96% 401/416 [01:37<00:02,  5.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9776      1.482      1.903          8        640:  97% 402/416 [01:38<00:02,  4.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9772      1.482      1.903          9        640:  97% 403/416 [01:38<00:02,  4.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9784      1.484      1.904         14        640:  97% 404/416 [01:38<00:02,  4.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9778      1.484      1.903          8        640:  97% 405/416 [01:38<00:02,  5.05it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9782      1.484      1.903          9        640:  98% 406/416 [01:38<00:02,  4.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.978      1.484      1.903         10        640:  98% 407/416 [01:39<00:01,  4.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9776      1.484      1.902          9        640:  98% 408/416 [01:39<00:01,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9777      1.483      1.902         10        640:  98% 409/416 [01:39<00:01,  4.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9771      1.483      1.902          9        640:  99% 410/416 [01:39<00:01,  4.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.977      1.484      1.902          9        640:  99% 411/416 [01:39<00:01,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.976      1.484      1.901          8        640:  99% 412/416 [01:40<00:00,  4.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9753      1.483        1.9         10        640:  99% 413/416 [01:40<00:00,  4.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9747      1.482        1.9          8        640: 100% 414/416 [01:40<00:00,  4.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G      0.974      1.482      1.899          8        640: 100% 415/416 [01:40<00:00,  4.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       9/10      1.39G     0.9731       1.48      1.898          3        640: 100% 416/416 [01:41<00:00,  4.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 11/11 [00:02<00:00,  4.69it/s]\n",
            "                   all        174        200      0.419      0.682      0.516      0.358\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/416 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.158      1.489       1.91         11        640:   0% 1/416 [00:00<01:39,  4.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.011      1.398      1.791         10        640:   0% 2/416 [00:00<01:54,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9867      1.354      1.766          9        640:   1% 3/416 [00:00<02:01,  3.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.941      1.382      1.758         10        640:   1% 4/416 [00:01<01:55,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.039      1.468      1.775         12        640:   1% 5/416 [00:01<01:54,  3.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G       1.19      1.613      1.955         17        640:   1% 6/416 [00:01<01:33,  4.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.128      1.513      1.897          9        640:   2% 7/416 [00:01<01:45,  3.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.098      1.533      1.878         11        640:   2% 8/416 [00:02<01:43,  3.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.101      1.513      1.897          9        640:   2% 9/416 [00:02<01:33,  4.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.097      1.545      1.898          9        640:   2% 10/416 [00:02<01:43,  3.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.127      1.588      1.917         14        640:   3% 11/416 [00:02<01:43,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.078      1.533      1.886          8        640:   3% 12/416 [00:03<01:42,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.039      1.496       1.85          9        640:   3% 13/416 [00:03<01:28,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.033      1.474      1.858          9        640:   3% 14/416 [00:03<01:36,  4.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G       1.02      1.454      1.857          9        640:   4% 15/416 [00:03<01:34,  4.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.016      1.488      1.837          9        640:   4% 16/416 [00:03<01:35,  4.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.031       1.49       1.86         11        640:   4% 17/416 [00:04<01:36,  4.12it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.071      1.543      1.901          9        640:   4% 18/416 [00:04<01:40,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.054      1.522      1.895         10        640:   5% 19/416 [00:04<01:44,  3.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.037      1.512      1.887          9        640:   5% 20/416 [00:04<01:28,  4.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.033      1.505      1.882         11        640:   5% 21/416 [00:05<01:24,  4.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.043      1.507      1.895         11        640:   5% 22/416 [00:05<01:25,  4.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.038      1.514      1.904          9        640:   6% 23/416 [00:05<01:28,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.018      1.502      1.888          8        640:   6% 24/416 [00:05<01:28,  4.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.016       1.49       1.88          9        640:   6% 25/416 [00:05<01:23,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.039        1.5      1.909         11        640:   6% 26/416 [00:06<01:23,  4.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.048      1.522      1.926         10        640:   6% 27/416 [00:06<01:19,  4.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.053      1.517      1.924          9        640:   7% 28/416 [00:06<01:21,  4.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.027      1.504      1.898          8        640:   7% 29/416 [00:06<01:15,  5.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.015      1.486      1.892          9        640:   7% 30/416 [00:06<01:13,  5.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.013      1.499      1.898         10        640:   7% 31/416 [00:07<01:23,  4.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.011      1.494      1.901         10        640:   8% 32/416 [00:07<01:21,  4.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G          1      1.485      1.894          9        640:   8% 33/416 [00:07<01:26,  4.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.006      1.476      1.908         10        640:   8% 34/416 [00:07<01:25,  4.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9991      1.468      1.901          8        640:   8% 35/416 [00:08<01:32,  4.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002      1.474      1.901         10        640:   9% 36/416 [00:08<01:19,  4.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9959      1.469      1.896          9        640:   9% 37/416 [00:08<01:13,  5.12it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001       1.48      1.897         10        640:   9% 38/416 [00:08<01:15,  5.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G          1      1.485      1.896          8        640:   9% 39/416 [00:08<01:19,  4.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9935      1.479       1.89         10        640:  10% 40/416 [00:09<01:12,  5.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9961      1.475      1.897          9        640:  10% 41/416 [00:09<01:16,  4.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.005      1.476      1.907          9        640:  10% 42/416 [00:09<01:15,  4.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9952      1.476      1.898          8        640:  10% 43/416 [00:09<01:13,  5.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001      1.475      1.904         10        640:  11% 44/416 [00:09<01:20,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9982      1.472      1.902          9        640:  11% 45/416 [00:10<01:15,  4.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9974       1.47      1.901         10        640:  11% 46/416 [00:10<01:12,  5.13it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9929      1.465      1.895         10        640:  11% 47/416 [00:10<01:25,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9867      1.458      1.891          9        640:  12% 48/416 [00:10<01:27,  4.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9925      1.466      1.898          8        640:  12% 49/416 [00:11<01:39,  3.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9892      1.457      1.898          8        640:  12% 50/416 [00:11<01:49,  3.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.994      1.457      1.904         10        640:  12% 51/416 [00:11<01:48,  3.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9989      1.455      1.909          8        640:  12% 52/416 [00:12<01:50,  3.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9986      1.451      1.908          9        640:  13% 53/416 [00:12<01:54,  3.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9962      1.454      1.908          6        640:  13% 54/416 [00:12<01:49,  3.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9911      1.447      1.903         10        640:  13% 55/416 [00:13<01:49,  3.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.989      1.449      1.905          9        640:  13% 56/416 [00:13<01:49,  3.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9862      1.446      1.903          9        640:  14% 57/416 [00:13<01:48,  3.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9823      1.449      1.901          9        640:  14% 58/416 [00:14<01:53,  3.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9885      1.451      1.905         12        640:  14% 59/416 [00:14<01:51,  3.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.003      1.469       1.92         10        640:  14% 60/416 [00:14<01:49,  3.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.007       1.47      1.924         10        640:  15% 61/416 [00:14<01:40,  3.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.004      1.467      1.922          9        640:  15% 62/416 [00:15<01:42,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.009      1.465      1.928          9        640:  15% 63/416 [00:15<01:41,  3.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.006      1.458      1.923          8        640:  15% 64/416 [00:15<01:32,  3.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.011      1.458      1.934          8        640:  16% 65/416 [00:15<01:27,  4.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.009       1.46      1.932          8        640:  16% 66/416 [00:16<01:30,  3.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.003      1.459      1.928          9        640:  16% 67/416 [00:16<01:38,  3.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9983      1.461      1.922          8        640:  16% 68/416 [00:16<01:31,  3.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001      1.461      1.928         10        640:  17% 69/416 [00:17<01:35,  3.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9991      1.461      1.929         10        640:  17% 70/416 [00:17<01:19,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9982      1.456      1.926          9        640:  17% 71/416 [00:17<01:29,  3.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.004      1.464      1.928         14        640:  17% 72/416 [00:17<01:21,  4.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.009      1.467      1.933         11        640:  18% 73/416 [00:17<01:25,  4.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.014      1.472      1.935         13        640:  18% 74/416 [00:18<01:29,  3.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G       1.01       1.47      1.931          9        640:  18% 75/416 [00:18<01:37,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.005      1.468      1.925          9        640:  18% 76/416 [00:18<01:29,  3.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.005       1.47      1.925          9        640:  19% 77/416 [00:18<01:16,  4.40it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.007       1.47      1.929          9        640:  19% 78/416 [00:19<01:26,  3.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002      1.468      1.923          8        640:  19% 79/416 [00:19<01:21,  4.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.004       1.47       1.92          9        640:  19% 80/416 [00:19<01:22,  4.05it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.003       1.47      1.919         11        640:  19% 81/416 [00:19<01:11,  4.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9996      1.468      1.917          8        640:  20% 82/416 [00:20<01:04,  5.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9951      1.465      1.914          8        640:  20% 83/416 [00:20<01:13,  4.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.994      1.465       1.91          7        640:  20% 84/416 [00:20<01:11,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9944      1.467       1.91          9        640:  20% 85/416 [00:20<01:17,  4.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9992      1.476      1.915         11        640:  21% 86/416 [00:20<01:06,  4.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9991      1.475      1.914         10        640:  21% 87/416 [00:21<01:04,  5.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9964      1.473      1.912         10        640:  21% 88/416 [00:21<01:04,  5.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9976       1.47      1.913         10        640:  21% 89/416 [00:21<01:11,  4.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9944      1.466      1.912          8        640:  22% 90/416 [00:21<01:05,  5.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.988       1.46      1.906          8        640:  22% 91/416 [00:22<01:15,  4.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9853      1.455      1.903         10        640:  22% 92/416 [00:22<01:10,  4.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9812      1.452        1.9          7        640:  22% 93/416 [00:22<01:09,  4.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9788      1.451      1.898          8        640:  23% 94/416 [00:22<01:04,  5.01it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9844      1.454      1.902         10        640:  23% 95/416 [00:22<01:06,  4.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9818      1.451        1.9          9        640:  23% 96/416 [00:22<01:03,  5.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9865      1.451      1.906          9        640:  23% 97/416 [00:23<00:56,  5.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9939      1.461      1.913         10        640:  24% 98/416 [00:23<01:04,  4.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9957      1.463      1.913         10        640:  24% 99/416 [00:23<01:12,  4.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9926      1.467      1.909          8        640:  24% 100/416 [00:23<01:09,  4.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9912      1.465      1.907          9        640:  24% 101/416 [00:24<01:10,  4.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9931      1.467      1.908         10        640:  25% 102/416 [00:24<01:04,  4.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9969      1.471       1.91          9        640:  25% 103/416 [00:24<01:01,  5.07it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9941      1.468      1.907         10        640:  25% 104/416 [00:24<01:10,  4.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9921       1.47      1.904          7        640:  25% 105/416 [00:25<01:15,  4.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.999      1.472      1.909         14        640:  25% 106/416 [00:25<01:21,  3.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001      1.479      1.912         11        640:  26% 107/416 [00:25<01:34,  3.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G          1      1.478       1.91          8        640:  26% 108/416 [00:25<01:27,  3.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001      1.477      1.911         11        640:  26% 109/416 [00:26<01:26,  3.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.003      1.477      1.913          9        640:  26% 110/416 [00:26<01:28,  3.47it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9989      1.472      1.909          8        640:  27% 111/416 [00:26<01:25,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002       1.47      1.911         11        640:  27% 112/416 [00:27<01:25,  3.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.999      1.467      1.908          9        640:  27% 113/416 [00:27<01:25,  3.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9943      1.467      1.903          8        640:  27% 114/416 [00:27<01:28,  3.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9973      1.468      1.907          9        640:  28% 115/416 [00:28<01:37,  3.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9961      1.465      1.907          9        640:  28% 116/416 [00:28<01:33,  3.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9962      1.467      1.906          9        640:  28% 117/416 [00:28<01:34,  3.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9954      1.465      1.905          9        640:  28% 118/416 [00:29<01:34,  3.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9975      1.466      1.906         11        640:  29% 119/416 [00:29<01:28,  3.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9973      1.468      1.906         10        640:  29% 120/416 [00:29<01:25,  3.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9966      1.467      1.906          8        640:  29% 121/416 [00:29<01:14,  3.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9954      1.471      1.906          8        640:  29% 122/416 [00:29<01:09,  4.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9983      1.473      1.909          9        640:  30% 123/416 [00:30<01:10,  4.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9966      1.471      1.907          9        640:  30% 124/416 [00:30<01:06,  4.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9999      1.474       1.91         11        640:  30% 125/416 [00:30<01:02,  4.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9953       1.47      1.905          8        640:  30% 126/416 [00:30<01:02,  4.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.996       1.47      1.905         10        640:  31% 127/416 [00:30<00:58,  4.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9923      1.469        1.9          7        640:  31% 128/416 [00:31<01:00,  4.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9942      1.467      1.903         10        640:  31% 129/416 [00:31<00:55,  5.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9913      1.464        1.9          8        640:  31% 130/416 [00:31<00:55,  5.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9935      1.465      1.903          9        640:  31% 131/416 [00:31<00:53,  5.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9946       1.47      1.902          9        640:  32% 132/416 [00:31<00:48,  5.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9933       1.47        1.9          9        640:  32% 133/416 [00:32<01:03,  4.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9959      1.471      1.902          8        640:  32% 134/416 [00:32<01:01,  4.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9961       1.47      1.903          9        640:  32% 135/416 [00:32<00:55,  5.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.003      1.475      1.909         14        640:  33% 136/416 [00:32<00:57,  4.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002      1.475      1.907          8        640:  33% 137/416 [00:33<01:02,  4.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.003       1.48      1.908          9        640:  33% 138/416 [00:33<01:03,  4.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002      1.481      1.908         11        640:  33% 139/416 [00:33<01:03,  4.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.003      1.484       1.91         10        640:  34% 140/416 [00:33<00:58,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9998      1.482      1.906          9        640:  34% 141/416 [00:33<01:03,  4.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002      1.482      1.908          9        640:  34% 142/416 [00:34<01:04,  4.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9998       1.48      1.905          8        640:  34% 143/416 [00:34<01:09,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G          1      1.481      1.906         12        640:  35% 144/416 [00:34<01:06,  4.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9962      1.476      1.902          8        640:  35% 145/416 [00:34<01:03,  4.24it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9979      1.476      1.904         10        640:  35% 146/416 [00:35<01:04,  4.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G          1      1.478      1.906          9        640:  35% 147/416 [00:35<01:10,  3.81it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9974      1.475      1.904          7        640:  36% 148/416 [00:35<01:08,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9977      1.474      1.904          9        640:  36% 149/416 [00:35<01:08,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002      1.477      1.908         12        640:  36% 150/416 [00:36<01:06,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001      1.475      1.907          9        640:  36% 151/416 [00:36<00:59,  4.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G          1      1.474      1.906         10        640:  37% 152/416 [00:36<00:53,  4.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9989      1.472      1.904         10        640:  37% 153/416 [00:36<00:57,  4.59it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.003      1.478      1.907         12        640:  37% 154/416 [00:37<00:57,  4.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001      1.475      1.904          9        640:  37% 155/416 [00:37<01:03,  4.12it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9975      1.471        1.9          8        640:  38% 156/416 [00:37<01:04,  4.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9998      1.476      1.902         10        640:  38% 157/416 [00:37<00:59,  4.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001      1.479      1.903          8        640:  38% 158/416 [00:37<00:58,  4.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9995       1.48      1.902         11        640:  38% 159/416 [00:38<00:54,  4.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9961      1.478      1.898          8        640:  38% 160/416 [00:38<00:53,  4.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9979      1.479      1.899          9        640:  39% 161/416 [00:38<00:54,  4.72it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.999       1.48      1.901          7        640:  39% 162/416 [00:38<00:55,  4.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9994       1.48      1.902          8        640:  39% 163/416 [00:39<01:04,  3.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9969      1.483        1.9          7        640:  39% 164/416 [00:39<00:58,  4.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9957      1.482      1.898         11        640:  40% 165/416 [00:39<01:09,  3.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9943      1.479      1.897          9        640:  40% 166/416 [00:39<01:09,  3.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9945      1.479      1.897         11        640:  40% 167/416 [00:40<01:14,  3.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9946      1.477      1.897          8        640:  40% 168/416 [00:40<01:11,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9925      1.475      1.895          8        640:  41% 169/416 [00:40<01:13,  3.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9932      1.474      1.895          8        640:  41% 170/416 [00:41<01:15,  3.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9935      1.478      1.895         10        640:  41% 171/416 [00:41<01:20,  3.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.993      1.476      1.894         11        640:  41% 172/416 [00:41<01:18,  3.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9961      1.478      1.896         12        640:  42% 173/416 [00:42<01:15,  3.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9986      1.479      1.898          9        640:  42% 174/416 [00:42<01:14,  3.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9989      1.478      1.898         12        640:  42% 175/416 [00:42<01:09,  3.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9977      1.475      1.897          9        640:  42% 176/416 [00:42<01:05,  3.68it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9951      1.474      1.895          8        640:  43% 177/416 [00:43<01:04,  3.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9978      1.475      1.897         11        640:  43% 178/416 [00:43<01:01,  3.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9961      1.473      1.895          8        640:  43% 179/416 [00:43<01:08,  3.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9962      1.474      1.895         10        640:  43% 180/416 [00:44<01:04,  3.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9955      1.474      1.895         11        640:  44% 181/416 [00:44<00:59,  3.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9942      1.473      1.895          6        640:  44% 182/416 [00:44<00:59,  3.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9946      1.473      1.894         10        640:  44% 183/416 [00:44<00:58,  4.01it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9933      1.472      1.892          9        640:  44% 184/416 [00:44<00:55,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9893      1.469      1.888          8        640:  44% 185/416 [00:45<00:57,  4.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9899      1.467       1.89         10        640:  45% 186/416 [00:45<00:52,  4.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9922      1.468      1.892         12        640:  45% 187/416 [00:45<00:57,  3.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9937      1.472      1.895         10        640:  45% 188/416 [00:45<00:51,  4.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9913       1.47      1.892          8        640:  45% 189/416 [00:46<00:53,  4.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9924      1.468      1.895          8        640:  46% 190/416 [00:46<00:58,  3.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9938      1.468      1.896         10        640:  46% 191/416 [00:46<00:54,  4.13it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9946      1.467      1.896         11        640:  46% 192/416 [00:46<00:53,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9952      1.467      1.897          8        640:  46% 193/416 [00:47<00:50,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9931      1.467      1.896          8        640:  47% 194/416 [00:47<00:44,  5.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9946      1.467      1.898         10        640:  47% 195/416 [00:47<00:51,  4.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9965       1.47      1.899         11        640:  47% 196/416 [00:47<00:48,  4.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9983       1.47      1.901         11        640:  47% 197/416 [00:47<00:49,  4.47it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001      1.471      1.903          9        640:  48% 198/416 [00:48<00:50,  4.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9994      1.471      1.901         11        640:  48% 199/416 [00:48<00:45,  4.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002      1.472      1.903         11        640:  48% 200/416 [00:48<00:41,  5.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001      1.474      1.903          8        640:  48% 201/416 [00:48<00:44,  4.82it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002      1.474      1.904          8        640:  49% 202/416 [00:49<00:47,  4.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.004      1.475      1.903         10        640:  49% 203/416 [00:49<00:45,  4.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002      1.474      1.901          9        640:  49% 204/416 [00:49<00:40,  5.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.003      1.476      1.903          9        640:  49% 205/416 [00:49<00:43,  4.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.003      1.476      1.903         11        640:  50% 206/416 [00:49<00:42,  4.97it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.003      1.475      1.905         10        640:  50% 207/416 [00:50<00:48,  4.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002      1.473      1.904          8        640:  50% 208/416 [00:50<00:52,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G          1      1.471      1.903          8        640:  50% 209/416 [00:50<00:50,  4.12it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G          1      1.469      1.903          9        640:  50% 210/416 [00:50<00:48,  4.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002       1.47      1.904          9        640:  51% 211/416 [00:51<00:51,  3.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9995      1.471      1.902          9        640:  51% 212/416 [00:51<00:53,  3.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9999      1.471      1.903         12        640:  51% 213/416 [00:51<00:50,  4.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.999      1.469      1.901         10        640:  51% 214/416 [00:51<00:46,  4.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9991       1.47      1.902         11        640:  52% 215/416 [00:52<00:45,  4.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G          1      1.469      1.903          8        640:  52% 216/416 [00:52<00:44,  4.48it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.003       1.47      1.907         10        640:  52% 217/416 [00:52<00:42,  4.70it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002      1.469      1.905          9        640:  52% 218/416 [00:52<00:37,  5.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001      1.468      1.904          9        640:  53% 219/416 [00:53<00:52,  3.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002      1.468      1.905         11        640:  53% 220/416 [00:53<00:52,  3.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002      1.468      1.907         10        640:  53% 221/416 [00:53<00:55,  3.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.003      1.468      1.907         10        640:  53% 222/416 [00:53<00:54,  3.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002      1.466      1.905          8        640:  54% 223/416 [00:54<00:54,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001      1.465      1.904         10        640:  54% 224/416 [00:54<00:54,  3.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001      1.466      1.903         11        640:  54% 225/416 [00:54<00:53,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G          1      1.465      1.903         11        640:  54% 226/416 [00:55<00:53,  3.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001      1.465      1.905          9        640:  55% 227/416 [00:55<00:57,  3.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.002      1.465      1.906         12        640:  55% 228/416 [00:55<00:53,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001      1.464      1.905          9        640:  55% 229/416 [00:55<00:55,  3.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001      1.464      1.905          9        640:  55% 230/416 [00:56<00:57,  3.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G          1      1.463      1.904          9        640:  56% 231/416 [00:56<00:57,  3.23it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9982      1.462      1.902          9        640:  56% 232/416 [00:56<00:56,  3.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9963       1.46        1.9          9        640:  56% 233/416 [00:57<00:51,  3.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9977      1.459      1.902         10        640:  56% 234/416 [00:57<00:50,  3.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9964      1.458      1.901          9        640:  56% 235/416 [00:57<00:53,  3.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9949      1.456      1.899          8        640:  57% 236/416 [00:57<00:45,  3.93it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9968      1.458      1.901         16        640:  57% 237/416 [00:58<00:44,  4.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.997      1.458      1.902          9        640:  57% 238/416 [00:58<00:43,  4.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9968      1.457      1.901         10        640:  57% 239/416 [00:58<00:42,  4.14it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001       1.46      1.904          9        640:  58% 240/416 [00:58<00:37,  4.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      1.001       1.46      1.904         10        640:  58% 241/416 [00:58<00:36,  4.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9991      1.458      1.903          8        640:  58% 242/416 [00:59<00:35,  4.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9972      1.457      1.901          7        640:  58% 243/416 [00:59<00:37,  4.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9976      1.457      1.902          9        640:  59% 244/416 [00:59<00:34,  5.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9981      1.457      1.902          9        640:  59% 245/416 [00:59<00:34,  4.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9967      1.457      1.901          9        640:  59% 246/416 [00:59<00:32,  5.22it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9954      1.455        1.9          8        640:  59% 247/416 [01:00<00:31,  5.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9945      1.455      1.899          9        640:  60% 248/416 [01:00<00:31,  5.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9943      1.456      1.899          8        640:  60% 249/416 [01:00<00:35,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9928      1.456      1.898          9        640:  60% 250/416 [01:00<00:32,  5.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9924      1.457      1.897          9        640:  60% 251/416 [01:00<00:32,  5.06it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9915      1.456      1.896          9        640:  61% 252/416 [01:01<00:30,  5.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.991      1.456      1.896          9        640:  61% 253/416 [01:01<00:34,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.993      1.457      1.898         11        640:  61% 254/416 [01:01<00:31,  5.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9938      1.458      1.899          9        640:  61% 255/416 [01:01<00:29,  5.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9938       1.46        1.9          8        640:  62% 256/416 [01:01<00:30,  5.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.993       1.46      1.898          8        640:  62% 257/416 [01:02<00:30,  5.17it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9916       1.46      1.897          9        640:  62% 258/416 [01:02<00:32,  4.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9932       1.46      1.899         10        640:  62% 259/416 [01:02<00:34,  4.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9923      1.461      1.897          8        640:  62% 260/416 [01:02<00:31,  4.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9907      1.459      1.896          8        640:  63% 261/416 [01:02<00:27,  5.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9919       1.46      1.897         13        640:  63% 262/416 [01:03<00:32,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9912      1.463      1.896          8        640:  63% 263/416 [01:03<00:33,  4.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9895       1.46      1.894          8        640:  63% 264/416 [01:03<00:33,  4.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9906      1.462      1.896         11        640:  64% 265/416 [01:03<00:29,  5.12it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9895       1.46      1.895          8        640:  64% 266/416 [01:03<00:30,  4.87it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.987       1.46      1.893          8        640:  64% 267/416 [01:04<00:34,  4.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9876       1.46      1.893         11        640:  64% 268/416 [01:04<00:35,  4.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9874       1.46      1.893          9        640:  65% 269/416 [01:04<00:34,  4.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9872      1.459      1.892          8        640:  65% 270/416 [01:05<00:36,  3.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9866      1.458      1.892          8        640:  65% 271/416 [01:05<00:31,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9865      1.458      1.892          9        640:  65% 272/416 [01:05<00:30,  4.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9857      1.457      1.892          7        640:  66% 273/416 [01:05<00:28,  4.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9855      1.456      1.892         10        640:  66% 274/416 [01:05<00:27,  5.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9847      1.456      1.891          9        640:  66% 275/416 [01:06<00:33,  4.20it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9841      1.454      1.891          8        640:  66% 276/416 [01:06<00:31,  4.42it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9827      1.453       1.89          9        640:  67% 277/416 [01:06<00:31,  4.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9818      1.453      1.889          9        640:  67% 278/416 [01:06<00:33,  4.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9835      1.455      1.891          9        640:  67% 279/416 [01:07<00:34,  3.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9828      1.454      1.891          8        640:  67% 280/416 [01:07<00:38,  3.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9853      1.456      1.893         12        640:  68% 281/416 [01:07<00:36,  3.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9845      1.455      1.892          8        640:  68% 282/416 [01:07<00:37,  3.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9851      1.455      1.892         10        640:  68% 283/416 [01:08<00:40,  3.29it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9849      1.455      1.892          9        640:  68% 284/416 [01:08<00:38,  3.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9855      1.455      1.893          8        640:  69% 285/416 [01:08<00:37,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9839      1.453      1.891          8        640:  69% 286/416 [01:09<00:35,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9841      1.454      1.891         12        640:  69% 287/416 [01:09<00:38,  3.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9825      1.453       1.89          8        640:  69% 288/416 [01:09<00:38,  3.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9809      1.452      1.889          9        640:  69% 289/416 [01:10<00:37,  3.34it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9818      1.452      1.889         12        640:  70% 290/416 [01:10<00:36,  3.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9803       1.45      1.888          9        640:  70% 291/416 [01:10<00:38,  3.25it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9798       1.45      1.888          8        640:  70% 292/416 [01:10<00:35,  3.47it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9795      1.449      1.887          9        640:  70% 293/416 [01:11<00:33,  3.67it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9782      1.447      1.886          8        640:  71% 294/416 [01:11<00:32,  3.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9793      1.448      1.887          6        640:  71% 295/416 [01:11<00:33,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9794      1.448      1.886         11        640:  71% 296/416 [01:11<00:32,  3.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9786      1.447      1.885          8        640:  71% 297/416 [01:12<00:30,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9765      1.445      1.883          8        640:  72% 298/416 [01:12<00:29,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9796      1.446      1.886         10        640:  72% 299/416 [01:12<00:31,  3.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9787      1.446      1.886          7        640:  72% 300/416 [01:12<00:30,  3.80it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9771      1.445      1.884          7        640:  72% 301/416 [01:13<00:28,  3.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9768      1.445      1.884          9        640:  73% 302/416 [01:13<00:29,  3.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.976      1.443      1.883          8        640:  73% 303/416 [01:13<00:27,  4.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9745      1.442      1.882          8        640:  73% 304/416 [01:13<00:28,  3.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9736      1.442      1.881          8        640:  73% 305/416 [01:14<00:27,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9727      1.442       1.88          9        640:  74% 306/416 [01:14<00:24,  4.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9722      1.441      1.879          9        640:  74% 307/416 [01:14<00:22,  4.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9726       1.44       1.88          9        640:  74% 308/416 [01:14<00:22,  4.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9726       1.44       1.88          8        640:  74% 309/416 [01:14<00:22,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9737       1.44      1.881         11        640:  75% 310/416 [01:15<00:21,  4.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9721      1.439       1.88          7        640:  75% 311/416 [01:15<00:22,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.972      1.439       1.88         10        640:  75% 312/416 [01:15<00:22,  4.62it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9719      1.438      1.879          8        640:  75% 313/416 [01:15<00:22,  4.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9717      1.438      1.879          8        640:  75% 314/416 [01:16<00:22,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9709      1.436      1.878          9        640:  76% 315/416 [01:16<00:23,  4.39it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9708      1.437      1.878         11        640:  76% 316/416 [01:16<00:22,  4.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9699      1.437      1.877          9        640:  76% 317/416 [01:16<00:20,  4.89it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9698      1.436      1.877          9        640:  76% 318/416 [01:16<00:19,  5.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9714      1.439      1.879         13        640:  77% 319/416 [01:17<00:19,  5.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9726       1.44       1.88         10        640:  77% 320/416 [01:17<00:20,  4.71it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9737      1.441      1.881          9        640:  77% 321/416 [01:17<00:18,  5.04it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9744      1.441      1.882          9        640:  77% 322/416 [01:17<00:17,  5.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9745      1.441      1.882         10        640:  78% 323/416 [01:17<00:19,  4.76it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9746      1.441      1.882          9        640:  78% 324/416 [01:18<00:18,  4.95it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9745      1.441      1.882         10        640:  78% 325/416 [01:18<00:18,  4.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9756      1.442      1.883         11        640:  78% 326/416 [01:18<00:19,  4.51it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9749      1.444      1.882          8        640:  79% 327/416 [01:18<00:21,  4.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9744      1.443      1.882          9        640:  79% 328/416 [01:19<00:19,  4.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9759      1.445      1.884          9        640:  79% 329/416 [01:19<00:17,  4.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9758      1.444      1.884          9        640:  79% 330/416 [01:19<00:20,  4.21it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.976      1.445      1.884          8        640:  80% 331/416 [01:19<00:19,  4.41it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9751      1.445      1.883          7        640:  80% 332/416 [01:19<00:18,  4.55it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9732      1.443      1.881          8        640:  80% 333/416 [01:20<00:19,  4.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9728      1.443       1.88          8        640:  80% 334/416 [01:20<00:19,  4.18it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9733      1.444       1.88         10        640:  81% 335/416 [01:20<00:19,  4.19it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9767      1.447      1.883         13        640:  81% 336/416 [01:20<00:19,  4.16it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9763      1.448      1.883         13        640:  81% 337/416 [01:21<00:20,  3.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9762      1.449      1.883          8        640:  81% 338/416 [01:21<00:20,  3.74it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9769      1.449      1.883         10        640:  81% 339/416 [01:21<00:24,  3.10it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9756      1.448      1.882          7        640:  82% 340/416 [01:22<00:22,  3.43it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9768      1.451      1.883          8        640:  82% 341/416 [01:22<00:21,  3.44it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9796      1.454      1.886         10        640:  82% 342/416 [01:22<00:21,  3.49it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9802      1.454      1.887         10        640:  82% 343/416 [01:22<00:20,  3.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9794      1.454      1.886          9        640:  83% 344/416 [01:23<00:21,  3.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9798      1.454      1.887         10        640:  83% 345/416 [01:23<00:19,  3.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9804      1.456      1.887         11        640:  83% 346/416 [01:23<00:19,  3.58it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9802      1.455      1.888          9        640:  83% 347/416 [01:24<00:20,  3.33it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.981      1.455      1.888         10        640:  84% 348/416 [01:24<00:20,  3.28it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9796      1.454      1.887          8        640:  84% 349/416 [01:24<00:19,  3.37it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9804      1.454      1.887          9        640:  84% 350/416 [01:24<00:17,  3.78it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9811      1.454      1.887          9        640:  84% 351/416 [01:25<00:16,  3.86it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9805      1.453      1.887          9        640:  85% 352/416 [01:25<00:16,  3.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9798      1.452      1.886          7        640:  85% 353/416 [01:25<00:16,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9803      1.451      1.887          9        640:  85% 354/416 [01:25<00:15,  3.96it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9789       1.45      1.886          8        640:  85% 355/416 [01:26<00:17,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9778      1.448      1.885          8        640:  86% 356/416 [01:26<00:14,  4.11it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9781      1.449      1.886          9        640:  86% 357/416 [01:26<00:13,  4.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9767      1.448      1.885          8        640:  86% 358/416 [01:26<00:12,  4.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9763      1.447      1.884          9        640:  86% 359/416 [01:27<00:11,  5.07it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9759      1.448      1.884          9        640:  87% 360/416 [01:27<00:12,  4.61it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9753      1.447      1.884          8        640:  87% 361/416 [01:27<00:12,  4.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.976      1.448      1.884          8        640:  87% 362/416 [01:27<00:12,  4.50it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9758      1.448      1.884          9        640:  87% 363/416 [01:27<00:11,  4.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9753      1.447      1.884          9        640:  88% 364/416 [01:28<00:11,  4.52it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9752      1.447      1.884          9        640:  88% 365/416 [01:28<00:11,  4.60it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9742      1.446      1.882          8        640:  88% 366/416 [01:28<00:11,  4.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9737      1.446      1.882          9        640:  88% 367/416 [01:28<00:10,  4.79it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9746      1.446      1.883          9        640:  88% 368/416 [01:29<00:10,  4.36it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9739      1.445      1.882          8        640:  89% 369/416 [01:29<00:09,  5.03it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9738      1.445      1.882          8        640:  89% 370/416 [01:29<00:08,  5.30it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.973      1.444      1.881          9        640:  89% 371/416 [01:29<00:09,  4.63it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9728      1.443      1.882          8        640:  89% 372/416 [01:29<00:09,  4.45it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9721      1.442      1.881          9        640:  90% 373/416 [01:30<00:10,  4.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9707      1.441      1.879          8        640:  90% 374/416 [01:30<00:09,  4.66it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9696      1.441      1.878          8        640:  90% 375/416 [01:30<00:09,  4.35it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9719      1.442       1.88          8        640:  90% 376/416 [01:30<00:08,  4.57it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9724      1.442       1.88         10        640:  91% 377/416 [01:31<00:09,  4.01it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9725      1.442       1.88          8        640:  91% 378/416 [01:31<00:09,  3.92it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9723      1.442      1.881          9        640:  91% 379/416 [01:31<00:09,  3.88it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9722      1.442      1.881          8        640:  91% 380/416 [01:31<00:09,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9712      1.441       1.88         10        640:  92% 381/416 [01:32<00:08,  4.15it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9714      1.441       1.88         10        640:  92% 382/416 [01:32<00:09,  3.77it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.971      1.441       1.88         10        640:  92% 383/416 [01:32<00:08,  3.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9695      1.439      1.879          8        640:  92% 384/416 [01:32<00:07,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G       0.97       1.44       1.88         11        640:  93% 385/416 [01:33<00:07,  4.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9686      1.438      1.878          8        640:  93% 386/416 [01:33<00:07,  4.00it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9709      1.438      1.881          8        640:  93% 387/416 [01:33<00:07,  3.84it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9705      1.437      1.881          8        640:  93% 388/416 [01:33<00:06,  4.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9702      1.436       1.88         10        640:  94% 389/416 [01:34<00:07,  3.83it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9701      1.435      1.881          9        640:  94% 390/416 [01:34<00:06,  3.85it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9694      1.436       1.88          9        640:  94% 391/416 [01:34<00:06,  3.64it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9685      1.435      1.879          8        640:  94% 392/416 [01:34<00:06,  3.94it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9691      1.434       1.88          8        640:  94% 393/416 [01:35<00:05,  4.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9694      1.434       1.88          8        640:  95% 394/416 [01:35<00:06,  3.53it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9686      1.433       1.88         10        640:  95% 395/416 [01:35<00:06,  3.32it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9685      1.433      1.879          9        640:  95% 396/416 [01:36<00:05,  3.75it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9691      1.434      1.879          9        640:  95% 397/416 [01:36<00:05,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9702      1.435       1.88         12        640:  96% 398/416 [01:36<00:04,  3.65it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9686      1.434      1.879          7        640:  96% 399/416 [01:36<00:04,  3.69it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9691      1.434      1.879         10        640:  96% 400/416 [01:37<00:04,  3.54it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.969      1.435      1.878          8        640:  96% 401/416 [01:37<00:04,  3.31it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9685      1.437      1.878          8        640:  97% 402/416 [01:37<00:04,  3.46it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9688      1.437      1.878         12        640:  97% 403/416 [01:38<00:04,  3.08it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9691      1.436      1.878         10        640:  97% 404/416 [01:38<00:03,  3.47it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9689      1.436      1.878          9        640:  97% 405/416 [01:38<00:03,  3.27it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9692      1.435      1.878         10        640:  98% 406/416 [01:38<00:02,  3.90it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9684      1.435      1.877          9        640:  98% 407/416 [01:39<00:02,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9687      1.435      1.877         10        640:  98% 408/416 [01:39<00:02,  3.91it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9687      1.435      1.878          8        640:  98% 409/416 [01:39<00:01,  4.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.968      1.435      1.877          8        640:  99% 410/416 [01:39<00:01,  3.99it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9687      1.436      1.878          8        640:  99% 411/416 [01:40<00:01,  3.73it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9678      1.435      1.877          8        640:  99% 412/416 [01:40<00:00,  4.09it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9675      1.435      1.877          8        640:  99% 413/416 [01:40<00:00,  4.26it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9672      1.436      1.877         10        640: 100% 414/416 [01:40<00:00,  4.02it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G     0.9674      1.436      1.877          7        640: 100% 415/416 [01:41<00:00,  4.38it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "      10/10       1.4G      0.968      1.438      1.877          3        640: 100% 416/416 [01:41<00:00,  4.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 11/11 [00:01<00:00,  5.53it/s]\n",
            "                   all        174        200      0.405      0.691      0.553       0.39\n",
            "\n",
            "10 epochs completed in 0.261 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 8.1MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 8.1MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics 8.3.160 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv8n-ghost1 summary (fused): 176 layers, 3,876,974 parameters, 0 gradients, 9.0 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 11/11 [00:03<00:00,  3.30it/s]\n",
            "                   all        174        200      0.405      0.691      0.553       0.39\n",
            "                   APE         60         72      0.412      0.431      0.436      0.288\n",
            "                   BPE         31         38      0.407      0.553      0.444      0.288\n",
            "                    NE         32         32      0.492      0.849      0.804      0.668\n",
            "                   VPE         53         58       0.31      0.931      0.527      0.315\n",
            "Speed: 0.4ms preprocess, 5.4ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!yolo task=detect mode=train model=/content/ultralytics/ultralytics/cfg/models/v8/yolov8n-ghost1.yaml data=/content/datasets/CPE-Dataset-16/data.yaml optimizer=SGD imgsz=640 epochs=10 batch=8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MScstfHhArr",
        "outputId": "df6dd974-c8b0-4df5-96ef-47a029eae47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "args.yaml\t\t\t PR_curve.png\t   val_batch0_labels.jpg\n",
            "confusion_matrix_normalized.png  R_curve.png\t   val_batch0_pred.jpg\n",
            "confusion_matrix.png\t\t results.csv\t   val_batch1_labels.jpg\n",
            "F1_curve.png\t\t\t results.png\t   val_batch1_pred.jpg\n",
            "labels_correlogram.jpg\t\t train_batch0.jpg  val_batch2_labels.jpg\n",
            "labels.jpg\t\t\t train_batch1.jpg  val_batch2_pred.jpg\n",
            "P_curve.png\t\t\t train_batch2.jpg  weights\n"
          ]
        }
      ],
      "source": [
        "!ls /content/runs/detect/train2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ODk1VTlevxn"
      },
      "source": [
        "## Validate Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpyuwrNlXc1P",
        "outputId": "0c68e1e5-2d6f-4223-d476-e4e7d58f7509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.160 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv8n-ghost1 summary (fused): 176 layers, 3,876,974 parameters, 0 gradients, 9.0 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 581.8±182.1 MB/s, size: 15.7 KB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/CPE-Dataset-16/valid/labels.cache... 174 images, 4 backgrounds, 0 corrupt: 100% 174/174 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 11/11 [00:03<00:00,  3.24it/s]\n",
            "                   all        174        200      0.403      0.691      0.553      0.389\n",
            "                   APE         60         72      0.406      0.431      0.436      0.287\n",
            "                   BPE         31         38      0.404      0.553      0.444      0.288\n",
            "                    NE         32         32      0.493      0.851      0.804      0.667\n",
            "                   VPE         53         58      0.309      0.931      0.528      0.314\n",
            "Speed: 1.0ms preprocess, 7.7ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!yolo task=detect mode=val model=/content/runs/detect/train2/weights/best.pt data=/content/datasets/CPE-Dataset-16/data.yaml  optimizer=SGD imgsz=640"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4eASbcWkQBq"
      },
      "source": [
        "## Inference with Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wjc1ctZykYuf",
        "outputId": "cae7c869-308b-48e9-dd93-4faa5ed52b7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '{HOME}'\n",
            "/content\n",
            "Ultralytics 8.3.160 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv8n-ghost1 summary (fused): 176 layers, 3,876,974 parameters, 0 gradients, 9.0 GFLOPs\n",
            "\n",
            "image 1/174 /content/datasets/CPE-Dataset-16/valid/images/1-Copy-Copy-Copy_jpg.rf.34d4ed872aceb1e9fdd7f77b9522bbab.jpg: 640x640 1 APE, 1 BPE, 1 VPE, 15.9ms\n",
            "image 2/174 /content/datasets/CPE-Dataset-16/valid/images/100_jpg.rf.d220165e74ce0ab421cbb6f0c34d28e1.jpg: 640x640 (no detections), 16.1ms\n",
            "image 3/174 /content/datasets/CPE-Dataset-16/valid/images/106_jpeg_jpg.rf.335d12ac7972c7610a4bc7dcb3fa2552.jpg: 640x640 1 VPE, 13.7ms\n",
            "image 4/174 /content/datasets/CPE-Dataset-16/valid/images/115_jpg.rf.12709be353f57eb15c8db3fbadee1e78.jpg: 640x640 1 NE, 13.5ms\n",
            "image 5/174 /content/datasets/CPE-Dataset-16/valid/images/117_jpg.rf.98a995ef62f15e41a9e68b50ba699424.jpg: 640x640 1 VPE, 13.5ms\n",
            "image 6/174 /content/datasets/CPE-Dataset-16/valid/images/117_jpg.rf.cb439bfa4dc961a3617f2b2ffab16f51.jpg: 640x640 1 NE, 13.5ms\n",
            "image 7/174 /content/datasets/CPE-Dataset-16/valid/images/119_jpg.rf.f282f0ba0094ac97e054acdff57d6008.jpg: 640x640 1 NE, 13.8ms\n",
            "image 8/174 /content/datasets/CPE-Dataset-16/valid/images/127_jpg.rf.4a296847ae4d4230f8c69edee300c6b3.jpg: 640x640 1 VPE, 14.8ms\n",
            "image 9/174 /content/datasets/CPE-Dataset-16/valid/images/137_jpg.rf.deb8a90fe8cddd341d1008c44b22b357.jpg: 640x640 (no detections), 13.5ms\n",
            "image 10/174 /content/datasets/CPE-Dataset-16/valid/images/139_jpg.rf.ce60d34b762a7f2ee45a97b917d47412.jpg: 640x640 2 VPEs, 12.4ms\n",
            "image 11/174 /content/datasets/CPE-Dataset-16/valid/images/145-Copy-2-_jpg.rf.943097c86ff0f14ef0f5ee1f24d52038.jpg: 640x640 1 VPE, 12.1ms\n",
            "image 12/174 /content/datasets/CPE-Dataset-16/valid/images/147_jpg.rf.f7dba152edaf87f4b4065696c1e227b2.jpg: 640x640 1 VPE, 12.0ms\n",
            "image 13/174 /content/datasets/CPE-Dataset-16/valid/images/156_jpeg.rf.55819949e8059ed1fdecc48d60763f4b.jpg: 640x640 1 VPE, 12.1ms\n",
            "image 14/174 /content/datasets/CPE-Dataset-16/valid/images/1690734642728_jpeg.rf.e6e2a87d8d625efeb0b5cdf0aa0ae8b6.jpg: 640x640 2 VPEs, 12.2ms\n",
            "image 15/174 /content/datasets/CPE-Dataset-16/valid/images/1695932841762_jpeg_jpg.rf.f315fd69f725fc08c7f9a50b739efeb1.jpg: 640x640 1 NE, 12.2ms\n",
            "image 16/174 /content/datasets/CPE-Dataset-16/valid/images/1697018829566_jpeg.rf.320e2a169eb379ac56f6baf94aa230a7.jpg: 640x640 (no detections), 12.1ms\n",
            "image 17/174 /content/datasets/CPE-Dataset-16/valid/images/1697046203888_jpeg.rf.e1c0686d2e5814abb75db04b6cc45831.jpg: 640x640 1 VPE, 12.0ms\n",
            "image 18/174 /content/datasets/CPE-Dataset-16/valid/images/1697442158601_jpeg.rf.037f1fc1e12174dfe43b05d4c34e773e.jpg: 640x640 1 VPE, 14.9ms\n",
            "image 19/174 /content/datasets/CPE-Dataset-16/valid/images/16_jpg.rf.5a6626ebac407016803ac88356ec4d7a.jpg: 640x640 1 APE, 13.3ms\n",
            "image 20/174 /content/datasets/CPE-Dataset-16/valid/images/207_jpeg.rf.f79f5b46cb0fb683fba69061162a4009.jpg: 640x640 1 VPE, 12.1ms\n",
            "image 21/174 /content/datasets/CPE-Dataset-16/valid/images/208_jpg.rf.e3418b76581d8bb728b77dea17e321e2.jpg: 640x640 1 VPE, 19.7ms\n",
            "image 22/174 /content/datasets/CPE-Dataset-16/valid/images/20_jpg.rf.e89ed84dc18be387fd7dea5ec23c6654.jpg: 640x640 1 NE, 10.6ms\n",
            "image 23/174 /content/datasets/CPE-Dataset-16/valid/images/21_jpg.rf.d3de8551f8e07b6bb79d45c5ced98815.jpg: 640x640 1 VPE, 10.8ms\n",
            "image 24/174 /content/datasets/CPE-Dataset-16/valid/images/240_F_209899320_JFX3bDlJrn4fYsGkLjXYIgIZlFRnOYIX-Copy_jpg.rf.42fa0b943cccfb723930f0f7cc8aebb1.jpg: 640x640 1 NE, 10.6ms\n",
            "image 25/174 /content/datasets/CPE-Dataset-16/valid/images/240_F_261754605_WfwZSL4wag3qHWCSqKCpnlwOgOTgz35L-Copy_jpg.rf.91d6aa14c56bcbc7a1ff8d818dd7f209.jpg: 640x640 1 NE, 10.7ms\n",
            "image 26/174 /content/datasets/CPE-Dataset-16/valid/images/240_F_304162992_U1V3pRO71rOfXB2Bfo7jfaH1S1CeX8Xr-Copy_jpg.rf.a366a4093974b3e7793a375a05e09108.jpg: 640x640 1 NE, 1 VPE, 10.5ms\n",
            "image 27/174 /content/datasets/CPE-Dataset-16/valid/images/240_F_541314083_bhXJ0vZBRdleFSg2thhmmgDzZ3lWvTkK-Copy_jpg.rf.390d7fbc7906ecbea44207d424096775.jpg: 640x640 1 NE, 10.6ms\n",
            "image 28/174 /content/datasets/CPE-Dataset-16/valid/images/240_F_574088254_s4JN4U1VormiR2ipVa6NpblpLq69Rpq5-Copy_jpg.rf.28b316687e209fe376582a84cb9bf8a8.jpg: 640x640 1 NE, 10.6ms\n",
            "image 29/174 /content/datasets/CPE-Dataset-16/valid/images/240_F_659482120_fs0YdszA9Ta6GoBoCwJbOvhLYcd4Mw3P-Copy_jpg.rf.80ef48aab1aa6e881c85f2278aad7c91.jpg: 640x640 1 NE, 12.6ms\n",
            "image 30/174 /content/datasets/CPE-Dataset-16/valid/images/240_F_87499670_UHSm9JM1vpFSBxfWfOncqZnPXmxHE5RY-Copy_jpg.rf.1a61d8a7a595a4327433a452b6973589.jpg: 640x640 1 NE, 10.9ms\n",
            "image 31/174 /content/datasets/CPE-Dataset-16/valid/images/29_jpg.rf.44de0fc9d4bf96f267d67af2031aca3c.jpg: 640x640 1 VPE, 10.8ms\n",
            "image 32/174 /content/datasets/CPE-Dataset-16/valid/images/3-Copy_jpg.rf.a0d2c3567379bf3b10f82d64256368b1.jpg: 640x640 1 APE, 10.9ms\n",
            "image 33/174 /content/datasets/CPE-Dataset-16/valid/images/32_jpg.rf.28df83b6af7cb9181718cd0c361b0b92.jpg: 640x640 1 VPE, 10.7ms\n",
            "image 34/174 /content/datasets/CPE-Dataset-16/valid/images/360_F_392813510_u3TKxMCwAGwYNhK9HZsLKQK7jm09Z4DK-Copy_jpg.rf.2f258eba3b7b3de61433821b803dca00.jpg: 640x640 1 NE, 10.6ms\n",
            "image 35/174 /content/datasets/CPE-Dataset-16/valid/images/36_jpg.rf.4a3d2469051e240d078281c16fdfa188.jpg: 640x640 (no detections), 10.6ms\n",
            "image 36/174 /content/datasets/CPE-Dataset-16/valid/images/38_jpg.rf.4224137aabf67bbf8966104c12de0d3b.jpg: 640x640 1 BPE, 1 NE, 12.6ms\n",
            "image 37/174 /content/datasets/CPE-Dataset-16/valid/images/4-Copy_jpg.rf.9cff88370c9cab9aa995134aaa341f11.jpg: 640x640 1 NE, 11.0ms\n",
            "image 38/174 /content/datasets/CPE-Dataset-16/valid/images/44_jpg.rf.793c14bb81c4cd05607152ec0dd41998.jpg: 640x640 1 VPE, 10.5ms\n",
            "image 39/174 /content/datasets/CPE-Dataset-16/valid/images/4_jpg.rf.f626cbcc2727f65b9afe5786f5493de1.jpg: 640x640 2 VPEs, 10.5ms\n",
            "image 40/174 /content/datasets/CPE-Dataset-16/valid/images/5-Copy-2-Copy-Copy-Copy-Copy_jpg.rf.448e13253478a5680fce33134857fff7.jpg: 640x640 1 VPE, 11.4ms\n",
            "image 41/174 /content/datasets/CPE-Dataset-16/valid/images/51_jpg.rf.3552dccfb332effa2cbd44bd75a23271.jpg: 640x640 1 VPE, 10.9ms\n",
            "image 42/174 /content/datasets/CPE-Dataset-16/valid/images/57_jpg.rf.7bd9ab158e561c8bb3a6f83d966caf67.jpg: 640x640 1 VPE, 10.6ms\n",
            "image 43/174 /content/datasets/CPE-Dataset-16/valid/images/60_jpg.rf.43db9e133f68469823e00139162a71c1.jpg: 640x640 (no detections), 10.6ms\n",
            "image 44/174 /content/datasets/CPE-Dataset-16/valid/images/67_jpg.rf.2937d521e6c8b53e198adf8620d32e11.jpg: 640x640 1 VPE, 10.6ms\n",
            "image 45/174 /content/datasets/CPE-Dataset-16/valid/images/6_jpg.rf.95eff5686251a49d7b595f13cab4d329.jpg: 640x640 1 VPE, 10.5ms\n",
            "image 46/174 /content/datasets/CPE-Dataset-16/valid/images/72_jpg.rf.f47e80a215ea386e80f3a2e97a81a462.jpg: 640x640 1 VPE, 10.4ms\n",
            "image 47/174 /content/datasets/CPE-Dataset-16/valid/images/76f841519f723e520f10fff2178f098b-1-Copy_jpg.rf.cc955614f49e8bd4a82e3153d1147db3.jpg: 640x640 1 NE, 10.5ms\n",
            "image 48/174 /content/datasets/CPE-Dataset-16/valid/images/82_jpg.rf.9654f26e2d5edbf1ac6e87f48c50a939.jpg: 640x640 1 BPE, 1 VPE, 10.9ms\n",
            "image 49/174 /content/datasets/CPE-Dataset-16/valid/images/8_jpg.rf.84609f69d96f97c8a0f8a89cae8e7e56.jpg: 640x640 1 NE, 10.6ms\n",
            "image 50/174 /content/datasets/CPE-Dataset-16/valid/images/8_jpg.rf.88c293921c1c332fb508efc4434825c8.jpg: 640x640 1 APE, 1 BPE, 10.4ms\n",
            "image 51/174 /content/datasets/CPE-Dataset-16/valid/images/8_jpg.rf.e813214cab2227ef3fc4ba1e3803b748.jpg: 640x640 1 VPE, 10.5ms\n",
            "image 52/174 /content/datasets/CPE-Dataset-16/valid/images/95_jpg.rf.3a9d26aaf39cdb491bfb356bcc3ef04a.jpg: 640x640 1 APE, 10.4ms\n",
            "image 53/174 /content/datasets/CPE-Dataset-16/valid/images/95_jpg.rf.e1fc9054948bbad9fae2bbea85d6ce52.jpg: 640x640 1 NE, 13.8ms\n",
            "image 54/174 /content/datasets/CPE-Dataset-16/valid/images/98_jpg.rf.2602642c9b7a3e2ec704b637bf8fb9a5.jpg: 640x640 1 VPE, 11.0ms\n",
            "image 55/174 /content/datasets/CPE-Dataset-16/valid/images/C0072735-Adenoviral_conjunctivitis_of_the_eye_jpg.rf.db01bf517382982c0fe4faba0b4be567.jpg: 640x640 1 VPE, 10.6ms\n",
            "image 56/174 /content/datasets/CPE-Dataset-16/valid/images/C0111797-Adenoviral_conjunctivitis_of_the_eyes-Copy-2-_jpg.rf.614a19eb2096dad244154c4286b17bf1.jpg: 640x640 1 VPE, 11.3ms\n",
            "image 57/174 /content/datasets/CPE-Dataset-16/valid/images/C0111940-Human_eye_showing_conjunctivitis-Copy-2-_jpg.rf.19f6910123578da4678b6596346ae02b.jpg: 640x640 1 VPE, 15.1ms\n",
            "image 58/174 /content/datasets/CPE-Dataset-16/valid/images/C0131008-Herpes_simplex_eye_infection_jpg.rf.d09a4c8bdcbd41917954b0888fcbf865.jpg: 640x640 1 VPE, 12.0ms\n",
            "image 59/174 /content/datasets/CPE-Dataset-16/valid/images/C0197764-Allergic_conjunctivitis_jpg.rf.178bf1904726eba9daf4a807cfdf5d1f.jpg: 640x640 1 VPE, 10.4ms\n",
            "image 60/174 /content/datasets/CPE-Dataset-16/valid/images/C0426380-Viral_conjunctivitis_jpg.rf.789fe0bb3b44eb794170e709497f9ee7.jpg: 640x640 2 VPEs, 10.5ms\n",
            "image 61/174 /content/datasets/CPE-Dataset-16/valid/images/C0500784-Kawasaki_disease_jpg.rf.0d04151d7df812bb01c860b763e95b3d.jpg: 640x640 1 VPE, 10.4ms\n",
            "image 62/174 /content/datasets/CPE-Dataset-16/valid/images/M1550406-Close-up_of_eye_with_viral_conjunctivitis_jpg.rf.ebaede45d0dd7dc736fde72177ee156e.jpg: 640x640 1 VPE, 10.3ms\n",
            "image 63/174 /content/datasets/CPE-Dataset-16/valid/images/M1550419-Acute_conjunctivitis_discharge_from_child_s_eye_jpg.rf.9e9a59ccf2c05d71e475e3718e6c57cb.jpg: 640x640 (no detections), 10.4ms\n",
            "image 64/174 /content/datasets/CPE-Dataset-16/valid/images/M1550441-Allergic_conjunctivitis_jpg.rf.d27f4c20beb84af47c0ff01dd8934cae.jpg: 640x640 1 APE, 1 VPE, 10.9ms\n",
            "image 65/174 /content/datasets/CPE-Dataset-16/valid/images/M1550486-Allergic_conjuctivitis_jpg.rf.3e3c96213bd5d25e31287eea96a87bd3.jpg: 640x640 1 VPE, 10.5ms\n",
            "image 66/174 /content/datasets/CPE-Dataset-16/valid/images/M1550493-Viral_conjuctivitis_jpg.rf.72dc03fd1c35781baa641290e49357e4.jpg: 640x640 1 VPE, 10.4ms\n",
            "image 67/174 /content/datasets/CPE-Dataset-16/valid/images/M1550497-Viral_conjunctivitis_jpg.rf.5125f9f494e39ebba206057e917f8627.jpg: 640x640 2 VPEs, 10.7ms\n",
            "image 68/174 /content/datasets/CPE-Dataset-16/valid/images/M1550597-Bacterial_conjunctivitis_jpg.rf.cbcb448f638604114fc2992a52c181a9.jpg: 640x640 1 VPE, 10.4ms\n",
            "image 69/174 /content/datasets/CPE-Dataset-16/valid/images/WhatsApp-Image-2023-10-26-at-10-01-19-AM_jpeg.rf.e003c88f81da16a0316fefbdcbb64a2b.jpg: 640x640 1 VPE, 10.5ms\n",
            "image 70/174 /content/datasets/CPE-Dataset-16/valid/images/a11-Copy-2-_jpg.rf.1527ae96e8c3893e98f4e7d72de09ace.jpg: 640x640 1 VPE, 13.0ms\n",
            "image 71/174 /content/datasets/CPE-Dataset-16/valid/images/a13-Copy-2-_jpg.rf.311aa6774993332b34b5adb7146e2ea1.jpg: 640x640 1 BPE, 1 VPE, 10.4ms\n",
            "image 72/174 /content/datasets/CPE-Dataset-16/valid/images/a6_jpg.rf.393e0e5152a7cfc7a1e4e511ca011cc0.jpg: 640x640 (no detections), 11.9ms\n",
            "image 73/174 /content/datasets/CPE-Dataset-16/valid/images/a81c96e5b7717c6e47151e8098a0a0b2-Copy_jpg.rf.aed089007ffe254f550d45c4c691c89a.jpg: 640x640 1 NE, 10.3ms\n",
            "image 74/174 /content/datasets/CPE-Dataset-16/valid/images/b190834787bc318f33443689729334f6-Copy_jpg.rf.a600ee337a4ca8ef12aa0a97fbdfe6ec.jpg: 640x640 1 NE, 10.4ms\n",
            "image 75/174 /content/datasets/CPE-Dataset-16/valid/images/b3-Copy-Copy_jpg.rf.2b425acd5de45602047fb97d73010048.jpg: 640x640 1 VPE, 10.3ms\n",
            "image 76/174 /content/datasets/CPE-Dataset-16/valid/images/b98bdade77381f195d8a1beb38800ec9-Copy_jpg.rf.4898eec2bf69ac0fa3400fac1cbf70c7.jpg: 640x640 1 NE, 10.3ms\n",
            "image 77/174 /content/datasets/CPE-Dataset-16/valid/images/bc10_jpg.rf.7c908b2cd477199d89b3967386ebc0bc.jpg: 640x640 (no detections), 10.3ms\n",
            "image 78/174 /content/datasets/CPE-Dataset-16/valid/images/bc29_jpg.rf.1c05b12a98b4cb673b51e88e3bc78371.jpg: 640x640 2 VPEs, 10.6ms\n",
            "image 79/174 /content/datasets/CPE-Dataset-16/valid/images/download-100-_jpeg-Copy-Copy-Copy-2-_jpg.rf.d3cf53b3b867e21528083da8be922155.jpg: 640x640 1 VPE, 11.7ms\n",
            "image 80/174 /content/datasets/CPE-Dataset-16/valid/images/download-11-Copy_jpg.rf.876c45a0fe16e2f4f527aad7cf049c66.jpg: 640x640 1 NE, 16.1ms\n",
            "image 81/174 /content/datasets/CPE-Dataset-16/valid/images/download-17-Copy-Copy-Copy-2-_jpg.rf.83ec5248e406ba8b1308cde0800b3a8c.jpg: 640x640 1 VPE, 18.9ms\n",
            "image 82/174 /content/datasets/CPE-Dataset-16/valid/images/download-17-_jpg.rf.744659c8f91b1c56a4461b764678445e.jpg: 640x640 1 VPE, 13.1ms\n",
            "image 83/174 /content/datasets/CPE-Dataset-16/valid/images/download-18-_jpg.rf.4c2dca4b6b3e73f0842e12a5fd2ce36e.jpg: 640x640 1 NE, 1 VPE, 10.6ms\n",
            "image 84/174 /content/datasets/CPE-Dataset-16/valid/images/download-2023-10-16T144303-153_jpeg_jpg.rf.f310c94031ab12f9d9a38d7c8acd717a.jpg: 640x640 1 VPE, 10.5ms\n",
            "image 85/174 /content/datasets/CPE-Dataset-16/valid/images/download-57-_jpeg.rf.ed5ea4052be794c8daaca696b9f3fa06.jpg: 640x640 1 VPE, 10.6ms\n",
            "image 86/174 /content/datasets/CPE-Dataset-16/valid/images/download-6-_jpg.rf.f658ba3eef78b296c15922fd22a333a8.jpg: 640x640 1 VPE, 10.7ms\n",
            "image 87/174 /content/datasets/CPE-Dataset-16/valid/images/eyes_107_jpg.rf.a331a6410a3cd705dc246a3e13037332.jpg: 640x640 1 NE, 10.4ms\n",
            "image 88/174 /content/datasets/CPE-Dataset-16/valid/images/eyes_10_jpg.rf.ad0acc9e434227f5034ae86de0f12dea.jpg: 640x640 1 VPE, 10.4ms\n",
            "image 89/174 /content/datasets/CPE-Dataset-16/valid/images/eyes_112_jpg.rf.21b24701198d1dae9f7454a339846f7d.jpg: 640x640 1 APE, 10.5ms\n",
            "image 90/174 /content/datasets/CPE-Dataset-16/valid/images/eyes_126_jpg.rf.3bfe0402be0ce66b96ace06d711873a7.jpg: 640x640 1 NE, 10.5ms\n",
            "image 91/174 /content/datasets/CPE-Dataset-16/valid/images/eyes_183_jpg.rf.2fed24c5fc009fde6f04f43d68c47f71.jpg: 640x640 1 VPE, 10.5ms\n",
            "image 92/174 /content/datasets/CPE-Dataset-16/valid/images/eyes_188_jpg.rf.bbb137e26a499f0ed63e364ed8cf8ce6.jpg: 640x640 1 VPE, 12.5ms\n",
            "image 93/174 /content/datasets/CPE-Dataset-16/valid/images/eyes_189_jpg.rf.ed856a931b315daf1d747e253777ef8f.jpg: 640x640 2 VPEs, 12.2ms\n",
            "image 94/174 /content/datasets/CPE-Dataset-16/valid/images/eyes_204_jpg.rf.fed0efea57a2faaa003870fc02282750.jpg: 640x640 2 VPEs, 10.4ms\n",
            "image 95/174 /content/datasets/CPE-Dataset-16/valid/images/eyes_206_jpg.rf.a9d05597e0b54fe251d56930c8082887.jpg: 640x640 1 VPE, 10.5ms\n",
            "image 96/174 /content/datasets/CPE-Dataset-16/valid/images/eyes_239_jpg.rf.81694ddf1205882248a1a6c7191c2044.jpg: 640x640 1 VPE, 10.4ms\n",
            "image 97/174 /content/datasets/CPE-Dataset-16/valid/images/eyes_3_jpg.rf.5f1cb07f5f0f364b27f911f62fb23de8.jpg: 640x640 1 VPE, 13.8ms\n",
            "image 98/174 /content/datasets/CPE-Dataset-16/valid/images/eyes_4_jpg.rf.292398a48a36fb67722d041d52512209.jpg: 640x640 1 VPE, 11.6ms\n",
            "image 99/174 /content/datasets/CPE-Dataset-16/valid/images/images-10-Copy_jpg.rf.dfb0b2c1733dfca19eb751338e848917.jpg: 640x640 1 NE, 10.6ms\n",
            "image 100/174 /content/datasets/CPE-Dataset-16/valid/images/images-12-_jpg.rf.521df63b732301090d338708ed9af5ea.jpg: 640x640 1 BPE, 11.1ms\n",
            "image 101/174 /content/datasets/CPE-Dataset-16/valid/images/images-13-_jpg.rf.26c6d33476384fb1b0e0a6c15049419d.jpg: 640x640 1 APE, 1 BPE, 1 VPE, 10.3ms\n",
            "image 102/174 /content/datasets/CPE-Dataset-16/valid/images/images-13-_jpg.rf.f90293b92cfe3d825f63f7d50386b9f1.jpg: 640x640 1 BPE, 10.4ms\n",
            "image 103/174 /content/datasets/CPE-Dataset-16/valid/images/images-14-_jpg.rf.ff4ed8580783d12d41fadd7c77dbcffc.jpg: 640x640 (no detections), 10.3ms\n",
            "image 104/174 /content/datasets/CPE-Dataset-16/valid/images/images-15-_jpeg.rf.bf1100a45f44d28b6894dd729d221aa8.jpg: 640x640 1 VPE, 12.4ms\n",
            "image 105/174 /content/datasets/CPE-Dataset-16/valid/images/images-15-_jpg.rf.9f4b91889387d010863a08f0552b0c94.jpg: 640x640 (no detections), 10.3ms\n",
            "image 106/174 /content/datasets/CPE-Dataset-16/valid/images/images-18-_jpg.rf.504cbdb75386781bb575d430eab63dbe.jpg: 640x640 (no detections), 11.4ms\n",
            "image 107/174 /content/datasets/CPE-Dataset-16/valid/images/images-1_jpeg_jpg.rf.377a5a7fd2b26f6c0442d5ef1069dc62.jpg: 640x640 1 VPE, 10.3ms\n",
            "image 108/174 /content/datasets/CPE-Dataset-16/valid/images/images-2-2-_jpeg_jpg.rf.e7bb8e2015d5c29032dd4af679fd032a.jpg: 640x640 1 APE, 10.4ms\n",
            "image 109/174 /content/datasets/CPE-Dataset-16/valid/images/images-2-_jpeg.rf.22c981e91079c133e5116a63a08b312f.jpg: 640x640 2 VPEs, 10.4ms\n",
            "image 110/174 /content/datasets/CPE-Dataset-16/valid/images/images-2-_jpg.rf.8d161ef4caf3755749293dcb2e9afe8e.jpg: 640x640 1 VPE, 10.7ms\n",
            "image 111/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T122711-665_jpeg.rf.4b83b82f946309913149ec798e268953.jpg: 640x640 1 NE, 1 VPE, 10.6ms\n",
            "image 112/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T130649-960_jpeg.rf.381fefc19fd7c5f5a9c4f7d0749c113c.jpg: 640x640 1 VPE, 11.2ms\n",
            "image 113/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T130654-119_jpeg.rf.7a34be80fa8a7923fbad523f97daff74.jpg: 640x640 1 VPE, 11.1ms\n",
            "image 114/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T131906-601_jpeg_jpg.rf.fe0c03b425509a2b8416cd764d2c411c.jpg: 640x640 2 VPEs, 10.8ms\n",
            "image 115/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T131956-672_jpeg.rf.290f969ee233fb7340148657506806b4.jpg: 640x640 1 VPE, 10.9ms\n",
            "image 116/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T140015-178_jpeg.rf.732df643a9fa8e87413a99cf1c87d07d.jpg: 640x640 1 VPE, 12.7ms\n",
            "image 117/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T140519-588_jpeg_jpg.rf.4c18361506fa10a00ba0fbfffa377a1e.jpg: 640x640 1 VPE, 10.4ms\n",
            "image 118/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T140758-434_jpeg.rf.a9c57e048cc41ede75e30b17db2270f7.jpg: 640x640 1 VPE, 10.4ms\n",
            "image 119/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T140943-788_jpeg.rf.458db9fff2a1cd320408e4e7c0e3ec65.jpg: 640x640 1 VPE, 10.3ms\n",
            "image 120/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T141626-769_jpeg.rf.1ee868c70ede737e4d1ea1037db070db.jpg: 640x640 1 VPE, 10.2ms\n",
            "image 121/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T141653-695_jpeg.rf.dda4e32666afb00b35dd352f60abf684.jpg: 640x640 2 VPEs, 10.6ms\n",
            "image 122/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T143548-226_jpeg.rf.377673bc4939c5e894b805a400afe8d2.jpg: 640x640 (no detections), 11.8ms\n",
            "image 123/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T143731-284_jpeg.rf.93d997fd57219aa6b9955468c8a17778.jpg: 640x640 1 VPE, 10.3ms\n",
            "image 124/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T144423-052_jpeg_jpg.rf.46ef5871594c96a118188d55b45cb3bb.jpg: 640x640 2 VPEs, 10.6ms\n",
            "image 125/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T144703-299_jpeg.rf.8d21a4c01a2da8938545d84ce012f340.jpg: 640x640 1 VPE, 10.3ms\n",
            "image 126/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T145254-530_jpeg_jpg.rf.c79f1d42c8e9691e943f178c64420059.jpg: 640x640 1 VPE, 10.3ms\n",
            "image 127/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T145946-900_jpeg.rf.44bf16e80eaf0172919c6ce5c8347506.jpg: 640x640 1 VPE, 12.9ms\n",
            "image 128/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-10-16T150043-325_jpeg.rf.ebfa664c42c745a3b311508a494e3d10.jpg: 640x640 1 NE, 12.6ms\n",
            "image 129/174 /content/datasets/CPE-Dataset-16/valid/images/images-2023-11-12T160903-481-Copy_jpg.rf.46ba98ce8a0e32d8c77059817df2bd7a.jpg: 640x640 1 NE, 10.3ms\n",
            "image 130/174 /content/datasets/CPE-Dataset-16/valid/images/images-2024-07-05T154109-918_jpg.rf.4114440325f324bd9197cfa57b09930f.jpg: 640x640 1 VPE, 10.5ms\n",
            "image 131/174 /content/datasets/CPE-Dataset-16/valid/images/images-2024-07-05T154123-787_jpg.rf.c0dc3e6d0ddf8fa96e7807bc488b55e6.jpg: 640x640 1 VPE, 10.3ms\n",
            "image 132/174 /content/datasets/CPE-Dataset-16/valid/images/images-22-_jpg.rf.49e9f1e329988e8ecb10b23046feddc2.jpg: 640x640 1 APE, 1 BPE, 1 VPE, 10.3ms\n",
            "image 133/174 /content/datasets/CPE-Dataset-16/valid/images/images-23-1-_jpeg.rf.e31ca62cdbf92dd5f621ea69c0695032.jpg: 640x640 1 VPE, 10.2ms\n",
            "image 134/174 /content/datasets/CPE-Dataset-16/valid/images/images-23-_jpeg.rf.6f1d4829ef16677606ada5cddd15c9d3.jpg: 640x640 1 VPE, 10.6ms\n",
            "image 135/174 /content/datasets/CPE-Dataset-16/valid/images/images-23-_jpg.rf.c76f1b8e8335f05f1426c9fd5076f9a8.jpg: 640x640 1 BPE, 1 VPE, 10.4ms\n",
            "image 136/174 /content/datasets/CPE-Dataset-16/valid/images/images-24-_jpg.rf.443f95e4bd60a8965b80e4e37d803a76.jpg: 640x640 2 APEs, 10.4ms\n",
            "image 137/174 /content/datasets/CPE-Dataset-16/valid/images/images-24-_jpg.rf.97564970376da15b43fec1f7d577f8d4.jpg: 640x640 4 APEs, 11.7ms\n",
            "image 138/174 /content/datasets/CPE-Dataset-16/valid/images/images-24_jpeg.rf.10d0870a57ffa7efbfb2d84d37f0abca.jpg: 640x640 1 VPE, 10.3ms\n",
            "image 139/174 /content/datasets/CPE-Dataset-16/valid/images/images-26_jpeg.rf.1d10c5cd38fff4261a805c6218abc3a6.jpg: 640x640 1 VPE, 10.1ms\n",
            "image 140/174 /content/datasets/CPE-Dataset-16/valid/images/images-29-Copy_jpg.rf.16b22604d364796f2854f2daa4c1078b.jpg: 640x640 1 NE, 1 VPE, 14.9ms\n",
            "image 141/174 /content/datasets/CPE-Dataset-16/valid/images/images-30-Copy_jpg.rf.5a9712d6857816eeb5189fc1694f34b7.jpg: 640x640 1 NE, 15.5ms\n",
            "image 142/174 /content/datasets/CPE-Dataset-16/valid/images/images-30-_jpeg_jpg.rf.7d1e6b6ef88b7485c5ee57c3b28d5fc8.jpg: 640x640 1 VPE, 10.0ms\n",
            "image 143/174 /content/datasets/CPE-Dataset-16/valid/images/images-31_jpeg_jpg.rf.1f7eeba7d1d37b4eabb24622186a524a.jpg: 640x640 1 VPE, 10.3ms\n",
            "image 144/174 /content/datasets/CPE-Dataset-16/valid/images/images-35-_jpg.rf.e65eb7934507f7e9a1f0bf8cde29d47a.jpg: 640x640 1 VPE, 10.1ms\n",
            "image 145/174 /content/datasets/CPE-Dataset-16/valid/images/images-37-_jpg.rf.587e4edabc2525fce040161b8cd432b3.jpg: 640x640 1 VPE, 11.0ms\n",
            "image 146/174 /content/datasets/CPE-Dataset-16/valid/images/images-38-_jpg.rf.cac78cf7c14d220dd14c129aed9aff18.jpg: 640x640 1 NE, 10.3ms\n",
            "image 147/174 /content/datasets/CPE-Dataset-16/valid/images/images-41-_jpg.rf.2b5fe3cefefb017d338fa8347eaa588c.jpg: 640x640 1 VPE, 10.1ms\n",
            "image 148/174 /content/datasets/CPE-Dataset-16/valid/images/images-44-Copy_jpg.rf.a0ff1142434486229015c33e72519498.jpg: 640x640 1 NE, 10.2ms\n",
            "image 149/174 /content/datasets/CPE-Dataset-16/valid/images/images-47-_jpg.rf.3f608db4d295ec90c519fd12cd489fde.jpg: 640x640 (no detections), 10.3ms\n",
            "image 150/174 /content/datasets/CPE-Dataset-16/valid/images/images-5-_jpg.rf.d95511cac589cda7470b71dec7dd8660.jpg: 640x640 1 VPE, 10.3ms\n",
            "image 151/174 /content/datasets/CPE-Dataset-16/valid/images/images-52-_jpg.rf.52d67c1bbe93d5316c480e67cb5c1346.jpg: 640x640 1 APE, 1 VPE, 10.3ms\n",
            "image 152/174 /content/datasets/CPE-Dataset-16/valid/images/images-56-Copy_jpg.rf.bba67acc4381cfd34c8a48f50c3165d6.jpg: 640x640 1 NE, 11.7ms\n",
            "image 153/174 /content/datasets/CPE-Dataset-16/valid/images/images-59-_jpg.rf.6af6c1542413fd75a67c08609f34f2d7.jpg: 640x640 1 VPE, 10.1ms\n",
            "image 154/174 /content/datasets/CPE-Dataset-16/valid/images/images-62-_jpg.rf.77e449df229229d7e9330f89f5d516df.jpg: 640x640 1 VPE, 10.2ms\n",
            "image 155/174 /content/datasets/CPE-Dataset-16/valid/images/images-67-Copy_jpg.rf.0f3529ebd564292702262553018ef8cf.jpg: 640x640 1 NE, 10.4ms\n",
            "image 156/174 /content/datasets/CPE-Dataset-16/valid/images/images-67-_jpg.rf.6eed3c752ae5c7f06e827ed178d2b0cc.jpg: 640x640 1 VPE, 10.5ms\n",
            "image 157/174 /content/datasets/CPE-Dataset-16/valid/images/images-67-_jpg.rf.75519c06d73ab8f6a179ec8628ec6e2d.jpg: 640x640 1 VPE, 10.7ms\n",
            "image 158/174 /content/datasets/CPE-Dataset-16/valid/images/images-7-_jpg.rf.33e5cb030dd25bdf9ac633af0b5c96a9.jpg: 640x640 1 NE, 11.6ms\n",
            "image 159/174 /content/datasets/CPE-Dataset-16/valid/images/images-8-_jpg.rf.561260d51daacd8dc8e21bcae53cb010.jpg: 640x640 1 APE, 10.2ms\n",
            "image 160/174 /content/datasets/CPE-Dataset-16/valid/images/images-8-_jpg.rf.dbae5e4e10a5ab956911bae56dcb1f55.jpg: 640x640 2 APEs, 10.2ms\n",
            "image 161/174 /content/datasets/CPE-Dataset-16/valid/images/images-83-_jpg.rf.44d63cdc39aaa4f75772492653e3b125.jpg: 640x640 1 BPE, 1 VPE, 10.4ms\n",
            "image 162/174 /content/datasets/CPE-Dataset-16/valid/images/images-84-_jpeg.rf.ef26d5ed0b592a1ef90fde45a76ead61.jpg: 640x640 1 VPE, 10.3ms\n",
            "image 163/174 /content/datasets/CPE-Dataset-16/valid/images/images-95-_jpg.rf.626cc5234f6b8578d044c6bd970c5646.jpg: 640x640 1 VPE, 10.3ms\n",
            "image 164/174 /content/datasets/CPE-Dataset-16/valid/images/images_jpeg.rf.8c57ad69947ce3cef692d2c2b4e1044e.jpg: 640x640 1 VPE, 10.4ms\n",
            "image 165/174 /content/datasets/CPE-Dataset-16/valid/images/istockphoto-1143266445-612x612_jpg.rf.d8b463f24b07eaa02ea955df8f5e2747.jpg: 640x640 (no detections), 10.3ms\n",
            "image 166/174 /content/datasets/CPE-Dataset-16/valid/images/istockphoto-1391628898-612x612_jpg.rf.b529565568381488abb874a3d2eba903.jpg: 640x640 2 VPEs, 10.3ms\n",
            "image 167/174 /content/datasets/CPE-Dataset-16/valid/images/istockphoto-1488091948-612x612_jpg.rf.6cc277c1d285d0c8c1ed959dfeacea60.jpg: 640x640 1 VPE, 10.7ms\n",
            "image 168/174 /content/datasets/CPE-Dataset-16/valid/images/istockphoto-149079036-612x612_jpg.rf.0eb3ff72797c14017150ed47eae11592.jpg: 640x640 2 VPEs, 10.3ms\n",
            "image 169/174 /content/datasets/CPE-Dataset-16/valid/images/istockphoto-179628926-612x612_jpg.rf.c4b71e494ccb2358592fc2af6a7e744f.jpg: 640x640 1 VPE, 10.6ms\n",
            "image 170/174 /content/datasets/CPE-Dataset-16/valid/images/istockphoto-957480102-612x612-Copy_jpg.rf.05d7017a29dee146d418bbcf45b830f8.jpg: 640x640 1 NE, 10.3ms\n",
            "image 171/174 /content/datasets/CPE-Dataset-16/valid/images/istockphoto-957480102-612x612_jpg.rf.5786d1b06b2e509c3939234e0675df1f.jpg: 640x640 1 NE, 12.0ms\n",
            "image 172/174 /content/datasets/CPE-Dataset-16/valid/images/pinkeye1-1024x642_jpg.rf.d6949ffbba2f72f8aa3cd99bd18e6ea4.jpg: 640x640 1 VPE, 10.4ms\n",
            "image 173/174 /content/datasets/CPE-Dataset-16/valid/images/red-bloodshot-eye-woman-irritated-infected-conjunctivitis-cry-186160485_webp.rf.3720e56db1edc7d5261388f6078afd45.jpg: 640x640 2 VPEs, 11.0ms\n",
            "image 174/174 /content/datasets/CPE-Dataset-16/valid/images/stock-photo-close-up-of-a-bloodshot-eye-damage-by-an-injury-hemorrhage-of-the-eye-rupture-of-a-vessel-in-the-2231585821-Copy_jpg.rf.eb1c31c01548d2fbd588192d237393d1.jpg: 640x640 1 NE, 10.4ms\n",
            "Speed: 2.4ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!yolo task=detect mode=predict model=/content/runs/detect/train2/weights/best.pt conf=0.25 source=/content/datasets/CPE-Dataset-16/valid/images save=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEYIo95n-I0S"
      },
      "source": [
        "**NOTE:** Let's take a look at few results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0tsVilOCPyq"
      },
      "source": [
        "## Deploy model on Roboflow\n",
        "\n",
        "Once you have finished training your YOLOv8 model, you’ll have a set of trained weights ready for use. These weights will be in the `/runs/detect/train/weights/best.pt` folder of your project. You can upload your model weights to Roboflow Deploy to use your trained weights on our infinitely scalable infrastructure.\n",
        "\n",
        "The `.deploy()` function in the [Roboflow pip package](https://docs.roboflow.com/python) now supports uploading YOLOv8 weights.\n",
        "\n",
        "To upload model weights, add the following code to the “Inference with Custom Model” section in the aforementioned notebook:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Define the folder to compress and the output ZIP file path\n",
        "folder_to_zip = \"/content/ultralytics\"\n",
        "output_zip = \"/content/ultralytics1.zip\"\n",
        "\n",
        "# Create a ZIP archive of the ultralytics folder\n",
        "try:\n",
        "    shutil.make_archive(output_zip.replace(\".zip\", \"\"), \"zip\", folder_to_zip)\n",
        "    print(f\"Created ZIP file: {output_zip}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating ZIP file: {e}\")\n",
        "    raise\n",
        "\n",
        "# Download the ZIP file\n",
        "if os.path.exists(output_zip):\n",
        "    files.download(output_zip)\n",
        "    print(\"Downloading ultralytics.zip...\")\n",
        "else:\n",
        "    print(f\"ZIP file {output_zip} not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "YHbd9fS0IRz0",
        "outputId": "2ec7f4b5-dda2-421f-c1d8-01c6d7a5290a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created ZIP file: /content/ultralytics1.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ab00b666-ebff-4f52-83e8-f13b9431642d\", \"ultralytics1.zip\", 39947693)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ultralytics.zip...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/ultralytics\")  # Use custom ultralytics directory\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Load the trained model\n",
        "model_path = \"/content/runs/detect/train2/weights/best.pt\"  # Adjust path to your trained model\n",
        "try:\n",
        "    model = YOLO(model_path)\n",
        "    print(\"Model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABr-Yv8xKEnQ",
        "outputId": "93472d3c-66d2-4e9f-e61c-f7ac7063cf18"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load an input image\n",
        "image_path = \"/content/datasets/CPE-Dataset-16/valid/images/1-Copy-Copy-Copy_jpg.rf.34d4ed872aceb1e9fdd7f77b9522bbab.jpg\"  # Replace with your test image path\n",
        "if not os.path.exists(image_path):\n",
        "    print(f\"Image {image_path} not found. Please upload an image.\")\n",
        "    files.upload()  # Upload an image via Colab\n",
        "    image_path = list(files.upload().keys())[0] if files.upload() else None\n",
        "\n",
        "# Manual preprocessing\n",
        "img = cv2.imread(image_path)\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_resized = cv2.resize(img_rgb, (640, 640))  # YOLOv8 default input size\n",
        "img_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).float() / 255.0  # Normalize, CHW\n",
        "img_tensor = img_tensor.unsqueeze(0).to(model.device)  # BCHW\n",
        "\n",
        "# Register forward hook to capture activations\n",
        "activations = {}\n",
        "def get_activation(name):\n",
        "    def hook(module, input, output):\n",
        "        activations[name] = output\n",
        "    return hook\n",
        "\n",
        "# Target layers (adjust based on yolov8-Ghost.yaml)\n",
        "target_layer_indices = [16, 19, 22]  # Use [22] if single input\n",
        "for idx in target_layer_indices:\n",
        "    try:\n",
        "        model.model.model[idx].register_forward_hook(get_activation(f\"layer_{idx}\"))\n",
        "    except IndexError:\n",
        "        print(f\"Layer index {idx} not found in model. Check model architecture.\")\n",
        "        print(model.model)\n",
        "        raise\n",
        "\n",
        "# Perform inference\n",
        "model.model.eval()\n",
        "with torch.no_grad():\n",
        "    _ = model.model(img_tensor)  # Run forward pass to capture activations\n",
        "\n",
        "    # Create EigenCAM instance\n",
        "    from ultralytics.nn.modules.yolo_cam.eigen_cam import EigenCAM\n",
        "    try:\n",
        "        eigencam_module = EigenCAM(model=model.model, target_layers=[model.model.model[idx] for idx in target_layer_indices])\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating EigenCAM instance: {e}\")\n",
        "        raise\n",
        "\n",
        "    # Get activations\n",
        "    activation_tensors = [activations[f\"layer_{idx}\"] for idx in target_layer_indices]\n",
        "    print(f\"Activation tensors: {[t.shape for t in activation_tensors]}\")\n",
        "\n",
        "    # Apply EigenCAM\n",
        "    try:\n",
        "        heatmap = eigencam_module(activation_tensors, targets=None, eigen_smooth=False)\n",
        "        print(f\"Heatmap shape: {heatmap.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in EigenCAM forward: {e}\")\n",
        "        raise\n",
        "\n",
        "# Process the heatmap\n",
        "heatmap = heatmap.squeeze().cpu().numpy()  # Remove batch dimension\n",
        "if heatmap.ndim > 2:\n",
        "    heatmap = heatmap.mean(axis=0)  # Average across channels if multi-channel\n",
        "heatmap = np.maximum(heatmap, 0)  # ReLU\n",
        "heatmap = heatmap / np.max(heatmap) if np.max(heatmap) != 0 else heatmap  # Normalize\n",
        "\n",
        "# Resize heatmap to match input image size\n",
        "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "# Create a colored heatmap\n",
        "heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
        "heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Overlay heatmap on original image\n",
        "alpha = 0.4  # Transparency factor\n",
        "overlay = img_rgb.copy()\n",
        "overlay = cv2.addWeighted(overlay, 1 - alpha, heatmap_colored, alpha, 0)\n",
        "\n",
        "# Visualize the result\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(img_rgb)\n",
        "plt.axis(\"off\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"EigenCAM Heatmap\")\n",
        "plt.imshow(overlay)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Save the heatmap and overlay\n",
        "cv2.imwrite(\"/content/eigencam_heatmap.jpg\", cv2.cvtColor(heatmap_colored, cv2.COLOR_RGB2BGR))\n",
        "cv2.imwrite(\"/content/eigencam_overlay.jpg\", cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
        "print(\"Saved eigencam_heatmap.jpg and eigencam_overlay.jpg\")\n",
        "\n",
        "# Download the results\n",
        "files.download(\"/content/eigencam_heatmap.jpg\")\n",
        "files.download(\"/content/eigencam_overlay.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "jXWLAtj9I5H3",
        "outputId": "4a3e636d-732d-4d7a-cce9-0047b24314cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation tensors: [torch.Size([1, 64, 80, 80]), torch.Size([1, 128, 40, 40]), torch.Size([1, 384, 20, 20])]\n",
            "Heatmap shape: torch.Size([80, 80])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved eigencam_heatmap.jpg and eigencam_overlay.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3d1c3b5a-53ff-4049-801d-6445fde1157f\", \"eigencam_heatmap.jpg\", 38879)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0e5aacd1-559f-4e1b-8cb2-1d39ab59a946\", \"eigencam_overlay.jpg\", 41098)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EhBAJ2gCPZh",
        "outputId": "53bb5d98-2c09-476d-d2f3-b426176d3495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An error occured when getting the model upload URL: This version already has a trained model. Please generate and train a new version in order to upload model to Roboflow.\n"
          ]
        }
      ],
      "source": [
        "project.version(dataset.version).deploy(model_type=\"yolov8\", model_path=f\"{HOME}/runs/detect/train/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5kOhjkmcV1l"
      },
      "outputs": [],
      "source": [
        "#While your deployment is processing, checkout the deployment docs to take your model to most destinations https://docs.roboflow.com/inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4bpUIibcV1l"
      },
      "outputs": [],
      "source": [
        "#Run inference on your model on a persistant, auto-scaling, cloud API\n",
        "\n",
        "#load model\n",
        "model = project.version(dataset.version).model\n",
        "\n",
        "#choose random test set image\n",
        "import os, random\n",
        "test_set_loc = dataset.location + \"/test/images/\"\n",
        "random_test_image = random.choice(os.listdir(test_set_loc))\n",
        "print(\"running inference on \" + random_test_image)\n",
        "\n",
        "pred = model.predict(test_set_loc + random_test_image, confidence=40, overlap=30).json()\n",
        "pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGRH0rX_vpfI"
      },
      "source": [
        "# Deploy Your Model to the Edge\n",
        "\n",
        "In addition to using the Roboflow hosted API for deployment, you can use [Roboflow Inference](https://inference.roboflow.com), an open source inference solution that has powered millions of API calls in production environments. Inference works with CPU and GPU, giving you immediate access to a range of devices, from the NVIDIA Jetson to TRT-compatible devices to ARM CPU devices.\n",
        "\n",
        "With Roboflow Inference, you can self-host and deploy your model on-device. You can deploy applications using the [Inference Docker containers](https://inference.roboflow.com/quickstart/docker/) or the pip package.\n",
        "\n",
        "For example, to install Inference on a device with an NVIDIA GPU, we can use:\n",
        "\n",
        "```\n",
        "docker pull roboflow/roboflow-inference-server-gpu\n",
        "```\n",
        "\n",
        "Then we can run inference via HTTP:\n",
        "\n",
        "```python\n",
        "import requests\n",
        "\n",
        "workspace_id = \"\"\n",
        "model_id = \"\"\n",
        "image_url = \"\"\n",
        "confidence = 0.75\n",
        "api_key = \"\"\n",
        "\n",
        "infer_payload = {\n",
        "    \"image\": {\n",
        "        \"type\": \"url\",\n",
        "        \"value\": image_url,\n",
        "    },\n",
        "    \"confidence\": confidence,\n",
        "    \"iou_threshold\": iou_thresh,\n",
        "    \"api_key\": api_key,\n",
        "}\n",
        "res = requests.post(\n",
        "    f\"http://localhost:9001/{workspace_id}/{model_id}\",\n",
        "    json=infer_object_detection_payload,\n",
        ")\n",
        "\n",
        "predictions = res.json()\n",
        "```\n",
        "\n",
        "Above, set your Roboflow workspace ID, model ID, and API key.\n",
        "\n",
        "- [Find your workspace and model ID](https://docs.roboflow.com/api-reference/workspace-and-project-ids?ref=blog.roboflow.com)\n",
        "- [Find your API key](https://docs.roboflow.com/api-reference/authentication?ref=blog.roboflow.com#retrieve-an-api-key)\n",
        "\n",
        "Also, set the URL of an image on which you want to run inference. This can be a local file.\n",
        "\n",
        "_To use your YOLOv5 model commercially with Inference, you will need a Roboflow Enterprise license, through which you gain a pass-through license for using YOLOv5. An enterprise license also grants you access to features like advanced device management, multi-model containers, auto-batch inference, and more._"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}